{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the daily movement of the stock market using various supervised ML Algorithms\n",
    "## Submitted by Kumar Gaurav\n",
    "## PGDIE 46 NITIE Mumbai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "from IPython.display import display\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market data read successfully!\n",
      "Number of data points: 5962\n"
     ]
    }
   ],
   "source": [
    "# Read data from SP500_historical.csv - data contains returns for the S&P500 and VIX index going back over 23 years\n",
    "# Source: Yahoo Finance\n",
    "\n",
    "all_data = pd.read_csv(\"SP500_historical.csv\",header=0)\n",
    "print (\"Market data read successfully!\")\n",
    "print (\"Number of data points:\", len(all_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'SP_Open', 'SP_High', 'SP_Low', 'SP_Close', 'SP_Volume',\n",
      "       'Vix_Open', 'Vix_High', 'Vix_Low', 'Vix_Close'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print (all_data.dtypes.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the 'Date' column data from a string into a form that can be manipulated mathematically\n",
    "# Calculate the 'Days_Since_Open' feature, which is a measure of how many days have passed since the market last opened\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "all_data['Date'] = pd.to_datetime(all_data['Date'])\n",
    "\n",
    "all_data['Days_Since_Open'] = (all_data['Date'] - all_data['Date'].shift(-1))\n",
    "all_data['Days_Since_Open'] = all_data['Days_Since_Open'].astype('timedelta64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1856615ff98>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEKCAYAAADq59mMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXV4FNcWwH8nSgjBXYNTKB6sSPFiLa/y6u7uEqgLLTVo\n++rupUYVihYv7u6hECRBQxLi9/0xs5v13exGNpv7+779MnPnzuyZze6ce+8xUUqh0Wg0Gk1RCCtr\nATQajUZT/tDKQ6PRaDRFRisPjUaj0RQZrTw0Go1GU2S08tBoNBpNkdHKQ6PRaDRFpsSUh4g0EZF5\nIrJFRDaLyH0Oxx8SESUitW3axonILhHZLiLn2bR3F5GN5rG3RERKSm6NRqPReKckZx55wENKqfZA\nb+AuEWkPhmIBhgP/Wjqbxy4HOgAjgHdFJNw8/B5wC9DafI0oQbk1Go1G44USUx5KqUNKqTXm9mlg\nK9DIPDwZeBSwjVAcC0xRSmUrpfYCu4CeItIAqKqUWqaMiMYvgf+UlNwajUaj8U5EabyJiMQDXYHl\nIjIWSFZKrXdYfWoELLPZP2C25Zrbju2u3udW4FaA2NjY7u3atSumO9BoNJqKwerVq48qpep461fi\nykNEqgA/A/djLGWNx1iyKnaUUh8CHwIkJCSoVatWlcTbaDQaTcgiIvt86Vei3lYiEomhOL5RSk0F\nWgLNgfUikgQ0BtaISH0gGWhic3pjsy3Z3HZs12g0Gk0ZUZLeVgJ8AmxVSk0CUEptVErVVUrFK6Xi\nMZaguimlDgO/A5eLSLSINMcwjK9QSh0C0kSkt3nNa4HfSkpujUaj0XinJJet+gLXABtFZJ3ZNl4p\nNd1VZ6XUZhH5AdiCsbx1l1Iq3zx8J/A5EAP8Zb40Go1GU0ZIqKZk1zYPjUajKToislopleCtn44w\n12g0Gk2R0cpDo9FoNEVGKw+NRqPRFBmtPDQajUZTZEolwlyj0Wg0wclv65K5b4rhEPvWFV19Pk/P\nPDQajaaCcjwjx6o4AO79bq3P52rlodFoNOUUpRQFBf6HW6zYe8zvc/WylUaj0ZQjZm4+TK3YKBpW\nj+GciX8DUDM2itz8AmbcP4BG1WN8us6Wg2n87+9dAKx7ahhdnptdJDm08tBoNJpyQE5eAQVKcdtX\nq52OHc/IAaDvxL/5J3Ew1StH0v6pmdSoHMlnN/SkS5Pq1r4Ld6Ty5dIk5mxNsbZVrxzF0+e3p029\nOPq97Js8WnloNBpNkPPDqv08+tMGLujc0Gvfqz9Zzu3ntgTgRGYu/3lnCYseHUSTmpVRSnHtpytc\nnndD3+ZFkknbPDQajSaI+dFUHAC/rz/otf+IDvV5ZcY2u7b+r8wD4PVZO4pNLq/KQ0TaiMhcEdlk\n7ncSkSd8OM9lDXMRqSkis0Vkp/m3hs05uoa5RqPR2PCIqThcsfvFUWx73r4qd9WYSPq1qu2y/9vz\ndhWbXL7MPD4CxmFU9EMptQGj1rg33NUwTwTmKqVaA3PNfV3DXKPRaGw4dSaXk5k5Lo91blyNdU8N\nIzxMqBQZzk+39+GzG3oAkJtXwK/rnGcoxZ0E1xebR2Wl1AqHwX6et5PMOhyHzO3TImKpYT4WGGh2\n+wKYDzyGTQ1zYK+IWGqYJ2HWMAcQEUsNc52WXaPRhCTxidM8Hv/t7n52+wnxNa3KYd72FFensDH5\nFAAPD2/D3YNb+/Q+nvBFeRwVkZaAAhCRSzCVgq/Y1jAH6pmKBeAwUM/cLtYa5k2bNi2KiBqNRlOm\nKKVoPs5luSM7Glar5LLdMsBf8+9Ja9v6p4bT+blZtKsfx1UfLQfgTG6+9fiIDvU53wcjvCt8UR53\nYdQFbyciycBe4Gpf38C2hrlSKs12BqOUUiJSbHMpxxrmxXVdjUajKWk+WrTH7bHeLWqybM9xFj06\niIY+xnG8f3V3qlWOZHSnBmw9mEbb+nGs2neCq3o1K+xzTXe/5fWqPJRSe4ChIhILhCmlTvt6cRc1\nzAGOiEgDpdQhEWkAWOZYuoa5RqOpkJzJyefF6dvcHv/ixp6kZ+VRq0q0z9esExcFQFZOPnuOZrDn\naAaAz8rHG754W90nIlWBTGCyiKwRkeE+nOdUw9zkd+A6c/s6CuuR6xrmGo2mQrIy6bhT220DWli3\noyPCi6Q4AKrFGMpj7jbXNpBA8cXb6kalVBowHKiFUZd8og/nWWqYDxaRdeZrlHnuMBHZCQy1XEsp\ntRmw1DCfgXMN84+BXcButLFco9GEAFm5+aSezuaFaVsAmH5vf+uxa8+JD+ja1WIiAzrfG77YPCxG\nilHAl0qpzb7EWSilFtuc68gQN+dMACa4aF8FnO2DrBqNRlMuWL//JGPfWWLX1r5hVVY/MZS0rDwq\nRQQWw21RHl2bVmetaUSfcGHxPUZ9kW61iMzCUB4zRSQOKCg2CTQajaYCcSYnn6zcfCfFYaFWlWia\n144lrpL/M4f7hrQmylQ+95puucWNLzOPm4AuwB6lVKaI1AJuKBFpNBqNJoTZcjCNUW8tcnls9RND\n7fajIsJ4akx7ujWr4bK/K2beP4CYyHCa1qpsbevdopZ1O/V0dhEldo8v3lYFItIYuNJcrVqglPqj\n2CTQaDSaCsL8Ha6N1yM61HdpEL+xX9GSFbatH+fUFhMVzntXdeOOb9bQzEapBIov3lYTgfswDNlb\ngHtF5MVik0Cj0WgqAMMmLeCVGdvt2pYkDgaKriSKysiODfj97r78p4vL+Gq/8GXZahTQRSlVACAi\nXwBrgfHFJoVGo9GEMGlZuexMSXdqb1Q9hqSJo0tFhk6Nq3vvVAR8Nefbvmu1YpVAo9FoQpxOz8yy\nbvdv7TrjbXnDF+XxErBWRD43Zx2rceFOq9FoNBrPjO3SkK9u6lXWYhQLvhjMvxOR+UAPs+kxpdTh\nEpVKo9Foyjn7j2eSk1/AkNcXAFAlOoLX/tsZgMmXdaZpzdiyFC9g3CoPEenm0GTJbNtQRBoqpdaU\nnFgajUZTftmVks7QSQvs2u4f2prIcGOx58KujV2dVq7wNPN43cMxBQwuZlk0Go2mXJNyOovoiHAn\nxQFQu4i5qYIdt8pDKTWoNAXRaDSa8kxBgaLnhLluj8dG++LcWn5wazAXkatF5BoX7deIyJXeLiwi\nn4pIiqX2uU37PSKyzaxr/opNu65frtFoyi17j2W4Pda8diw9m9csRWlKHk/eVvcAv7honwo85MO1\nP8eh1riIDMIoN9tZKdUBeM1s1/XLNRpNuebLf5Ls9p8a0966Pe/hgSWe5ba08TSPilRKOUW1KKUy\nzCJPHlFKLTTLz9pyBzDRrFOOUsoSq6/rl2s0mnLLqTO5fLF0n11brSpRbHt+BFHhgWXHDVY83VWM\nWT3QDjOrbpSf79cG6C8iy0VkgYhY3H8bAftt+lnqlDfCx/rlpmy3isgqEVmVmprqp4gaTcUmIzuv\nrEUod/ScMMepbVj7elSKDCcsLDRX2j0pj0+An0TEWvDWnElMMY/5QwRQE+gNPAL8UJw2DKXUh0qp\nBKVUQp06dYrrshpNSLN+/0ku/WApSil2p6bT4emZjJu6EaVUWYtWLrjsg6Vk5xVWqXh0RFtEoHJU\naBnIHfHkbfWaiKQDC0WkitmcjrHs9J6f73cAmKqMb+UKESkAaqPrl4c8p7NyycjOp361SmUtisbk\n8KksRry5kJOZuQBsSk7j/LcXA/Ddin/p2rQ6lyY08XSJCk9Gdh7L9xaWkB3dsQF3DmzFnQNblaFU\npYPHxTil1PtKqWZAPBCvlGoWgOIA+BUYBCAibTCWv46i65eHPA/+sJ7eL81lU/IpAJRSzNh0iB9W\n7Sc+cRopp7PKWMKKRUGBovdLc62KA2DTwVN2fR79aQPfLv+3tEUrV3R4eqZ1++WLO/LihR3LUJrS\nxSdLjlLqtFLqdFEuLCLfAUuBtiJyQERuAj4FWpjuu1OA65SBrl8e4szecgSAMf8zRrbvL9jD7V+v\n4dGfNgBw33fryky2isitX612ahs3daNT2/hfNrLjSJF++hWG6RsP2e1f1qMp1SqHlkeVJ0psUU4p\ndYWbQ1e76a/rl4cYO46cJievgLMb2Sdijk+c5tR36Z5jpSWWBpiz9YjbY1ERYeTYrOF/vWwfz42t\n2D9BpRQHTpyhSc3CYkoP/bDeuv26mbOqIhHaFh1NmZGVm8/wyQsBeO8qxzRprkk5nUXdOG0TKSmW\n7j7GFR8t4/MbeljbLLUkbBX6o+e15YVpW637x9JzSk/IIGXBjlSu/2wlAC9e2JHmtWM5k2ssjqx9\nchg1Yv11QC2/eFQeIlINIyjP4h6bDMxUSp0sacE05Ze8/AKe/LUwscAd3/iWQ7PnhLm89t/OXNK9\n/CeNCyZOZuZw61erWWEadi0PwQeHtXHZ/+Juje2UR7iDq2lGdh6pp7OJr12+s8IWhddn7bBuj/+l\ncHnvlv7NK6TiAM/pSa4F1gADgcrmaxCw2jym0bBoZypDXp9PVm6+te3Rnzfw4+oDHs6yZ3THBtbt\nh39c76Gnpqjk5hfQ5bnZVsVhy60DWji1hQlOD8Pf1x+koMBw203LyqXD0zMZ+Np8cvMLnM4vz2Tl\n5hOfOI3hkxdw8OQZa/v87SlsTD7l8pz+rStuSIAng/njQHel1B1KqRfM1+1AAvBE6YinCXau+WQF\nu1MzSLLJ6zN1jXdv6p7Na/LbXX359uZevH1l15IUscJyND2b1o+79i85q0FVKkWGW/ct/4Of7zgH\ngEfOa2vX/4OFewC49P2l1jZ31y6vPP3bZgB2HEnnnIl/W9stMzVXRIRoAKAveFIegpF63ZEC85im\nglJQoNhw4KSde+2INxZx3acr7PpV8ZBFdMXe43RuUp1zWtXGMU40PnEa7y/YTZvH/9KBagGQ8EJh\n1PNnN/Swq5U9qK39iHlMp4asfmIoXZvWAOCuQa1Y//Rw6/GXZ2xj5JuL2Ha4/HhepWfnkZ2X770j\nkF+g+H7Vfrs2y0zEwqRLO/OZjb3o8xt6cE6r0Cgp6w+ebB4TgDUiMovC1CFNgWHA8yUtmCY4OZ6R\nQ7fnZ7s8tmBHKjM2Fbovbnr2PJeeVQAz7x/g8X0m/rUNgCNp2Tqw0A/W/nvCut2hYVUGta0LwGMj\n2vHyjG08PLyt0zm1HOpNVIuJ5I3LunD/94Yb9dZDaU7nKKWclH9Zkl+gyMrNJzY6grPNGIz5Dw/k\nk8V7uap3U9rVr+ryvJbjpzu1tXtyhnW7dpUoLurWmKPp2YCxvDfQ/EwrKp4izL8Qkd+B8yg0mM8H\nximlTrg7TxPaLNrpOWfY7V8bxvHLzMjk3+7qy9h3lgDwxOizaFQ9hpE2Ng5v/LnhIDf3d16b1xgU\nFCi2HT5N+4b2D8UL3/0HgLsGteShYYWK4o6BLbljYEufr38sw7On1dH0HOrEBU+RozH/W8zWQ2m0\nqFNozB/42nwAvlq2z272ZcExl9fVvZvy9TL74MjJl3UBoFZsFBd1bcSIs+sXs+TlD4/eVqaSmCIi\nNc19Z6ubpsKQm1/AfVN8C+a7sV9zADo3qU7iyHZk5eZ7VAK9W9Rk2R7nr9cL07Zyc/8WZObk8fqs\nHdw7uHWFCsRyR36B4uEf1/PLWsO+9OPtfegRb9SLmDBti7XfI+e1C+h9KkeFO7U9NKwNa/49wbzt\nqXy1bB+jOzagbf24gN6nOMjJK7DOjvakuq6tkV+gnLzHLC7lcdERzHtkIJHhYXbKo2G1SpzT0lie\nEhEmmYqkouOphnlT4BWMcrOnjCapCvwNJCqlkkpFQk3QMGWF76kqYmyMsbef632kO+XWPgCMfWcJ\n6/c7e4L/uf4Qnyzey5nc/AqVAsKRz5bs5cul+9h71P7h+MacHXx5Yy+2Hkrjo0V7AbjZVOCBMLhd\nXUTA1vR0z5DW7EpJZ972Bbw1dydvzd0J4HJUX5q0ecK7AT/1tLEMmpJm2OvqVq1EsulZ9cc9/ahd\nJdrJzrYkcXBQLc0FC54M5t9jFINqoJRqrZRqBTTAyE81pTSE0wQHl36wlPjEaTxpeqPY0qt5Tfq3\ndjYaVor0r4bBlzf2tG43MG0dufkFvPW38YCqqLmWUk5n0emZmTz7xxYnxQGwZNcxWo6fbk3/AvD4\n6LMCft96VSux96XRdGta3a69gQs7lMWdtyzYnepUeoiZ9w+gcY0YuzaLzaLni3Pp+eJc5m83Sgo1\nqh5jjVuxVRQz7u+vFYcbPP3CayulvrfJMYVSKl8pNQWoVfKiaYIFxxiBuOgIdr84im9u7sX3t/Xh\n/au78/MdfTivQz1rn7pV/TNyW5ZJ+reuzaFTxujwnm/XcuBEod99XojFF7hi3rYUMrLzOJNj/Px6\nTphLWpZznY1Fjw5yef7uF0cV60Pv7SuNLAGzHjAcHVzV427hwuhcWgx5fYFTW9v6cXx9Uy+7tl/X\n2ruRW9xwn7Sp+gew5slhvHhhR9rWK/vluGDFk81jtYi8C3xBobdVE+A6YK23C4vIp8AYIEUpdbbZ\n9ipwPpCDkeTwBku0uoiMA24C8oF7lVIzzfbuGCVtY4DpwH1K+2+WGodPOWe7XfjoIMLDhL6mm2Js\ndATdm9Xkg2tqMui1+QEZUCPDw1j9xFCqxUTSyowjmLH5sF2fVo//xfYXRhAd4bweX97YdyyDmKhw\nu7QszcdNs1smem5sB7tzGlSrxMXdGvOwGYvx5Jj2PP9noZ3jsxt6OK3rB0rD6jFlvizlimPp2fy+\n/qB1P2niaDYfPMWuFGMmEl87lrVPDiM1PZvhkxdSIzbKpft3P4fZc83YKK7s1bRkhS/neJp5XAts\nBJ4FZpqvZ4FNwDU+XPtznOuNzwbOVkp1AnYA40DXMA9mluw66tTmKR3DvIcH8sNtfQJ6z1pVookI\nD+PPe/rZtTe3SYfR9okZLhVbeeDRn9YTnziN39Ylc+6r8+k5YS5gzKjG/G8Rjs+2p8zlws6Nq5E0\ncTRLxw2xKg6Am2xsG12bVre65ZY057Q0FiD6tChciCjucd37C3YTnzjNpZswQPcX5vDsH4bi/PWu\nvgB0aFiNsV0KC47WiI2iulk//NWZ22k+znmG5CkmSeMat8pDKZWjlHpPKTVCKdXRfI1QSr1rqUHu\nCaXUQuC4Q9sspZRl7r2MwkJP1hrmSqm9GOnXe4pIA8wa5uZsw1LDXFPMHE3PZsEOezfcXSnpPGSm\nC4kMF+4Y2JIdL4wsNZnOblSN6IjCr+hr/+1kd/zZP5xtMMHOC39u4YdVRuoWW8+1Sz9YSqvH/2JT\nsuuHJMBXN/dye2z1E0PZ/Ox5/HJn3+IT1guTLu3C7ee25BsbuTJzfAvK8xVLvM/INxc5HXNcvuzS\npLpTHwuRIVpHvCzxlNuqtsP+1SLyllknvDjmxDdSWJtD1zAvY/q/PI/rPl3B6azC4kBDJxWuI697\najiPjWhHVETp/ghty3t2b1aTx0YUup7+temwNafW4p1HeeTH9UyavQOlFDd/sYppGw45Xa8sWbf/\nJB8v3uvymKNd6Y+7+7HhmeGM6VQYE1O1knsX5VpVol3aIUqS+tUqkTiynV2N7oJinHk88L1nt/BW\nRUiPEunhe1uaA6JQwtOTYJZlQ0SewFiqWo0RYT4pkDcVkceBPOCbQK7jiK5h7h8FBcqaXtrWkyfW\nxse/tB9M7ripX3P62aSEOJaRw66UdK7+ZDk/rj7AW3N38snivczZeoS7vvUtm28gPPP7ZuITpxGf\nOI1uz8/mtZnbUUqxdPcxdqUUpvLIyM7jUxvFYVHCn13fw+56Yzo1IGniaDo2rkbVSpFMutSIKXjI\nTQbcYMNVAsaiYEkJsnT3MWsMiwXbJbE0m0FO89qxfHdLb4/XjQx3P94t7QFRqODpiWD7aV8E9FdK\nZYjItxjZdv1CRK7HMKQPsTF86xrmpUxWbj6TZ++gZd0qtK5bxdp+wdtLSJo4mrSsXDKKeQmiOIiK\nCOPrm3vx4vStfLhwD5uST3GbQ1U823Tit3+1mvev6V4ispzJyefzf5Ks+8czcnh73i7enrfL2rb9\nhREs2XWUGz9fZW3b+9IoCpTRv05cNBMuPJvHfzFS2D8x2t7rJyoiLCgN1e44FKAdqoeZj+uKj5YB\ncF6HeszcbBSuOpGZS+WocK76eDmr9xUmuZj38ECv140Mc1YQ8x4eyHEvEfQa93hSHjEi0hVjdhKp\nlMoAUErliohfTxURGQE8CpyrlMq0OfQ78K2ITAIaUljDPF9E0kSkN7Acw4j/P3/eW2OPbd4eV+w/\nXvjvWfyYa3fQsmRQ27p8uHAPO72USJ2x+TAzNh1ixNm+p0Txlcd+3uC1T9sn7D/n6IgwRIRwweqV\ndlWvZvx7LJPrzokv93m8bFPzF4XU09n0mDDHqf3WAS2tysNVTrUPfBwYhLnwPmteO9bOCUNTNDzN\n1w5hLE+9Bhw1jdeISC2MJSePuKlh/jYQB8wWkXUi8j6ArmFeuthO+V3x0vSt1riKSZd2pnGNyh77\nlySWBIqOhYs6NjZK275mU6TnWzcG5du/XlMi9g+Li+iqJ4b6fI6tDceWcaPOomH1GJfHygPXnxMP\nQPXKRS+MFJ84zaXiAOjYqBoD27pfgj6vg+85pt6+sqvVI0sTOJ4SI7obbp4EPKdExW0N80889Nc1\nzEuJtf96LgRpqd0AMKBN2dqO2taPY+2Tw6gaY28sjnXIuVQrNopzWtXmlv7Nrek5burXnE9MO8Mf\n6w8yulPxzD7y8guYPKdQadWuEs2SxME8/dtmqsZEMHVNMref25I5W49Y4w1WPD6E12fu4Jo+zYpF\nhmDjql5N+fyfJDvvOF94afpWj8ejIsLo2qQG87c7O8BcW8TPckynhgD8/dC52vuqGPCU26ouMB5o\nhRHv8ZJSKs2cEWS6O08T/Fjqbmx69jwqRYQxb3sqjWvEuHSHrBUEJTZdxZU4Ovyd39l4MIwfdRbd\nm9WkR3wNjmXkWJXHnqPO6SuKSn6B4sdV+0mcWliG9N4hrQEjvcXH1yUA8PzYs4mNjuD+oa2ty4N1\n4yrx8iWdnC8aIliMzkWtLmg7UAEjyO/6z1Ywf3sq3ZsZtUVu7Bdvp6wt+OvE0aJOFe+dNF7xpH6/\nBDIwbAxVgLdKRSJNifLXxsLlmyrREUSEhzGsfT3OalCVvS+Nsut727ktykVen3sHt7LmcRIRRpxd\nn1pVomlTL452ZrbXHUfS2XbYfQyFN5RStBw/3U5xANxnKg9bLA+1SpHhrHtqGNueD/24VstIvijK\nw91S4qfX9eCJ0WdZPajiKkXy/H8KFx8GtzOCIC9NaOLyfE3p4El1N1BKPW5uzxSRkvd71JQ4d3xj\n/Bttf4wWHBVFlajgcM/1xlW9m7ldhphx/wBrQappGw65LQbkiozsPK76eDnHMrK5bYB9ZuDh7evx\nwLA2XtOA+GMDKI9YPv8pK/fTr3UdGnmx3+w8ctrOlXpg2zo8P9b4ToaFiVP6/mt6N2Pl3uP8vv4g\nn1yXUC4GNaGOx4U/EakhIjXNeh7hDvuaICczJ481ZkW5+dtTOGHjlnhNb+/rxRuST5WYbMWJt6W1\nt64w6nP/7+9dHvs50v+Veazbf5L9x8/wxK+b7I59eG0CZzXwXRGFOlGm8lj770lGvLHQa/9hkwv7\nTL6sM5/f0JMmNT07Zky6tDMbnhmuFUeQ4GloWQ0jKND2P2UZKihAl3cLUo6mZxMTGc64qRv5ff1B\nqleO5GRmoYdV4kjfCgR5Gz0GCxFejJ9jOjbg3u+MXJ4paVmkZ+f5tO7tKgZgbJeGjBsZeKrzUCMy\novAxcdpF9l9PjO7Y0Kd+EeFhVNWG7qDBk7dVfCnKoSkmTmXmkvCCvdujreIAiK/lm+ttz+bBPcG8\ntk8zlruoPuiIrY9/zxeNJISWwLuM7DzCw4RKkfbeWxsPFM66WtWtwq6UdH6+ow/dmwX3Z1JWRPn4\nUH/wh3VsPWTE5tSrGs3chwbqCO9yis+L2iIyCpinlDojIhcppaaWoFwaP+n83CyvfYa3d+8b//dD\n5xImwpncfKuxOVh5bqzvHtyR4UJufmF6C6UUu1LS7ZZPfrurL53N5Hrnv20UVWpZJ5Y5D55bTBKH\nLo62n27Pz+Z4Ro5ddPyUFf8ydU1hgogHhrbR2WzLMUVR+aOAeWaNjydKSB5NAPjiTfTIeW1dRtta\naFGnCvG1YzmrQdWQWlseelY9u/0FO1LtFAfAtaYL8w+rCnN02iZi1LjH8btiWfKzzUfl6KlWt6r/\ndV80ZY+nOI9ewB6lVCqAUupuEXkKuA+4q5Tk0xSBEW84x2lYeP2/nbm4e2O3x0Odm/o1569NhUWl\nLBXkbBl5dn1embGNd+fvBqBd/TiGFyGCWeNMWlYe1WIiOXXGOatBnSrlOxVLRcfTzONDwDqUNfNO\ndQHaAXeXsFyaImKbcmTpuMHMuL8/m589z9pWkRUH+OYyO2XlfqviAJh+b/+SFCnkONdFNoLOz84i\nLSuXcVOd84A1qK6VR3nG04JjhFIqW0QiMKoCngEuUUoViEhAyY5E5AHgZgyvrY3ADUBl4HsgHkgC\nLlVKnTD7uyxRqymk0zOGrePp89vToFoMDaoZnlLLxg0hI6do3i+hSNUY11/1n27vQ9WYSIZPdnYv\n9bS8p3GmqRtX2+V7jjN9ozHre/HCjlzcvRH/HsukdhW9bFWe8TTzWCwic4H1QH/gBVNxnIuhSPxC\nRBoB9wIJZm3zcIwStInAXKVUa2Cuue+tRG2FpaBAWTOY2uYHcixBWr9aJVrqdAxuCyklxNekTT1n\nx4AliYNLWqSQ4wE3NUdu+bIwHf1lPZoQHRFOaxefuaZ84clV9zYR6QfkAEeAn2yqC15cDO8bIyK5\nGDOOgxj1zAeax78A5gOPYVOiFtgrIruAnhgZeyss905Zy58bDlG7SjRH042qwBd1bUS8TjHtEltX\n3Dpx0aSetq+kvO35EXZp6stLjEswUTM2ihv7NufTJa6rJYKzV5am/OLR20optVgptUIptU8p1QPo\nqZRqrpTyO1WJUioZI837vxhp308ppWYB9ZRSlmQ3hwGLe4y7ErVOVJQytJsPnuJPMy/Q0fRsaybT\nSZd1KUsc3DAvAAAgAElEQVSxygXNa8eybNwQp/ZKkeHW9O9X925a2mKFDBanqxv7Nieukv3Y9MMS\nKsqlKRs8eVv1APYrpQ6b+9cCF4vIPuAZpZRf9SZFpAbGbKI5Rnr3H0Xkats+SiklIkUuhqyU+hDD\n0E9CQkLxFVMOEtKyckk9nc3otxbbtburEaGx55/EwVSpFGEd/TqWJm1bP45tz4/wOeBN44zlE61f\nLZoNTw+n+bjp1mPneqjLoSl/eDKYfwAMBRCRAcBE4B4Mj6sPgUv8fM+hwF6LC7CITAXOAY6ISAOl\n1CGz8FSK2d9didoKh8UobuGfxMGcM/HvMpKm/GFbbGlJ4mCXSsIx0lxTNGqZRvCqlSLtYj9qVI4k\nOkJ/tqGEJ+URbjO7uAz4UCn1M/CziKwL4D3/BXqbHltngCHAKoz079dhKKnrgN/M/i5L1Abw/uWS\nHQ7lVp8+vz0Nq8cQX6sySccyg7JUbDCjbRolw839jeWq/zqkS7+pX/MykkhTUnhUHiISoZTKw3jA\n3+rjeR5RSi0XkZ8wkizmAWsxZjJVgB/McrX7gEvN/ptFxFKiNg/7ErUVgt/WJXPflEJ93blxNW7o\na/wY5zx4LgdPZpVpqViNxkJkeBhXu8jYHErZCjQGnpTAd8ACETmKMUNYBCAirYCAcnUrpZ4GnnZo\nzsZQUq76uyxRG4qs23+S/AJF89qx1IyNYueR03aKw7FgU0R4GE19THSo0ZQVtkGsmtDAk6vuBDPO\nowEwSxUmqQnDsH1oioHf1x/kWHo2l3RvzL5jmfznnSUu+12a0JjHR7XXIzhNueLFCzsy/peNtNe1\nT0IOsU1cFkokJCSoVatWee9YhqRn53H2074Fy9tmJ9VoyhM7j5ymVd0qeuBTThCR1UqpBG/9tE9i\nGZB0NIP4xGkuFUdUeJhdTqpG1WP4+Fqv/0eNJmhpXS9OK44QRCfTL2WUUgx8bb5d21c39eRMTj4K\n6NOyFrHREbSoE8ue1AwWPzZI//A0Gk3QoZVHKfHZkr08+8cWp/ZLujemf2vn4Km/HxpYClJpNBqN\nf2jlUYKkZeU6BfZZ2P7CCHLzla6kptFoyiX6yVVCrP33BBe++49d27R7+1E5KoJmNSsTFiZovaHR\naMor+vFVApz76jz2Hcu07r9/dTe6Nq1Bvaq6+I1GowkNtPIoRuZtT+EGm/KmjWvEsPgxXRdCo9GE\nHlp5mGTm5PHl0n1kZudx39A2LusOZOXmszLpON2b1eB0Vp51JpF6OpseE+ZY+zWvHcvM+wcQFaE9\noTUaTWgSssojr0Axb3sKfVvWJjJc2HwwjTb14ogMF+6dso4/1h90e+5bf+/imt7NuL5vPC9N30pG\ndj69W9Ri8pwdTn07NqrGxuTCbC0/3NaHns1rlsg9aTQaTbBQZhHmZinZVUCyUmqMiNSkGGuYRzdo\nrRpc90aRZKoUGUZWrn+1Md66oisXdG7o17kajUYTLPgaYV6WM4/7gK2AJemNpYb5RBFJNPcfc6hh\n3hCYIyJtAsmsO7ZLQ27u14JmtSsTFR5GdESYXSDeyqTj/Pd9o8pt/9a1WbTzKACLHh1Ek5qVWb3v\nBB0aVmXEGwtpUy+OD3UEuEajqWCUycxDRBpj1CmfADxozjy2AwNtikHNV0q1NWcdKKVeMs+diVHJ\n0GMN87Znd1HbNq4lPTuP7LwCaptFajQajUbjnmCfebwBPArE2bR5qmG+zKafxxrmFNYdSQ8LC9te\nbBIHD7WBo2UtRAmi7698o++v/NPWl06lrjxEZAyQopRaLSIDXfUpjhrmoYqIrPJlVFBe0fdXvtH3\nV/4REZ/SkZfFzKMvcIGIjAIqAVVF5Gt0DXONRqMpN5R6IIJSapxSqrFSKh7DEP63UupqjFrl15nd\nHGuYXy4i0SLSnApaw1yj0WiCiWCK85iIrmHuCyG9LIe+v/KOvr/yj0/3GLKVBDUajUZTcuj8GRqN\nRqMpMlp5aDQajabIaOURBIhIkohsFJF1Fjc5EakpIrNFZKf5t4ZN/3EisktEtovIeTbt3c3r7BKR\ntySI6teKSLiIrBWRP839kLg/EakkIitEZL2IbBaRZ832ULm/JiIyT0S2mPd3n9keEvcHICKfikiK\niGyyaQuZ+/MVERlh3tMuM8uHZ5RS+lXGL4xcXrUd2l4BEs3tROBlc7s9sB6IBpoDu4Fw89gKoDcg\nwF/AyLK+N5v7eRD4FvgzlO7PlKWKuR0JLDdlDJX7awB0M7fjgB3mPYTE/ZlyDQC6AZts2kLm/nz8\nDMLNe2kBRJn32N7TOXrmEbyMxUjhgvn3PzbtU5RS2UqpvcAuoKcZG1NVKbVMGd+GL23OKVPMdDSj\ngY9tmkPi/pRBurkbab4UoXN/h5RSa8zt0xj56BoRIvcHoJRaCBx3aA6Z+/ORnsAupdQepVQOMAXj\nXt2ilUdwoDASPq42U6yA53Qt+23OtaRraWRuO7YHA5Z0NLYpi0Pm/swluXUYga2zlVLLCaH7syAi\n8UBXjNlVyN2fA6F+f464uy+3BFOcR0Wmn1IqWUTqArNFZJvtQaX8S9cSDEgJpqMJFpQRd9RFRKoD\nv4jI2Q7Hy/X9AYhIFeBn4H6lVJrtcn4o3J8nQv3+/EXPPIIApVSy+TcF+AVjCnnEnAojvqVrSTa3\nHdvLGks6miSMqfBgsUlHA+X+/qwopU4C84ARhND9iUgkhuL4Rik11WwOmftzQ6jfnyNFTgOllUcZ\nIyKxIhJn2QaGA5soYroWc4qdJiK9TS+Pa23OKTNUMaWjCdb7E5E65owDEYkBhgHbCJ37E+ATYKtS\napLNoZC4Pw+E+v05shJoLSLNRSQK47f6u8czytrKX9FfGN4N683XZuBxs70WMBfYCcwBatqc8ziG\nZ8R2bDw6gAQMxbMbeBszg0CwvICBFHpbhcT9AZ2AtcAGU7anQuz++mHY5DYA68zXqFC5P1Ou74BD\nQC7GWv9NoXR/RfgcRmF40+22PIc8vXR6Eo1Go9EUmTJZtiquoByNRqPRlA1lZfP4HMOoaIulhnlr\njOliIoDY1zAfAbwrIuGlJ6pGo9FoHCkT5aGKISinVATVaDQajUuCKc6jWGuYx8bGdm/Xrl0JiarR\naDShyerVq48qpep46xdMysOKUoHXME9ISFCrVvlUilej0Wg0JiKyz5d+wRTnUdSgHI1Go9GUEcGk\nPHQNc41GoyknlMmylYh8hxEwVltEDgBPo2uYazQaTbmhTJSHUuoKN4eGuOk/AZhQchJpNBqNpigE\n07KVRqPRaMoJWnloNBqNpsho5aHRaDSaIqOVh0aj0WiKjFYeGo1GoykyWnloNBqNpsho5aHRaDSa\nIqOVh0aj0WiKjFYeGo1GoykyWnloNBqNpsho5aHRaDSaIqOVh0aj0WiKjFYeGo2m2Nh/PJOBr87j\nSFpWWYuiKWG08tBoNMXCkl1H6f/KPJKOZfLrWl2vLdTRykOj0RQLf6w/WNYiaEoRrTw0Gk2xoFRZ\nS6ApTcqkGJQ7RKQt8L1NUwvgKaA6cAuQaraPV0pNL2XxNBqNj2g9EvoElfJQSm0HugCISDiQDPwC\n3ABMVkq9VobiaTQaD4iUtQSa0iSYl62GALuVUvvKWhCNRqPR2BPMyuNy4Dub/XtEZIOIfCoiNVyd\nICK3isgqEVmVmprqqotGoykh9MyjYhGUykNEooALgB/Npvcw7B9dgEPA667OU0p9qJRKUEol1KlT\np1Rk1Wg0zoRpRRLyBKXyAEYCa5RSRwCUUkeUUvlKqQLgI6BnmUqn0WhcUKgxwvQ0JOQJWHmISDMR\nGWpux4hIXOBicQU2S1Yi0sDm2IXApmJ4D41GU4wcOJFp3RatPEKegLytROQW4FagJtASaAy8j2Hs\n9veascAw4Dab5ldEpAuGB2CSwzGNRhMELNp51Lqtl61Cn0Bdde/CWEJaDqCU2ikidQO5oFIqA6jl\n0HZNINfUaDSly6bktLIWQVPCBLpsla2UyrHsiEgEOj5Io6nw/LzmQFmLoClhAlUeC0RkPBAjIsMw\nvKP+CFwsjUaj0QQzgSqPRIyUIRsx7BDTgScCFUqj0Wg0wU1ANg8b19mPRKQm0FgpnR5No9FoQp2A\nZh4iMl9EqpqKYzWGEplcPKJpNBqNJlgJdNmqmlIqDbgI+FIp1YsA3HQ1Go1GUz4IVHlEmAF8lwJ/\nFoM8Go1GoykHBKo8ngNmYmS/XSkiLYCdgYul0Wg0mmAmUIP5jxQmL0QptQe4OFChNBpN+UL7yVQ8\nAjWYNxaRX0QkxXz9LCKNi0s4jUZTPsgv0MqjohHostVnwO9AQ/P1h9mm0WgqEPl65lHhCFR51FFK\nfaaUyjNfnwO6kIZGU8EoKHBui0+cxszNh0tfGE2pEKjyOCYiV4tIuPm6GjhWHIJpNJryQ54r7QG8\nMmNbKUuiKS0CVR43YrjpHsao8HcJcEOgQmk0mvKFG92hCWEC9bbah1EuVqPRVGC0zaPi4ZfyEJH/\n4SH1ulLqXn8FEpEk4DSQD+QppRLM9CffA/EYxaAuVUqd8Pc9NBpN8eLO22p3agbxidNImji6lCXS\nlDT+zjxWFasUzgxSSh212U8E5iqlJopIorn/WAnLoNFofKTAy8wjv0ARrssLhhT+Ko/vgTilVKpt\no4jUwZg1FDdjgYHm9hfAfLTy0GiCBm9xHrn5BYSHhZeSNJrSwF+D+VtAfxft/YBAs+oqYI6IrBaR\nW822ekqpQ+b2YaCeqxNF5FYRWSUiq1JTU1110Wg0JYA35fH3tpRSkkRTWvirPLorpaY6NiqlfgEG\nBCYS/ZRSXYCRwF0iYnc9s16Iy2+qUupDpVSCUiqhTh0dbqLRlBbelq2OZ+R4PF4abDhwkpOZZS9H\nqOCv8qhcAtcEQCmVbP5NAX4BegJHzOy9mH/1MEajCSLyykF6kgveXsJlHywrazFCBn8f9Cki0tOx\nUUR6YJSl9QsRiRWROMs2MBzYhJEC5Tqz23XAb/6+h8Y3MrLzyloETTnio4V7ALiiZxO+vaWX0/HY\n6MDsHamnswM638L2IyVhkq2Y+Ks8HgF+EJFnROR88/Us8IN5zF/qAYtFZD2wApimlJoBTASGichO\nYKi5rykBDp/KYuSbi+jw9EwW7zzq/YRyxIYDJ/nin6SyFiMkmbJyPwDREeHUqRLtdPyB79dz6kyu\nX9demXScHhPm8OeGgwHJaOGZ3zczadb2YrlWRcYvbyul1Apz5nEXcL3ZvBnoZS43+YWZ0r2zi/Zj\n6AqFpULvl+Zat5fuOUq/1rXLUBrPZOflU1AAMVG+jWoveHsJAL1a1KRd/aolKVqFJb9AIeLaJXfr\noTR6t6hV5GtuSj4FwMq9xxnTqWFA8gF8bg4gHhzeNuBrVWT8jjA3lcTTxSiLJsgI9mXsga/O59Cp\nrCIHoGVk55eQRJqWdWJpVbeKy2OBpm13p5R8QdcbKX4CzW2lCWEigjyo69CpLL/OU0oRnziNe75b\nW8wSaSLC3T9S/DWqF8dzP9gHQuURrTw0bgnViGDLCPiP9cWzhq4pJDLc/Xcm008njH3HMvwVx0pF\nmXmcOpNLVm7pzKz9Uh4i4vY8EanuvziaYCLYZx7+ctmH2l2zpIgIc/9IefzXTX5d84ul+/wVx0pF\nmXl0fnYWI95YWCrv5e/MY5WIOPnjicjNwJrARNIEC5UidToJTdGo7MF5IdBAQW+BiCV1bnkj6Vhm\nqbyPv8rjXuBDEflIRGqKSFcRWQqcR+AR5ppiZMvBNO76Zg2ns4ruJpmdFzpFGirKskVZcdu5LQAY\n2LauXfuSxMHseGGkdT/Nj++hhdx8//+H+t9f/PjrqrtYRLoDzwC7gXTgJqXUrGKUTVMM/OedJeTk\nF3AkLYuf7jinSOdml9LaaWlQHiKgyzNVK0UChXayZeOGkHzyDI2qx9gp7l/XJnNtn3i/3iM/gIpT\nFWnmUVoEYjC/BLgCeA8jWeFlZt0NTRCRk2/84FbtK3r5k/Iy8/BlVrH5YFopSFJxeXPuTgAsZrL6\n1SrRvVkNwN7FNjrC/0fOD6sO+H2uq2/IM79vLjXjcijir8F8DnA1MFQpNR7oBawDVtpkwtWUc4JF\neew/nklevntZmo+b7vUaWw95Vh4Z2XmcCILkfeWVHPO7EuYlFiM6IjA7mr/Lj65mHp//k6QzDgSA\nv8OAd5RSY5RSewGUUgVKqf8BfYFzi006Tamyet9xu/3svLIflR1Jy6L/K/N46a9tAV0n0k38gcWI\nO3TSAro+P5sPF+72qKg0ngnz4qG3/3hgxtz2T8306zzl5l8a6PeqIuOX8jBTr7tqP6yUuiowkTRl\nxUSHH9J3K4x8RYdPZfHbuuSAr3/B24sZPnlBkc7ZnZIO4DXP1g+r9ns8/vyfW1y29zHTsVgCDl+c\nvo0nf/PPpVTjngs6G2lFXp+9IyAFcsbPZSZt8yh+/F222igiG1y8NorIhuIWUlM6rExytosopbjs\nw6XcN2VdQJ4yABsOnGLHkXSvaSp2HjnNmRzjIXHlx8sB2J2a7vGc170kuhvY1r6+y0VdGwHQv7Vz\n3ReL0tQUkl+guP2r1U6zU19564qu1u3+r8xjRylnt9Wqo/jxd9lqDHC+i5elXRMknN3ISADYqXE1\nv85/deZ29pl+452eKR5nuhenb3VqU0qhlCI7L59hkxdyz3f24ULevKW8ZWw9q4F9IsSr+zQDYM7W\nI6zff9IXsUOaggLF7C1HrIr917XJzN+eQn6B4r35u9l7NJ0Zmw9z5zfFE8Y1fLJ9INuBE5lk5pRc\nGQBPMw/txu0f/iqPR4HGSql9rl7FKaAmMFrXjQOMUf9/3lni8w/0pn7NAXh3/m679jlbjgQs0yeL\n9zq1DZm0gM7PzuKwuXw0Z6vn5MyOP/isXM92ilwH43+Ozf7Yd5Y49c8JEmeB0uKrZfu45ctVzNh0\nGID7v1/H9Z+tZPaWw7w8YxtP/bYZcK+k46IjrN8ZX7GdgfZ7eR7XfLLCT+m9Y1EertKnfLVMP7L8\nwV/lsQN4TUSSROQVEenq9QxNmZBrY/xdt/8ki3yo0TGmUwOa1451eezOb42R54mMHH53kRsq6WgG\nh06dKbKce1IzSMvK49xX51vbdqW4X6qyPHh8zb/1+uwddvsdGnpOyT5l5b8+XTdUOGj+z/Ydt88j\nZVHK/+w+ZrcPhgK3KJO8AuU1nU3dOPs6H/uOZfDg9+usKddX++hOXuBlFvrcH1vo+Iy9Yd0y1njm\ngg5cZ846LSzY7nf9ugqNvwbzN5VSfTA8q44Bn4rINhF5WkTaFKuEmoDIc4jKve2r1V7P6dOyltvK\nb5YR+b1T1nLvd2vZfzyTDxbsJj5xGhsPnGLga/Pp89LfTuf5Uwnup9X2fv22dg/LMlazmp4qIrsn\nrlIk7erH2bV1bFS4tGcZaVcUpm88BEC+w/dlmtnuivcX7KHzs7M4mp5NXkGBV0V++7kt7fYHv76A\nqWuTGfO/xUWSNceLN9ynS/ZyOst+hm1RHmEixEbbx0ZHBRB7EqwcPGk/gNuVks59U9YWaw33QOuN\n71NKvayU6ooRMPgfwHlB20dEpImIzBORLSKyWUTuM9ufEZFkEVlnvkYFIndFIs+PqNwrejR1aTy3\n8Owfm60zmBOZOVZ3x/Pftn8IzN+ewszNxjKIPwbS9xfYL5lZRqiANbjr6t72o0hX2CquRtVjrNuO\nyuPkmRw+uS6hyHKGAvuPGw+b12fvsC4deuPXtYYHXkpatk8zjxv7NefWAS28XveGz1bw4Pfr3B6/\n7avVxCdO42i67wMSy7JVmMDdg1vZHWvqYgCSm1/ArpTyW7L2nIl/W5d2Z2w6xNBJC/ht3UE+XZJU\nbO8RkPIQkQizBO03wF/AduCiAC6ZBzyklGoP9AbuEpH25rHJSqku5st7VFgFZ9+xDD5cuNtjPqDp\nGw/x3Yp/WbAjlRV7C71owsKES7o3dnveZzZfQEt1Pldc/9lKbvtqNWPfWWL34Af8iqVISSt8WGSY\n3lix0eFUr2ykxhj7zhIOnjzDuKkb7GwWe2xmLAsfHcSuCUaupQY2igSgbb04hpxVj1Z1qzD0LPsc\nTRWJO74pnJ1GeajPYakHnldQgFIQ7iGjroXxo87y2mfe9lSmrk1mwQ7Xy0mW9u+W+760aFEeIkLl\nKPuZx+E0Z2X54vStDJ20kOSTRV+CDRYsv/3bvy50cnCM8F+977jf5YH9ddUdJiKfAgeAW4BpQEul\n1OVKqd/8kgRQSh1SSq0xt09jzGIa+Xu9ikpOXgHnvjqfF6dvczuKPHwqizu/WcO4qRu57tMVXPrB\nUqBwNN68lmubhz+s33/SKRhrztaiG94nmF5aT/+2iQvMpY5th09zZc+m1vc5b/JCvluxn+V7j1nP\nGzd1o3U7PEysBYv+66AgLUb62lWiSDtTcp4/wc7afwu9zzwtW1lYY9oq/t4WuDNFis2DfMkuz/a5\nE5meH3q2ThXbDxuKztVs5bd1zrY7ywDpeHrZZh0Y879FLh1MfCHLRZCvrfLIyy/g4veWcv1n/jkq\n+DvzGAf8A5yllLpAKfWtUirwii02iEg80BVYbjbdY8aSfCoiNdycc6uIrBKRVamp/hvBsnLz+WrZ\nvnLpwpebX0CbJ/6y7h86dcZpTfdMTr5drXJbtpk/shqxUdSMjfJbjrFve17HdrRn+MrprFy+WLqP\nY2ZkeLv6cdSrWqnwuFlw6JpPVpCVm8/4Xzay56jx1bwsoYndtRzXvjub7sxVK0X6PRorK1YmHWfv\nUf9+go4G6Lb14tz0NDh06gyfLSl8oD3zhxGAeczH9C7PXtDB7bGeLxZ+Ly2xPnHREVSJds7h+umS\nvaRn55GZk+cyBsl21m2pWz5zs7OCa+2mbC7AtyvK1hNrU3Iaz/+5hazcfDvF6gtZOfm84BAca5tn\nzPJv33DAflXAV/w1mA9WSn2slCp6tj0fEJEqwM/A/UqpNIzkiy2ALsAh4HU3cn2olEpQSiXUqeMc\n/OUrr8zYzpO/bnL5RQt27v7W3g8/LSuPOIcf3pdLk3y6lmP9hc+u7+GzHOvdfCEfG9HOetz2oeWp\nAt17V3Wzbnd0iDXp3KQ69apGO54CwI+rD/CtzdLGs2PtH1qWB1JcdAR3DWrJN7f0BqBu1WhSThf+\nUJVSLN9zDKUUK/Ye9yu9fUnz3/eXMui1+X6de9qhwt92L/ap4ZMX8uwfzhH7fVvW9un9ru3j3U4F\nRr4xpRSns/M4t00dJxsVQPfnZ9P+qZkuY5As6XVWJR0nxqxN07CaMdBY9cRQVowfAsDOlHT+2V04\ny7FdUg2WgNE7v1ljp1hd4TgIyMzJ52OHWYvtgFiZoZP+1pYPOjcDEYnEUBzfKKWmAiiljiil8pVS\nBcBHQM+SlOFYhjG1LcuMmxnZeS6n2F8uTWJl0nGUUmTl5pPwwhx+X3+QAycyOXTqjEuFl+EQ25Hr\nwd7QpGaM22OD2gVuB7hjoOFxk3o6m5dnGktZxzNyyM1X9GtVm57x9omZa8ZGMbJjA+51MHJaiIkM\nZ3j7+i6POf6YHItbxUZHMH5UO3656xweOa+dVZk0qBbDicxcfl2bzM1frOT39Qe57MNlTJyxjUs/\nWMqQ151TrBQUKK9R8MFKUR8ejp5MFgb7aCcSEZ4+vz0fXNOduwe5/r8CHM/MYbG5dDVt4yFm3O9c\nKsgxeefafwvHs1m5BRQUKC55fymzzPgki82ldpVo6trMWK/8aLl122JP80R2Xj6/rk32e3UiJ6/A\nq93P9v/y9zZjSTU+cZrbolqOgZCOv3uw/7wCXVgJKuUhxpzqE2CrUmqSTXsDm24XAiWafMjyP/OS\nILTY2HjglNOUdOSbi0h4YQ4nM3PslNhTv23mv+8vpfm46bR7cgZH07O597u19Ht5nksXWTB+RBuf\nGc7oTsbH+NqsHS77AUy6tIt1e/yodtbt68+JB+ClizoC8O0tvVyOBIvCBwv2MG97Ct2enw3A4l1H\n+fj6BH6+o4+1j+WHsv+Ea8NlTGQ4YWFC0sTRTsdsfzyD3Si+Wwe0pFVd+/uwLIPd//065mxN4fuV\nxuhzphlAl+LC7bjF+OkMeX1BufTQ8RYQOahtHcZ0auDkauuIu8/YFTf0bc55Herz8Hlt3faZvz3V\nafnwXZtZqCtutXFFz8rNd1r3r2Y6V7giPnEam5JPke4wEzvlwrYyafYO7v9+nfWhbktWbr7XVD5t\nnvjLmnrHHe7+L5bvoyOOY4BMF0rwuxWFM3FbJxl/CCrlgZGV9xpgsINb7is2ebMGAQ+UpBClnUTt\n/LcX0/PFudz4+Upr279m8rguz83m4vf+ATzPGLwRVymSty73HssZV6lwievWAS15xPxxt6hjGNCv\n6NmUpImjOadlbX65s6+1ry+K1rJk8J8uDa1tN3xWeM9Dz6pL1UqRdG9Wk7VPDrM79/Ie9vYKC9Ee\nSuW+MqMw35WrH7k7HF1OLQFylvKe3ZpW52Rmjssf99p/TzLglXkBl1wtCkUZ/R5Jy3JKTOgte3Ld\nuEq8fWU3Eke289jPXeZib9zmwX3XcVY0qmMDkiaOdnJ2AMPD0NYtOzsvn9w8+/NjHL4vjnawMf9b\nTN+J9oOwzs/NcoqbOGAOZlzNwi55/x+7ZbQ/1h8kPnGa3VIoeH94u/u/vDzDORPwvO0pfO8Q2Dp1\njbNd8YDNIOzaTwOL6A8q5aGUWqyUEqVUJ1u3XKXUNUqpjmb7BUop7y4gAWB5KHirPVDcuXj+3pbC\noVNnWJVk/6XafDCNtKxcthShoNF/ujTk7SvtlYUv0dg1K9sbyW/u35zxo9pxhenRZEuMTb3q6ff2\nJ2niaOY8OMBqeLb2M3+w391q2BQmX9YFV9i+R43YKL6+qRdzHzIy/PdqUcvlObY1s9c9NYy/HzqX\nm4uYJsMRSwZYdxxJy6bLc7N58AfnWIRHftrAv8czeexnw104PnEaA1+dF5A83kizeYB5q1vS68W5\n9O0BQvMAABb8SURBVH+lUJ6s3Hyrkn3nSvtRfaVI4/EQGeH+e/PljYGvII8bdRZ7XxrFnAedqzns\ndpNl4NX/dna+jo1XHRgz2wU77R1nHBXcy5d08knGhaZ78JdLk4hPnMaGA4ZHmgg8/stGjtksMW9K\ntv8fWJwLLB5fvlKUFDk3fLaSJ83AVstvwp29prgcgYJKeQQLlnXB6Ej3H8+OI6dp/9RM4hOnBfRe\njv/IPi/9zSXvL3Xq1+mZWS5zMLnjjcu7MqZTQ1Y+PpQtz51nbf8ncbB1O65SBMPa17N7WDoqzOiI\ncG4d0NLrqNJi8G5VN453r+5Ov1a1WfzYIHZOGMmixwbx0kUdaWa6/4oIU+90Lok75Kx6dvv9Wtem\nZZ1CT5itz42gRe1Y6lWNJmniaJImjraTq3rlKFrUqcLjo51jCcZ0auDU5o6wMLHaZlxh8f3/c8Mh\n4hOncdXHy5z6nMzM4eQZY/ZhmbG4I79A8cvaA17Tbrij87OFo9yRby7y6RyL0f+DBXus7riOMQA3\n9DWUsG3kvePsY0CbOjSuEeNkqyoqImLG19h/B976excAzWo5B/I5zhosM0QLP64+wL3frQ1ILguJ\nUzfy27pka+YBS1Dl8r3H+Wb5v0yYvpUdR07b2TEs3mI7TQX4nOlkYLuC8OnivW5tTp6Ksdme42gb\n9RSjBVjzlzny4PfrmLLC99iZCqs8mo+bxkM/rHdqLyhQ1pG/ZUll+sZDZJjroEopPl+y1ykrqD+k\nZ+d5TQDoiZ0TRnJD33jr/l2DWhIVHmZnM6gTF20XFNWwegxf3WSMFj+6NoGPrk3ghQvPth73pDBd\nYQkis32PRtVj+PrmXjSuUZnI8DBqV4l2mrl0a1qDHS+MtO7f0t/7bCEmKpy/Hx7I8vFDPfYTF2to\nntxDXfHw8Lb8eHsfkiaOpldzzw/GJbuOObWtTDrBk78WmuaUUqxMch2Q9dXSJB74fj0XvOPavfng\nyTNFGi0m+eCyu2yP8R2fPKfQ/mX7Do2qx/DoeW2Zfm9/LrV5SN/Sv3CJ6cfbje/Z4scG88PtfSgO\nhrgxutva4iy8fEknZj/gbEQvKr/e1dd7J+C+Kc4zTcu/ZeqaZIZPXkirxwvd5A+nZTFs0gLr0pZF\nifxoU073uT+30HL8dLt8cAkvzGbEGwvdBkkCTJi21aqoHJVPrVjX3ocWlpqeg/1b23vHTV2bTKLD\n7M0Tzs7TIcLG5FPEJ05zaUgF45/+85oDXH9OPB8v3sMbl3VBRGgx3j54/cEf1jF1TTJjuzTkzcu7\nMnPzYatfe1FZuCOVk2dyGd6+HlsOpXHRu//4dZ1ZDwxgwfZUIsPDePr8Djw4rA3ZeQXUrhLNI+d5\nXpcGo4aF7edStVIkjarHkHzyjMeIYldsevY8dqacpmF1915a7rCNP7ljoHuvG3/YOWEkG5NP0a2p\ny5Agr4SHCT3M0fT3txkPxrz8An5dd5CHf3QedLjC1vPt2xX/8vgvhjJx/E4u3WMon03JaczZcoSh\n7QtH38v3HOOyD5e5PM8du1PTiXeT2NJCZk6e07JIRLhwTe9mfLVsH31b1UJEaO+QQNJ26bNHgLMN\nV1zRsyldm1andd04Wtr8Fm1tcba0rhfHtudH0O7JGV6v/fBw12n3ujSpzqUJjZ1qpL99ZVfu/tbz\nzMWTi/nCHalWhWHhpb+28sGCPU59X5q+zVrz5Gh6DkfTc3jiV/d+QZ8u2UvyyUw+uCbByTBexc1n\ndWPf5ny6ZC9fLt3Hl0sL41fqxHlWNu4IWeVhwbKsdF2fZtw+sCUNqtk/5Cz5mB4c1sZlNO3UNUb+\nnt/WHeTNy7tap6u25OYX+GQstBioLu7mPK2sHBXu0jvCFW3qxdHGJpArrlIkgfk9wdQ7z2H9/pNe\ny4g6EhURRoeG/tUKAdj+wgjSs/ICCkh0RWR4mN+Kwx0R4WFc0r0xufkFvDt/l8vvgjssisPCqTO5\nbDxwin6ta3PwZKEh9YdV++2Uh20qGDBsFLtS0jm7kfvP/KYvVnlVNIk/b2RgG/tRfrWYSJ65oAN1\n46K5tk+823PnPTzQOhMvCdrVNxTWmieHWT3xXOWfsuDogg3QuEaMnXEYYHQn97asVy7pbKc8fr+7\nL50aV+fjRXtZ56Hei+1D2JGnf7dPrjmgTR2XigOwBnie8fEZAMbgxNWyuSt9Nqx9PZ4ccxafLtnr\ndCz1dLZfzjghrzwsfLF0H18s3cdvd/V1WRhpwY5UO+8cV+TlF1hTZICRYjrldDaDXpvP5zf0ZOik\nBbx6SScu6taYdHOquis1nXnbUrj2nMLAqJ9deEEseGQQPSbM8ff2AqZe1UoM7+A6XqIkiY4IJ7qK\nZ8eEYOOKnk25omdTzuTkc9ZT3ke8jrwyY5u1Tsp3t/Rmo03eL0uZ1QMnMun3sr2hPTsvn+f+3MK3\ny//lsxt6MKhtXbc/+rfm7uTeIa3t2mxtKmdy8+n8nH1gnUXZ3uNwniPu0vUXNzVjo6z2OlcKwpZV\nTwzlWHoOjWrEUCU6guSTZ6xeU8vGDaF+tUoez7clLjqCTo2rA4ZLumPd9KiIML/qvSz0sAy1MfkU\nOXkFTkXQHGlXP86aBcIdrpZtP7ymu8t2C46553xBymMKDl+IbtBaNbjuDZfHxnRqwJ8biu6w1alx\nNbtQ/sSR7ax1v8/rUM/viPTr+jTj2bGFdoevl+3jlRnbePGijtz97Vo2PDOc/HxF1+dn8/7V3Rlx\nduk/5DWuSTqaQUZOHklHMxnUrg5vzt3J5T2aMm9bCs/9uYUBbep4fGi4YtKlnXnQhT1uyq29ee6P\nLWwxPaoeG9GOX9YeYMcR1x5Jb13RlQs6N+SfXUdpUrMydatG0/YJ18puz4ujijzrDHYKChQirh+m\nrsgvUHzxTxIXdWtEdRuvQ9vR/fXnxPPMBR3Iys33aamsuNnz4iinpXVHRnWsz+v/7UKX52bx5z39\naG2zSuGLg8++l8esVkp5TS9dIZVHcTD3oXM5mZnDxe85e0YVlUWPDqKJw7RcKeXzl14T3Gw7nMaI\nNxZRr2o0R9KKXtfEFy7q1ohlu4/Rsm4Vu4JfPeJreEyvD0Zup9ku3GQ1BgUFiv0nMq3eghYufX8p\nK5Jcx2pYbIgAz4/tYHWjtWXF+CEkHcvkpi9Wuo3adyRp4mjmbDnC+F82ugxWBWOQ0duNa3taVi43\nf7GKrk2rUykinMhwcQoarvDKo1m7jmrk458zY7NrtzRPLH5sELn5ipqxUXZukBYeHdGWOwe2QilF\n83Hes8PXr1rJmvbZ0Qj30LA2XpcJNKGFu9HfuJHtnLIPg+Gmus+Lu++XN/ZkQJs67EpJZ+gk5/Qp\ntnRuUp31+0/y4LA2TktbGt/Jys3nwIlMhk4yPC9v7Nucq3s3pUG1GPKVYsAr87i4WyMeH21UlZi5\n+TD7j2eSdCyDmrHRPDis0IDv7jsx+4EBNKweQ4enZ/LuVd0Y1bHQ5Xz/8UxmbTnCqTO5nMzM4cul\n+zi3TR2+KELsjeMM6pyWtfju1j4VW3kkJCSoFStW8sK0rVzZqymNa8RYP6Q3L+9CTl4Bv68/SExk\nOJsPptnl7bc1Np7KzOWf3UeZPGcHO478v70zj/aqquL45xsOqAiBKAvFVAqHpyIiCpWkIoqoma0m\nlEzNYbmyEm1pqGnWslUOyykrcylFgWakYjnjkBYo+mRWBkVtKaOKIJQD8nZ/nP3g+uP9JnzP9373\n7c9ad7372/f8ztn7/uDuu8+wzxrOH7YHZ2fy8by3dh0jbn6aGa+tpMtWaXe6W085kInTF/GTiXO4\n6Og9OWNwbw6+4nFGDe3DNwbszJ6XPMB7axvo/5lPc9f3KpsmGOSHxSvf5fW332X+0neYv2w1Fx9d\nxwtLVnHALt244sF5/M7HQ347sj/rGoxj9u3JWeOeW5+f6cSBn2H7Tlty/aMvAmlxZLabZe26Bn5x\n39z1mWQLOefwPpx7RGz42Vysfm8t85au/lizz95a8z4HXL5hzHPqRYfTvdOWFW+z/HH4cF0D981e\nwqDe29Gjc0ckhfOor6//iMwyG8JkeXTuMk4bW0/fXl04Y3BvvlxmhXFzMGfRKvbesXN0TQUbMfO1\nlfxj5mJ+cmzdelnjfuFTX1nBsAonNjQ0GP9csHz9yuvGLrOnLhyy0azDoG3w/OJV7Nxtazp3LJ6D\nq6UJ59GE8yiGmVH/n7cZsEvXeJgHQdCuqdR5tJupuqWQ1CILnoIgCPJKu01PEgRBEGw64TyCIAiC\nqgnnEQRBEFRNOI8gCIKgamrGeUg6StJ8SS9JGt3a+gRBELRnasJ5SOoA/AYYDtQBJ0iqK/2tIAiC\noKWoCecBHAS8ZGYvm9kHwF+Ar7SyTkEQBO2WWlnnsROQ3ZD3dWBgYSFJZwJn+sc1kkrnWK9NugNv\nli1Vu4R9tU3YV/vsUUmhWnEeFWFmNwM3t7YeLYmk+kpWf9YqYV9tE/bVPpIqSs1RK91Wi4Dsbve9\nXBYEQRC0ArXiPJ4F+kjaTdIWwAjg762sUxAEQbulJrqtzOxDSd8HHgI6AGPMbOPdVdoHue6WI+yr\ndcK+2qciG3ObVTcIgiBoOWql2yoIgiBoQ4TzCIIgCKomnEcbQNKrkmZLmtE4TU5SN0mTJL3of7tm\nyl/oaVrmSxqWkR/g9bwk6Qa1oZ2tJHWQNF3Svf45F/ZJ6ijpGUkzJT0v6Wcuz4t9O0t6XNILbt85\nLs+FfQCSxkhaLmlORpYb+yql6hRQZhZHKx/Aq0D3AtmVwGg/Hw1c4ed1wExgS2A3YCHQwa89AwwC\nBDwADG9t2zL2nAfcBtybJ/tcl05+vjkw1XXMi309gf5+vi2wwG3IhX2u15eA/sCcjCw39lV4Dzq4\nLb2BLdzGulLficij7fIVYKyfjwWOz8j/Ymbvm9krwEvAQZJ6Ap3N7GlL/xr+lPlOqyKpF3AMcEtG\nnAv7LLHGP27uh5Ef+5aY2TQ/Xw3MJWV8yIV9AGb2JLCiQJwb+yqk6hRQ4TzaBgY8Iuk5T7EC0MPM\nlvj5UqCHnzeVqmUnP15vQt4WuA64AGjIyHJjn3fJzQCWA5PMbCo5sq8RSbsC+5Oiq9zZV0De7Suk\nmF1FqYl1Hu2Ag81skaQdgEmS5mUvmplJqsk51ZKOBZab2XOSDm2qTC3bB2Bm64B+kj4N3C1pn4Lr\nNW0fgKROwJ3AKDN7J9udnwf7SpF3+zaViDzaAGa2yP8uB+4mhZDLPBTG/y734sVStSzy80J5a/NF\n4DhJr5JC4SGSxpEf+9ZjZiuBx4GjyJF9kjYnOY7xZnaXi3NjXxHybl8hVaeACufRykjaRtK2jefA\nkcAcUvqVk73YycA9fv53YISkLSXtBvQBnvEQ+x1Jg3yWx3cy32k1zOxCM+tlZruS0so8ZmbfJif2\nSdreIw4kbQUcAcwjP/YJuBWYa2bXZC7lwr4S5N2+QqpPAdXao/zt/SDNbpjpx/PAxS7fDngUeBF4\nBOiW+c7FpJkR88nM6AAGkBzPQuBGPINAWzmAQ9kw2yoX9gF9genALNft0pzZdzBpTG4WMMOPo/Ni\nn+t1O7AEWEvq6z8tT/ZVcR+OJs2mW9j4HCp1RHqSIAiCoGqi2yoIgiComnAeQRAEQdWE8wiCIAiq\nJpxHEARBUDXhPIIgCIKqCecRIGk7pYy+MyQtlbQo83mLTahvqKSJfv5VSec3k57jJL2ilMF2gaSx\nknZsjrqLtLeXpCf8PsyV9DuXD5R0bQu2O1SSSTolIxvgslGbUN8QSYOKXDtd0htu4zxJP/wYqreE\nXtOVMts+WKxs0DpEepIAM3sL6Acg6TJgjZldnS3jC59kZg0b11Cy7rubS0/nXDObKOlTpEy9j0na\n18zWNnM7kObqX2lm97n9+wBYyl01tQXayzIb+BbwR/98Amkt0KYwBHgTeLrI9fFmNkrS9sB8SRNs\nQ16nlqQivSA5VOAeSYPNbMEnoFtQhog8gqJI+pzSPg7jSQsYe0q6WVK90t4Ol2bKHqO0F8A0Mtk4\n/Q3yOj8fJ+l6SVMkvSzpqy7vIOkmf/N92N8yS2YkNbMGd3ArSKvyaUo3SUdK+ltGn+GSJkjaTNKf\nlfZfmFPkjbsnnuzOErO9jmxkdbmkWz1CeVnS2Zm2TpU0yyOlP7ish6S7XM9nSrxNvwx0ltTdHeUR\nwEOZuvtLmur13ympi8vP9d9slt/vzwKnA+d7dPGFEvf0DW+3MS1Hk7pK2tajvll+HJ+5t09Jmibp\nDqWMCUh6XdJlHkXMkrR7NXq5bo+QVrqf4XWeJelZv7cTJG0lqYv/Bpt5ma7Zz0HzEs4jKMeewLVm\nVmcpB9doMxsA7AccIalO0tbA70krVA8ASnUl7UDKd3U88EuXfYOUwbMOOAX4fBX6TXMdaUo30urg\nvpK28zKnAmNcz+5mtq+Z7UNKoV3INcCTku6XNKrxAd0Eu5Me7oOAn7sz3A/4MXCome0H/MjL3kCK\nZgYA3+SjaeoLuRP4OjCYFOlko6txwHlm1pe00vkSl18A9HP5981sobdxlZn1M7MpxRpTyprbgbRK\nupSulwFveBv7AU8oJfUcDRxuZv1JK9LPyVS/zMz29zrOq0avDNnfeoKZHej3diFwipmtAiaTcotB\nitYmmNmHFdQdVEk4j6AcC82sPvP5BI8upgF7kR74dcACM1toKWXB+BL1TfS3+FlsSPl8MPBXjyYW\nA09UoV92t7aNdPNutvHAiZK6kZzGw6R9GPZQ2vFtGLCqsGIzu8Vt+xtwOPCUmh4DutfMPrCU2HIF\nsD2pS+YOM1vhdTXuFzEUuEkphftEoKtSTqymuIP00D6BlEIjGZwcYUczm+yisaQNjSBFiOMkjeSj\nzqYUIyXNJqXi+LWl/RxK6ToU+I3bZWb2NvAF0r2a4uVHArtm2mhMqPhcgbwasr91X0n/cr1HAHu7\n/BbSCwL+9w+b2FZQhgjngnL8t/FEUh/S2+RBZrZSKTtuxyrrez9z3hzbdPYD7iuj2xjSWzykB/o6\n4C1JfYHhwNnA14AzKcCjrTHAGKVU+XuVsWkdpf9fyXX8oESZ9W1LEnAI8D2SQyrHMC9/HHCR21iO\nxjGPgcADku51R9ikrmp6d1UBD5rZSUXaaLxH5e5PKfYnbUYFKVIcbmZzJJ1Oivowsyck3SjpMGCt\nmc0rUlfwMYnII6iGzsBqUvbQnqQHFcALbMjIKdKbcjVMBr6uRE82vEUXxcueS0pgN6mEbpjZa6SB\n2dH4ALTS4LDMbAJwKWkb0sI2jsr0n+8IdAUWV2jTY8C3PNqh8S+pGy07LtKvTD2XAD/OTlTwCQ7v\nZsYJTiJ1HXUAepnZY6Tuq+7A1qT7sm05hX0iwO3AD8roOqlR7r9DV2AKcIik3i7fxh16KSrSy+s7\nDPguadwDYBtgqVK6+BMLio8jRZsRdbQg4TyCaphGchTzSG9+kwHM7H/AWaR9m+tJGUqr4a+k/RLm\nkh7u02miG8m5VtJMUj9/P2CIz7RqUrcMtwGvZGbq7Ewaz5hBeshc1ERbw4Hnvb37SRshvVGJQWY2\nk7QPdmMbV/mls4Ev+sDxC/gAcIl6/m1mTaXGPol0L2aRuosuJ73R3+ayacDVlraOvQf4pg9YlxyY\nBn4FnO6D3cV0/RnQQ9IcUpbdwWa2jJSN9g6/X1NIY0GlKKfXSB9MX0AaPzrezOb7tUtJacQnk373\nLOOBLqRuv6CFiKy6QZtAUiczW+MRwVRgYKUP6grrvwl4yszGli0c1DSSRgDDzOzUsoWDTSbGPIK2\nwgOSOgObAz9tZscxA3gb+MQWwAWtg9JCzqFsmHEVtBAReQRBEARVE2MeQRAEQdWE8wiCIAiqJpxH\nEARBUDXhPIIgCIKqCecRBEEQVM3/AcSV3UL+qHcXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18566203fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some of the key data\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_data = all_data.SP_Close\n",
    "plot_data_VIX = all_data.Vix_Close\n",
    "\n",
    "\n",
    "f, axes = plt.subplots(2, 1)\n",
    "\n",
    "axes[0].axis([5962,0,400,2200])\n",
    "axes[0].plot(plot_data)\n",
    "axes[0].set_ylabel('S&P500 Close')\n",
    "axes[0].set_yticks([400,800,1200,1600,2000,2400])\n",
    "\n",
    "axes[1].axis([5962,0,0,100])\n",
    "axes[1].plot(plot_data_VIX)\n",
    "axes[1].set_ylabel('VIX Close')\n",
    "plt.xlabel('Trading Days Since Most Recent Day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1856648abe0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnXeYFeXVwH9nCyxtkS7SmyIqqCBiB7FgiT2KMbYYSaIm\ntkSxRI0J0WjUmESNfDaMvWssqIgVBKRIkyJNivS2tIUt5/tj5u7O3p1779y7c7fcPb/nuc+deect\nZy7snDnvOe95RVUxDMMwjDDIqmkBDMMwjMzBlIphGIYRGqZUDMMwjNAwpWIYhmGEhikVwzAMIzRM\nqRiGYRihkTalIiJPicg6EZnjKbtfROaLyCwReVNE9vJcu0VEFonIAhE52VPeX0Rmu9f+KSLiljcU\nkZfd8ski0jVd92IYhmEEI52WyjPAsKiyj4EDVbUvsBC4BUBE+gDDgQPcNo+KSLbb5jHgSqCX+4n0\neQWwWVV7Ag8Bf0vbnRiGYRiBSJtSUdUvgE1RZR+parF7Ogno6B6fCbykqrtVdSmwCBgoIu2BfFWd\npM4qzWeBszxtxrjHrwFDI1aMYRiGUTPk1ODYvwBedo874CiZCCvdsiL3OLo80mYFgKoWi8hWoBWw\nIXogERkBjABo0qRJ/969e4d3F4ZhGPWAadOmbVDVNonq1YhSEZHbgGLg+eoYT1VHA6MBBgwYoFOn\nTq2OYQ3DMDIGEfkhSL1qj/4SkcuA04GLtDzx2Cqgk6daR7dsFeVTZN7yCm1EJAdoDmxMm+CGYRhG\nQqpVqYjIMOAm4AxV3em59A4w3I3o6objkJ+iqquBAhEZ5PpLLgHe9rS51D0+Dxivlh3TMAyjRknb\n9JeIvAgMBlqLyErgTpxor4bAx65PfZKq/lpV54rIK8B3ONNiV6tqidvVVTiRZI2AD9wPwJPAf0Vk\nEU5AwPB03YthGIYRDKlvL/fmUzEMw0geEZmmqgMS1bMV9YZhGEZomFIxDMMwQsOUimEYhhEaplQM\nw0grq7bs4qO5a2paDKOaMKViGEZa+cm/vmLEf6fVtBhGNWFKxTCMtLJpx56aFsGoRkypGIZhGKFh\nSsUwDMMIDVMqhmEYRmiYUjEMwzBCw5SKYRiGERqmVAzDMIzQMKViGIZhhIYpFcMwDCM0TKkYhmEY\noWFKxTAMwwgNUyqGYRhGaJhSMQzDMELDlIphGNVC2FuXF5WUsmDNtlD7NKqOKRXDMOoko96bx8n/\n+IIVm3bWtCiGB1MqhmFUCyEbKkz9YRMAW3YWhduxUSVMqRiGYRihYUrFMIxqIWRDxailmFIxDKNO\no6auahWmVAzDqBbCjv4yaiemVAzDMIzQMKViGIZhhEbalIqIPCUi60RkjqespYh8LCLfu98tPNdu\nEZFFIrJARE72lPcXkdnutX+KiLjlDUXkZbd8soh0Tde9GIZRdWzyq36QTkvlGWBYVNlI4BNV7QV8\n4p4jIn2A4cABbptHRSTbbfMYcCXQy/1E+rwC2KyqPYGHgL+l7U4Mw0iJtQWFaetbkLT1baRO2pSK\nqn4BbIoqPhMY4x6PAc7ylL+kqrtVdSmwCBgoIu2BfFWdpI6X79moNpG+XgOGRqwYwzBqB7/677Sy\nY/PT1w+q26fSTlVXu8drgHbucQdghafeSresg3scXV6hjaoWA1uBVukR2zCMVNi6y1a71zdqzFHv\nWh7V8u4iIiNEZKqITF2/fn11DGkYBhXDiG09Sf2gupXKWndKC/d7nVu+CujkqdfRLVvlHkeXV2gj\nIjlAc2Cj36CqOlpVB6jqgDZt2oR0K4ZhGEY01a1U3gEudY8vBd72lA93I7q64Tjkp7hTZQUiMsj1\nl1wS1SbS13nAeLXVVYZRq/D+QdpfZ/0gJ0glEWkLHAXsA+wC5gBTVbU0TpsXgcFAaxFZCdwJ3Au8\nIiJXAD8A5wOo6lwReQX4DigGrlbVErerq3AiyRoBH7gfgCeB/4rIIpyAgOHBbtkwDMNIF3GViogM\nwQn7bQnMwJmuysOJwOohIq8BD6hqQXRbVb0wRrdD/QpVdRQwyqd8KnCgT3kh8NN48huGkfmYBVS7\nSGSpnApcqarLoy+4fozTgROB19Mgm2EYdRx74Nc/4ioVVf1DnGvFwFuhS2QYRkZiCqZ+EMhRLyLX\niki+ODwpItNF5KR0C2cYRt3GwojrH0Gjv37h+k1OAloAF+M43Q3DMAJx1iMTuP2t2TUthpFmgiqV\nSPqTU4H/qupcT5lhGEZCFqzdxnOTKrlnjQwjqFKZJiIf4SiVD0WkGRAznNgwDAPMj1IfCbROBScj\n8MHAElXdKSKtgMvTJ5ZhGJlAOpWKpY+tnQRSKqpaKiJrgT5uKLFhGIZhVCLoivq/ARfgrHiPrHRX\n4Is0yWUYhmHUQYJaHWcB+6nq7nQKYxhG/aO0VNlTUkpebnbiykatJ6hSWQLkAqZUDMMIhXmrC3h1\n6kr2lJTw3KTlLPnrqWRlmaOkrhNUqewEvhWRT/AoFlX9XVqkMgwjI4iXOPyiJyazacee8rqpjpFi\nOyM9BFUq77gfwzCMwMR74JtNkpkEjf4aIyINgH3dogWqavuEGoaREsUlpWz0WClG5hA0+mswMAZY\nhvOC0UlELlVVi/4yDCMmsWa/3p212qeuYvZL3Sfo9NcDwEmqugBARPYFXgT6p0swwzAylz3FlpAj\nUwmapiU3olAAVHUhTjSYYRhG0vhlLzaHe2YQ1FKZKiJPAM+55xcBU9MjkmEYmUKs1PeWEyxzCapU\nfgNcDURCiL8EHk2LRIZhZAzJKI9kFY15X2onQaO/dgMPuh/DMIwq4ac/bEOvzCCuUhGRV1T1fBGZ\njc//A1XtmzbJDMMwjDpHIkvlWvf79HQLYhhG5hHL9vCb6jI/S2YQV6mo6mr3+4fqEccwjPqATXVl\nLommv7bh/7IhgKpqflqkMgwjI6gO6yNefjGj+klkqTSrLkEMw8hE0h9S/Pa3P3JI5xbhdWhUibiL\nH0WkZbxPdQlpGEZm4Rv9laKieWbisqqIYoRMIkf9NJx/f7+QcAW6hy6RYRgZzw8bdlQqW7VlJz3b\n2uRIXSfR9Fe36hLEMIzMI5b18cRXSyuVnfXIROb86eQ0S2Skm0TTX73d70P9PqkOKiLXi8hcEZkj\nIi+KSJ47pfaxiHzvfrfw1L9FRBaJyAIROdlT3l9EZrvX/ikitsjWMOoo23cXB667Y3cxM1duTaM0\nRqokmv66ARiBk6U4GgWOT3ZAEemAk+6lj6ruEpFXgOFAH+ATVb1XREYCI4GbRaSPe/0AYB9gnIjs\nq6olwGPAlcBk4H1gGPBBsjIZhpEe0hWX9cGcNWnq2agqiaa/RrjfQ9IwbiMRKQIaAz8CtwCD3etj\ngM+Am4EzgZfcVDFLRWQRMFBElgH5qjoJQESeBc7ClIph1Bos3Lf+EXSTrmzgNKCrt42qJp0LTFVX\nicjfgeXALuAjVf1IRNpFFlsCa4B27nEHYJKni5VuWZF7HF3uJ/8IHIuLzp07JyuyYRi1DFNWtZeg\n+6n8D7gMaAU083ySxvWVnAl0w5nOaiIiP/fWUed/TGj/a1R1tKoOUNUBbdq0CatbwzAMI4qgqe87\nhpg88gRgqaquBxCRN4AjgbUi0l5VV4tIe2CdW38V0Mkri1u2yj2OLjcMo5bg92a4cvPOtPRr1A6C\nWiofiMhJIY25HBgkIo3daK2hwDzgHeBSt86lwNvu8TvAcBFpKCLdgF7AFHeqrEBEBrn9XOJpYxhG\nLeXov31a0yIYaSSopTIJeFNEsnB8GSnn/lLVySLyGjAdKAZmAKOBpsArInIF8ANwvlt/rhsh9p1b\n/2o38gvgKuAZoBGOg96c9IZRizDXR/0jqFJ5EDgCmK0heMhU9U7gzqji3ThWi1/9UcAon/KpwIFV\nlccwjPSQNoe6KataS9DprxXAnDAUimEYRrI8PO57/v7hgpoWo97w/dptTFy0IaW2QS2VJcBnIvIB\njkUBpBZSbBiGkSwPjVsIwO9P3q+GJakfnPjQFwAsu/e0pNsGVSpL3U8D92MYhpEQm9qofwRSKqr6\np3QLYhiGERTbObL2EtSnYhiGEZhJSzayblsh2wqDJ4k0MoOg01+GYRiBKC1Vho+elLiikZGYpWIY\nRqhUx8SUxaHWXoImlGyDk2K+KxUTSv4iPWIZhlEfKSlVetz6PtcM6WmRXnWUoJbK20BzYBzwnudj\nGIYRGsWlpQCM/mJJDUtipEpQn0pjVb05rZIYhmG4WHRX3SWopfKuiJyaVkkMw8gIqiPxhqmc2ktQ\npXItjmLZJSIFIrJNRArSKZhhGPWPsPVRYVEJpaWmgqqTQEpFVZupapaqNlLVfPc86QzFhmFkPrXl\nEb67uITefxzLqPfn1bQo9Yq4SkVEervfh/p9qkdEwzDqC6WuqVJUohSVlFa6Pn35ZiCYRVO4x2n/\n6tQV4QloJCSRpXKD+/2Az+fvaZTLMIw6SlWmsLxtRzw7tdL1cx6daPvT13LiRn+p6gj3e0j1iGMY\nRn3Gqy4+XbCegsIi8vNyK9bR5KLDTAVVL4mmv45OcD1fRGyTLMMwytiyc0/KbaOtkIVrtqUuiCRX\nfV1BIZt2pC674ZBoncq5InIfMBaYBqwH8oCewBCgC3BjWiU0DKNOsXDt9pTbBrEqAlseSZooA//6\nCZDaHiJ1kbMemcCxvVpzw0nhZi5INP11vYi0BM4Ffgq0B3YB84DHVfWrUKUxDKPOU5WFi9HukmUb\nd9I0Lyeqjk1oJcvi9dsZP28dVx7bvazs2xVb+HbFlupVKgCqugn4P/djGIYBwMK122iYk0WXVk0q\nlFfpmR/V9vevzky9rySnvzKZ8x6byOadRVx8RBfycrPTOpZlKTYMIy7/GLeQd2f9WKn8pIe+4Lj7\nP6tUXjWdkri1YlmKk2XHnpK415du2MEjny4KZSxTKoZhxOUf477nmhdmBK5flempIIvfl27YUals\n7JzVFPusawnCx9+t5dMF61JqWxvoeev7PPpZ1RTCz5+YzP0fLmDj9t1VlseUimEYoVIlSyWAQjrp\noS8qjfHr56bzeIqZja98diqXP/1N2fn6bVV/sFYnxaXKfWMXpNz+mPvGs6soviWTDIGUiog0FpE/\nisj/uee9ROT00KQwDMOgagppzdbCUGQ4bNQ4Vm/dFUpfdYEVm3aFGvwQ1FJ5GtgNHOGerwL+EpoU\nhmFkDiGtqE8WieWYT6HPdQV1y1oJSnX4ooIqlR6qeh9QBKCqO7HYCsMwfNhclcWPtv49rcT6fSWm\nRk6eoEplj4g0wtX5ItIDx3IxDKOeU1KqbCssKju/4ZUqhAGbTkkLEZURKxCiJqa/7sRZVd9JRJ4H\nPgFuSnVQEdlLRF4TkfkiMk9EjhCRliLysYh873638NS/RUQWicgCETnZU95fRGa71/4pYapbwzAC\nMfL1WRx010ehPJiCr5avXHPl5op+kEx+GhSVlFZQ5ImI/BaJ/o3CeIQG3U/lY+Ac4DLgRWCAqn5W\nhXEfBsaqam+gH84K/ZHAJ6raC0dpjQQQkT7AcOAAYBjwqIhEVu88BlwJ9HI/w6ogk2EYKfDqtJWh\n9XXMfZ+m3HbaD5tDk6O2K6RfjpnKQXd9lHS7WCpl887gCioRyYQUdwCygQbAsSJyTioDikhz4Fjg\nSQBV3aOqW4AzgTFutTHAWe7xmcBLqrpbVZcCi4CBItIeyFfVSeqo32c9bQzDqGbCmEHZUxxsrYnf\nULHewjNxRu3zhetTajdw1DhK0rwTZsI0LQAi8hTQF5gLRP7VFXgjhTG74SSmfFpE+uEkqrwWaKeq\nq906a4B27nEHYJKn/Uq3rMg9ji73k38EMAKgc+fOKYhsGIZR9yksKmV3cQmNGwR69KdE0J4HqWqf\nEMc8FPitqk4WkYdxp7oiqKqKSGjqVFVHA6MBBgwYkIkvLoaRFpLxk1TnH1YyVlEtn8mqFqQaf4Wg\n019fu76NMFgJrFTVye75azhKZq07pYX7HcmbsAro5Gnf0S1b5R5HlxuGERKTlmyqaRECE0vPRMpL\nS5WXv1keeIrNSI2gSuVZHMWyQERmuRFXs1IZUFXXACtEJJJveSjwHfAOcKlbdinwtnv8DjBcRBqK\nSDcch/wUd6qsQEQGuVFfl3jaGIYRAjt2FweuW9Mp6aPfxaPP3565iptfn81jny1O2NcZ/57A+Plr\nQ5MNYMP23Qz5+2csWZ/6fjN1gaDTX08CFwOzKfepVIXfAs+LSANgCXA5joJ7RUSuAH4AzgdQ1bki\n8gqO4ikGrlbVSKKaq4BngEbAB+7HMIyQqK1zxYmcza9PW8nBnfeqULZ5hxPhFHRx5sOfLOL43u0S\nVwzIB3PWsHTDDp78aimjzj4otH7DJIxJsqBKZb2qvhPCeACo6rfAAJ9LQ2PUHwWM8imfCth2xoaR\nJkpraY75d2ZWTsUfYcP23dxYlX1Y6hBBrcPqDJEOqlRmiMgLwP/wrKRX1VSivwzDqCPUVkf9tyu2\nxLxWXFJZkv9+vYxlGyunzK+PpPs9IahSaYSjTE7ylKUaUmwYRh2hlhoqcYnOb1VcWsof355bdl7b\nFzYmQ/S/z9qCQpZt2MHh3VtVKK/OWw6kVFT18nQLYhhG7SMZnVLTCigyfLQc0e6X6gyvrW5OefhL\nNu3Yw7J7T4tZJ93/TEEXPz7tJ4uq/iJ0iQzDqDVE+1Q279jD6q2F9Nknv4YkSkyih2aNWSrVoHU3\n7UgchJDuKL2g01/veo7zgLOB2J4ywzAygujnz1mPTuCHjTt934RrOm19LF2RKNS4LpPKL14rLBVV\nfd17LiIvAl+lRSLDMGoN0Q+gHzbuBGBriAkIwyLR4scIQS2VmSu2oKrh7TVSS5w56TaYUt2jvhfQ\nNkxBDMOofcSaKnlywlKfuumWJj7bCotdOSoKEr2CPhklsWKT/7bCc1ZtTes00uYde1i1JfGWxsFD\nij33HKdJGHov6B7120SkIPKNE1p8c9WHNwyjNvPwJ9/7XwjhgXpo1OLE6iKZ56bflN7Xizdy+r++\n4smv/BSrMmbiMnbu8clEkMRvduS94znq3vFJSBqfoPcchp4Mup9KM1XN93zvGz0lZhhG5rFkffrW\ndpw/oFPiSimQDgNi9sqtFLibYq3Y5EwBzl+zrVK98fPXcec7cxn13jwAXpqynJWbd1aoE8Qa2FVU\nkrgSqfpUatBRLyKHxruuqtPDFccwjPqCCOTlZlFYVM0JHpOc4iktVX7y768Y0KUFr/3myLh1d+5x\nlMGWXUXs3FPMyDdm07FFI766+fiyOrGU3rbCIpo0yCErK72+l3hKN4zpr0SO+gfiXFPg+DjXDcOo\nRyRrIYgIk289gT3FpQwf/TWL02gVVRg3Sa0Sua3py/13lty1p4TcbCEnO6uCDRBZH7M5EuYb9cT+\naO4a1hQUcskRXdm6s4h+d3/ENUN68vuT9yMoqVhlNRr9papD0jy+YRj1lKG929K8US4A7fLzqk2p\nJEsiZ/j+d4xlyH5tePrygWVlQdTWiP9OA+CSI7qyyU1y+e6sH5NTKglUxH1j51cKVEg2wGBdQSHP\nTfohcP2gix9zgd/gbAMM8BnwuKrWvrhCwzDSju92vkm+A7dq2rC8bYivz4UJ/BERg+HdWT9yzQsz\nEvYXES1e1NinC5ztfeM+sN1rz09eXilLcaqRZKUJZg4fddP8N8srf9QnO9KNr87ky+83BK4fdPHj\nY0Au8Kh7frFb9sukpDMMIyMI2xkepvN4T0kwH00QhQKx7zWRNZKukGOv0pwRY0ouXeMFIahSOUxV\n+3nOx4tI/cgtbRhGJZ7yWadSV0jWFx1ReLVj6SJc9MTksuOgCtQre21Z/FgiIj0iJyLSHUhOfRmG\nkTFEopy8qCb/Vhs2G7fvTlwpSVJ5CIe2Ct+HaT9UzTqJZxVW2zoV4A/ApyLymYh8DowHbqz68IZh\nZAqL1m2n9x/HVio/55AOCduG9fbsp+yiqerzPp3rPDbvLGLyko2B66ekvGpyPxURyVXVIlX9RER6\nAZGwhAWqGv4rgWEYdZZYuy3279qCN2asits2rOfc29+uYkjv+Bmk5qwqYNG6ygsXg1BQWMRbM5xc\nuome55EH/o49JewKoOwAtu4q4oLRkwLLk5PCmpbD7/mE35/kH2F22KhxHN2rddJ9VpApwfVVIvIO\n8CIwXlVnVWk0wzAylmQc0/+75uioxuHIsHzTzoR1Pl+4nk4TGwXqr2BXMSWlTg6u4lKl710fpSTX\n2Y9O4KLDO6fUNh55udkAZAmMn782Zj2vRaMK93+4wLdecanymRvJ5q2fDImmv/YHvgFuB1aIyMMi\nMii5IQzDqA/Eevb4LTZs1CA7LTK8MnVloHpBF0D+5N9fcfwDnyc9VnTvfildwiCy302pwi+emRp6\n/0s3JL92KK5SUdWNqvq4uwhyILAEeEhEFovIqNTENAwjE4mVJ8xvmii6LCvVfOk+RPJuxSNdmVC8\nb/Xp3gwLoCR6W0uXT+atZfXWxFmOE1EcMLrMS+B/SlX9EXgSZ33KNmyNimEYAWnZpEGF8+hn+n7t\nmqXU7wM/7VepbOLixI7usKKzYkWb+XWfDhUTS6lcMWYqZz8yscr9p/I7JVQqIpInIj8VkTeARTj5\nvkYC+yQ9mmEY9Q4BPr1xcIWyrKiH1WHdWqbU9+n92qcmU0iWSv+/jAunoxSJpVQA1hQUlh1v3ZVa\n8pNUfqe4SkVEXgCWA+cDzwNdVfUyVR2rqrZOxTCMQDRvnFvhPPphdXrffWjdtKI1E4Rkk0NWtV08\nRn+xmK/jWEl3vD035b5nLN/M7uLKj9ySNE+xCclbWImiv8YCv1LV9HiZDMOotUxdtimUfnx9Kj4P\n9c4tG7Nh+54q911T/PX9+WXHRSWlbEziXmav2hrz2pL12zn70Yn079KC16NS789bXZC8oEmQyvRX\noizFz6YsjWEYdRZV5bz/fJ22/sNSBtHTaEFJd5qZcfPW8f7sNYHrL4gTHbZ5pzN15beS/r6x/qHB\nYVFSqny/NjmbIsSYC8MwMgW/qfowo5n8I8KSVxC1yFCpQHS6+UQE/WX/NnZ+4koh0rhBNgWFPlsj\nx6HGlIqIZIvIDBF51z1vKSIfi8j37ncLT91bRGSRiCwQkZM95f1FZLZ77Z+SzoQ7hlGP8FMgt745\nJ6W+/BRUWH+qmfAXf8/783jMTVHvT/kPGL9e+ITuqHc6leYicoGI3OB+LhCRvVIRMIprAW9A+Ujg\nE1XtBXziniMifYDhwAHAMOBREYmsnHoMuBLo5X6GhSCXYdQ71hUUMmVpuQ/FTxGMnbM6pb79DBy/\ndSKp6IdMeI98/IslNS1CTP6TghJLFP11CTAdGAw0dj9DgGnutZQQkY7AacATnuIzgTHu8RjgLE/5\nS6q6W1WX4oQ1DxSR9kC+qk5S57XqWU8bwzASsGzDjrIFcqf/6yvOf7zch1Lqowniha/Gw68vP0e9\nt9alR3RJaaxMY+CocazYVPVFjKky5uvgOz5GSBT9dRvQX1W3eAvdqanJOA/yVPgHcBPgXfHUTlUj\nr0JrgHbucQfAm2FtpVtW5B5Hl1dCREYAIwA6dw4//45h1EUG//0zAJbdexrrtiXOD5uqS8VvKs13\ncaCn3p/OPDClB1qmsW7bbl7+ZkVNi5EUiaa/YoUpl5Kij0xETgfWqeq0WHVcyyM0r6CqjlbVAao6\noE2bNmF1axgZi591sW13cg7bCH5/yH5KJSc7NRdv347NU2pXV0hnqv10kOhfcRQwXUQeE5Fb3c9/\ncKbEUs39dRRwhogsA14CjheR54C17pQW7vc6t/4qoJOnfUe3bJV7HF1uGEYVSXGmy5cduysv2vOb\n/vrXhYcAMOYXA5Pq/4LDOiWuVMuYnsQ2wOlOIXZo5zBc5OUkSig5BhgAfA7sdj+fAQNU9ZlUBlTV\nW1S1o6p2xXHAj1fVnwPvAJe61S4F3naP3wGGi0hDEemG45Cf4k6VFYjIIDfq6xJPG8MwUiAyBRVm\n+PA/xi2sVOZnqbTLz2PZvadx3L7BZhM+ufE4AH42MPGUdir7jqSTcx4Nnpcr3XbKqLMPCrW/hPam\nqm5W1ZeAp4GnVfUlVa3afpb+3AucKCLfAye456jqXOAV4DucFf5Xe1LEXIXj7F8ELAY+SINchlFv\neH7yciBcS2W3z5qNVBct3n3mAWXHPdo0BYJFgLXLz0tpvFpBmrVKborTjrFItPNjZ+A+nCSSW50i\nycfZTnikqi6ryuCq+hmO5YOqbgSGxqg3Cp/pNlWdChxYFRkMwyjn9rfm8PNBXUK1VLJ9rIRU7YYm\nDXKYfKvvYyIudTnyON0+lbB/m0Qq6mXgTaC9qvZS1Z5Ae+AtHH+IYRgZSJjz+L5rUgI8yKbcOtQ3\ntX27/LykLY+6rFRmLN+SuFIVSNVqjNlfguutVfVlb0ZiVS1xp8NahSqJYRi1Br/or1Txe2gFmbJq\nm5/Huf07VihL9fmXjqzE1UVxmHORPoT9yyRSKtNE5FEROVxE9nE/h4vIo8CMkGUxDCNkbnptJsP+\n8UXS7UaHuMrbT6n4TYkFIVWlUsv89LWKsC2VRIsfLwGuAP5E+cLCVTgRWU+GKolhGKETdM92L4VF\nJUmlDnnikgE8M3EZXy3a4HvdT4Gk+pBP1eII+8GZSYT90yRKfb8HJ7/WY+EOaxhGbeGSp6ZUOP/F\nM98k1f6EPu14b3Z5XrCebZuyaN32snO/h1aqD/mUH4CmU2JSrY56EWkddf5zNxvwCMsIbBiZwRcL\n11c4D7LHezS3nrp/2XF05NhhXStvFZzq9FcsHh5+cNzrZqnEJuxHeSKfykeegW8HLgamAScCD4Yq\niWEYdZY2zRoy/sbjuPXU3uTlZle45vdAD/shf+bBvmn/POOFOlxGIcDtp+2fsF5QguT+inAOcI67\nyv5nOAsUDcMwAOjepikjju1RaTrlxD5tK9VN2aeS6rRZjPmvxy46NG671k0bVjg/7aD2KY1fm8kS\nYa/GDcLrL8H1RiJyiIj0B3JVdQeAqhYBlRP6GIZRKyl1w1LfnLHSd1+UdvkNK5UFYVD3ylNbt53a\np+x48H5N8/LlAAAgAElEQVRtOH9A5dxcqSuH1Ig1XH6j3LLj3Gy/Ssrvju8JwG8G96Bzq8YpSlB7\n8f425xwa3+ILQiKlshpnmuvvwAZPwsdWQGopSw3DqDIjnp3K6C+Cb6BU4vo5rn95Jr9+bnpocrw0\n4ohKZUf0aMW/f+Ykh2zcIDvUOft4XTVukB3zWqzptqKS8hQy5xzS0bdOntuvamb6+yv8NCEsiUmU\nUHJI1CfyirMFOLbqwxuGkQoffbeWv74ffL/yRGsZ68riwHhy/veKw2O3i9Eskj/MW6dpQ/+g2LqW\ngj4o4vlVw7jDRNFfbUXkHyLyrojc4+b9iqyq3xnC+IZhVAM/9ezqCDBpScUIr+LSykkfq0JNKKn+\nXVrEvOZnqXw/6hQ6tYw/naUKZx3cgdZNG3DhYZ2rJd1Lqk7zl0YMSqldloQbVpxo+utZYAfwL6Ap\n8M/whjYMI528NaN8e6GZKyrmjxo+elKF8w3b91SLTFUlzBX1QbPz7rNXI6befiJdWzepFmV5xsH7\npNRuUPdW3DRsv6TbeacnVZWx1x3D9D+emJIMkFiptFfV21T1Q1X9LdA35ZEMw6hWrnv52xobO11T\nRSk/0gNoo0gV7zqbmlje0rZZsGSZDXMqP75zsyqX7dM8fn/RlkrvvfNp2aQBp/dNLdItoaoWkRYi\n0lJEWgLZUeeGYdQSnpv0A9+uSG9G25om0UP+pD7tyMut/FhLVTdE+6JyfCPEaoZZd51UqexMHyvn\nymO7lx13a92k0vVY1te/f1Yebp1MCHgipdIcZ7Fj5JOPs5XwNGBq8GEMw0gHu4udyP6CwiJuf2sO\nZz0yoYYlckjfNFH8fkdfMoCfDexSuVVI4ow4tjuXH9U16Xbd21R+mMdj8H6Jd79smFM52q2tz5YA\n3lt/+5qj+PwPgyte92iBWPZlMnZnouivrqraXVW7+Xy6x2trGHWFxz9fTNeR77HHZ4fC2s6db88F\nYNeeisvGon0oAIeNGlctMqWT1FPfB68V7wHauEEOd/7kgDg1/OnfOXYQgR/PXD4w6TFikZUlNG6Q\nzaGd9yI/L5curSoqOAGO792Ogzo053dDe1W41sNVhs1iRMT5jpeMcCJyqog0co/PSaatYdRW/v3p\nIqDyg7k28PXijSzbsCPm9Ze+WcHjn1der/L69MrZiddv2x2qbMlyYp92Ve5jW2H6l8eFuUHZGf32\noX+XFow8pXfKPgo/7jkn+L7yLZs04Lu7h/HGVUf5Xs8SoXmjXP7326MrhFgD/PlMZ2PdHm2b+jX1\n7y9wTYdTgU/d/VRuT7KtYdRKyh5UtWe6vIwL/28Sg//+Wdw693wwn5I0b+QUBv93yYAq97Fk/fbE\nlXwIsgAzHU75a47vyeu/OZJWTRtW8FFUlV5JPOQTpZaJd99NXAsl3sLSaBKtUzlcRMom91T1GuB9\n4AKcvesNI2Ooy4lsj7x3fIXzNz3hxJlEqrqzJv5pF//1VPZt1yzl9v+68JCY17ICes57tW2aUKHG\n83/17dicG0/cl4cuiJ8FuoJsCa6PBgrKBhd5EDgY6A1cE3gUw6gDhDntUZOc/eiEapkmqgmi0+oH\nJZkXhrDCoYOk9z+yR+xd2X/Sbx8ePL+ff98Bb8gvGiyaeF2JCL8d2itwmDMkVio5qrpbRHJE5Dmg\nGXCeqq4HMi+zmlG/yRClMmN55oYVB5nm6+kzNRQk1PqQTnsB0KttuXWR7v8SL1w5iFFnHxjzeqwH\nfhCFNf/Pw7h6SM+E9ap1ky7gKxH5BJgJHAP8RVVLReQ4YFe4ohhGzeJ9Q523uoCpyzbVoDQVKSwq\n4bqXZrB1V1FNixKIdC1+LAlgqVw4sBNvXnUkXT0ZhYtKErc7r39HPv/DYA7vFnwJXvvmeexXhSku\ngIsOrxwCnYhI2pnPfj84Zp283GDJPKt1j3pV/ZWIHA3sAdYCr3l2gzw3VEkMo4bxvgSf8vCXACy7\n97QakgY2bi+P1jrhwc9ZuXkXKzbvijklki4uO7Irz0xcVq1jxiLI7JeIcEjnFklnRxaRSuG2hUXx\nIwK/vmUoW3cW0e/uj+LWi+apywawYVvi1DgdW8SfEOrqs5gxWcL2NyWM/lLVr1R1iqr+oKqHAQPd\ndSrh5c82jBB57DNn3UlBYXJv9anO14fFMxOW0nXke+zY7fhD+v+lfF3Jys273O+dnPvYxLTKMeyA\nvSuc33F6H+bdPSypPsJc/Pjns8qnh0rT8G/00AX9OKZXa99rOwOEmftkRvGdgvNyfO92nH9Y5X1m\nojmsa0veuaZyKLA3ZX9VCXtr50TRX4eJyN6e80uAJ9x96i1Ni1Er+dtYJyX8fz4Lvt8IpB5ZFBZP\nfLUUgE074r/BbkxwvSrMvOMk/nnhIRU2a8rKEholEVIaNhcPKp8eSodSOfuQjnHT5ieiWV4uD57f\nj6G9y3e4DPMx3bfjXpXKdoe4ULe696h/HGfqCxE5FrgXJ3PxVpzIMMOotST7t1LTlkqgqR0krVFq\nzRvn0iAniwfPDx5CWp2E+IIeCL88Yn6cc2hH2iVI3BgGkf/TfTs2T/tYqZJo7X22qka8lRcAo1X1\ndeB1Eam5FKhGvWXG8s0c1KE5OQHSlgeZgvEqkroQ/LWmoLCmRahRSqvZnPRGgiVDutY8zbnrZAoK\ni8jLrTnLMRGJ/jKzRSSieIYC3hVWwZPBeBCRTiLyqYh8JyJzReRat7yliHwsIt+73y08bW4RkUUi\nskBETvaU9xeR2e61f0rYdpxRq5izaitnPzqRBz5eGKj+ys2J95F70p1yAmdqZdOOPTyW5LRZWEQU\nnEjNW021lSDRX4m4cGAnjts3ccJGIKnUKtXx8GnSMIf2zRtVw0ipk0gxvAh8LiIbcEKIvwQQkZ44\nU2CpUAzcqKrTRaQZME1EPgYuAz5R1XtFZCQwErhZRPoAw4EDgH2AcSKyr6qWAI8BVwKTcVb6DwM+\nSFEuo5azbpvzlj5vdUGCmg5LN5YrFVVl1sqt9OtUcX766QnLyo4XrNnGc5N+YNy8dVUXtorUtH+n\ntnJ0T3+HejLcc06wbaGuP2FfRhzrnzd33A3H0iA7trVQV7ZnTgeJshSPAm4EngGO1vLXpyzgt6kM\nqKqrI5FjqroNmAd0AM4ExrjVxgBnucdnAi+p6m5VXQosAgaKSHsgX1UnuXI962ljZCCR/31B/1z3\napRbdvzmjFWc+cgE3pu1ukKdVVvKl1s99tliCnbV3Ep0rx5Jh0O6qtx44r48PLxmfC2tmjQA4KgQ\nlEpQGjeIvc6jZ9tmdG5l67/9CBJSPElV31TVHZ6yhWGEFItIV+AQHEujnapG/uLXAJGUph2AFZ5m\nK92yDu5xdLnfOCNEZKqITF2/fn1VxTZqiMjbe2Sxlqry+rSVMbMLe8NEv1/nJCJctjF2xl+AKSEu\neHxzxsoKSuu9WavjLl6M6BHVYCvHq5vfDu3FGf1S2+o2LOrKBHcsOZvl5bBX41z/i3H46PpjeSKE\nhJzVQbJZikNDRJoCrwPXqWqF+QzX8gjtr0pVR6vqAFUd0KZNsLlUo/ZRWuZzcP5iv16ykRtfncmf\n3/suYduqvvhv313MCQ9+zuyVwWZ9P5y7hutfnslR946n68j3+Hzheq5+YTrXvTQjYdtS1UCWygM/\nTW0R5H7tmlWyOD7/w2DG3XBswrY17bashQZcGUF+mhl/PJGpt52QdN/7tmvGCSFsHVAd1IhSEZFc\nHIXyvKq+4Ravdae0cL8jE9urAO8qoY5u2Sr3OLrcyFDKpr/cP94dux0LZe3WQr77sYBut7xXwTKo\n0NZ9R4mXkiLe8+rVqStYtG479304n2UbdpQpilj86r/TKpxf+tQUAOav2cbjny+m2Cc2NiJjqcLG\n7YnXorSPEcJ626n7x233s8M7c0T3iokMu7RqQs8UI52MysRSvjnZWYEiF+sy1X53boTWk8A8VX3Q\nc+kd4FL3+FLgbU/5cBFpKCLdgF7AFHeqrEBEBrl9XuJpY2QkrqXinomn9MUpy1GFT+atrdBi3bZC\n/vjWHHYXOQ9x7+ZVa6PCc/02seo68j1mr9zKn/7nWENffr+hbH+TV6euqFQ/Eau3FnLPB/PL5Ni8\nYw8vTF5O15HvsbbAGX/Lzj0cc9+nCfvye3BNGHk8vzymW9l5h70qRwod3GmvWrl3TNh4b3GfalhD\nEmvs+kZKYcFV5CjgYmC2Z63LrTgLK18RkSuAH4DzAVR1roi8AnyHEzl2tRv5BXAVThBBI5yoL4v8\nymDU41NZV1DIL5+d6parbwLDZyYuY8byLbw3u9w5v2hd+SZPW3ZW9G90a92EpT67LP7k31/5yvNN\nFfwvq9y0Kxf+3yTmr9lW4drZjwZLwyICfzh5P+7/cEFZWUSJzLzzJFBnMWPXke9VaNev0141vgtk\ndfPbob245Y3ZNS1GvaDalYqqfkVsRT40RptRwCif8qlA7LzRRkZR6pn+8jrUFVi2ofKalJWbd9G1\nlX/Cva07i9ixp2Kk14zlm5OSZ23Bbm57czZfLdpAYVEJ95xzEOsKdnNgh8Srnf85fhEnHbB3JYWS\nDAIc0rlyCg+A5o3iO4PrisM7LJJJbxXZ5bBhwNX0EbxhxPXt9/VSE5aKYVQJZ3Fg+bkqfLVoQ9l5\ni8a5bHatEL8/7h827uC4+z+rVL55Z/Jp5Z+fvLzs+BfPTE2q7eNfLEl6PC892jZl4drgSmn8jceV\nRcHVtWdeKg/pvZvnscS1PJMJMLhqSE9ys7O4cGDnpMbzWsv1WalktsfIqBPs3FOcMMU4wNUvOFHs\ngvCjxyHvnfgSqLBaOtpvAnDB45NSljVM/jfzxyq1b920YVL1u7dpysluBuKqRHE9EuJe60FJJerL\nK2cyd5uXm81vh/YitwoO9WQXP3qTZtZ1TKkYNcri9dvpc8eHZY5pVU2csl7gng/ml51GpzTxPgwW\nrt1ONHUtf1YkjXqPNk1Yes+pAJywf9t4TRIS5JH3+R8G89KIQZXKT0sidUk0/71iICNP6Z1y+2Ro\n0aQBvdzfrjpCods0LQ8GSHY4b3r/uo4pFaNGOemhL4DyyKv/+3IJfe/6qMwSKSwq4cxHJjBrZfl2\nsNGr4guiFhSuyyAn9M8HdebSI7sCcHj3VogIy+49jScuPaxK/QZ56HVp1YRB3WPvoZ4Kx/Rqw6+P\n65F0u6rqhOqYjbpqSI86Y3E0SmNCSlMqRrWzrbCobJ1G9MrxsXPWALB6q6NUxkxcxswVWzjj3xNi\n9jfTsyDxwY8Xxl0/Utf43fG9knIyB6W+5aaqDh9HbnZW2T401fnrNszJok/7/KTazLjjRNo2S276\nNCjmqDeqnYPu+ohTDtybx37ev9K18ggv58/yX+MXJdV3Ks722sqvju1O2/w8zj20IzNXbOH3J+1X\n0yLVWYoD7FEfBmWjVKOnfsFfTkm6TV5uNl/cNCQt6YDMUjFqhA/mrKmUs2vrriLm/uhYHarKik07\n2b675hI81jSR/cfzcrO577x+tHSTKsaie5sk9iv3PPNOPWjv2PXqOJ1bOkkf12+vninRZJOeRvPz\nQclFnFWFvNxsmjQM364wS6WeUlKqvDZtBece2jFQ2oi1BYXc+8F87jnnoJgbBM1auYVx89Zxw4n7\nBpKh358+qnA+Y/lmitw3ynMf+5purZN4SNZCrji6G1t3FfHatJWJK3vo2qoxd595YMx902Px8ogj\nAteNvEg3a5jDoxdVthgT8buhvWjTNLaSi/yXyvHbwD0FHr+4P098ubQsW3FQHhp+MBMXbay2rM8d\nWziLT5PZhyXCsntPC1ucGsGUSj3l5W9WcOubs9m6q4gRxyZ2nN797ne8N2s1Q3q3jZmpNuL3uP6E\nXr7RNqu27KqwKG9PVP6rUe/Nq3Dut7q9LtEgJ4u//7Qfvfduxl+i7i0eChwbcBOpCId3a0mbNM2R\n+5HoxeGE/dsx4tjuKTnl/ejfpSX9u7RMul1+Xi7DDtybD2avTlw5BNrl5zH/z8NomFN/J4Hq753X\nczbvdBIWRqcqiUVERfzuxRk8PO77uHX3lJRy1ztzOeuRis71o+4dz4F3fhiz3ffrKof/1gR/ONnf\nd3HWweXK9GWfUNtoclwPeyTEOTqJYyxqcybeoORkZ3HrqfsnnLKrLobuX30ZfvNyY+/DUh8wpVJP\niTjosgOGFnmz+z40Lv52vnuKS3lm4jK+XVEeBrxzT837Rg7v1pLc7MT3Gx1GG8mn9buhvfj9Sfsy\n5bahgR4akdXuZx/agcH7teGhCw6OqbC8+OUxS0Q8cV7/zRE8+4uBSfeZSTSox5ZDdWO/dD0lolTi\npYL34ldt9dZdjJm4rFL5x99VzBS8Y3cxfe6IbaFUF49f3J/5fz6FBtlZPH1Z7HUeOVlStmgO4OZT\nejPuhuPo3qYp1xzfi7bN8mKG+XrDNCPbEufn5fLM5QPZu3keVw/pyaJRp/Dd3SfHHH/LjnAj2Pp3\naZn0dFqmUp+npaoL+4XrKRHHZVBLJXpf+K27irjy2anc+c5c3p+9mi07y/f/uOGVmRXqbt6ZeG+Q\nZHjm8tQW/uVmZ5GdJSwcdQpDeldckR5ZXwDQt2PzCkq0UW522ar2CH6Wyrd3nMgRPcqtnFhWSU52\nFo0bxHZnbqvHEW/pZO6fTmbGHSfWtBgZjymVekpEqQTRKaWlWindyZxVW5mzylE0Vz0/nYPv/ti3\n7cwVW7j2pW99r6XKgK4tOWCffHrvHX9Tqehomni5nCpmmK34o/hNmUX/breftj97Na7oP2gQMHfU\nr4/rUaXUJ0YwmjTMiavMjXAwpVJPiQReZQXQKg98vKBS2UVPTA40zpmPTGDaD/4p5b+8aQhL/npq\noH68CPDe745h7HXHxvQV9OtYOf18tHK4/7y+HN2zPGw3Vriqn3KInjaM+GG8pUE8Iw1zshh5Sm/a\nNauZTaRyAviYDCMZTG3XUyJJGH/csouuI9/j6iE9+PmgLrRvXnGnwAmLNvDIp4vTIkOjBtlkZQkz\n7zyp0pqVeHidrsfu24b+XVpUUlxP+vhMoi2Qnw7ohOKkzReBD649hh82Vd6XxW8dT7RS8fM5RSe6\njOaVXx3h2y4vyX08UqFpwxyuHdorpfUUhhEPs1QyjKKS0oQPMyh/wM5y82Y98ulijrhnPO/PXs19\nY+fz1/fn8daMVYEtklSIPJibN8pl4sjjA7X55rYTKk1j3eTxXZx8QDuW3Xta8LTwnhXQbfPzOKxr\nS/e8/GnvN/11wD75XH5U17LEfEEDHrwM7NaybLwIR/Zoxdhrjw3cR2RxYawFqbEQEa4/cV96tbN9\n6Y1wMaVSy9i6q4itcdaO3P7W7ErbwwLs2lPCP8YtpNdtH/DoZ4tZt62wrJ/dxSU88eWSsmSNi9Zt\nY8l6x0cyy5OMERz/yKOfLWb0F0u47uVwfSHRVNhDfK9G/Ofn/csCB07s46wrOG7fNpzXv2NZvWZ5\nlY3rw7q2LPOvJLuCu2+n5hXG88PPF5OVJdz5kwPo1NKx7CI6xWsNpbLe5PjebcvSswRhQJcWXDu0\nF/ef1y/5wQwjDdj0Vy0jMg0UK2XDc5OcnQZVtcID7IGPFvDEV0sBuP/DBdz/4QIa5mRxzZCeTFi8\ngUlLnO13D9gnn7k/FlTuuAr03rsZe4pLadOsIfed19d3V0WAIfu14dMF5RmEo9/uhx24N6ce1J7/\nzfyR0/u258pjujOgSwuysqQs1YmfQZCVJdw0bD9+8cxU2uYnt6q89975LBp1SqUprnMO7VC2Z0u8\nMNRjerVh4drttGxc2R+TzHqTVNfKZWU5Fodh1BbMUqnFLFq3jbvemcueYser7p3WKipRiktKKS1V\ntuzcwzM+60V2F5fywMcLyxQKUGWFcu3QXpXKxl53LON/P5iXf3UEXVo1Ydm9p/Hnsw6stE/6k9F7\ngCTwQwzs1rJSIEGslO1D9mvL3849iJuHJb8BlJ/PZMSx3dmnueM8jxc1dsspvfnq5iG0zc9z5TOM\n+o1ZKmni2xVbaNusIfvs1cj3+qQlG9m6q6hse9foFNTeKa6Iwjj30PJpoF1FJUk5t6vKT/t3pH+X\nFgwf2JnrT9zXdwrOy8WDunDxoC6s37abN6avpGfbppUVRJwncKwV67HaiAgXHBZehlfv+PEipHKy\ns+jYorGnYflhMlnFI9ZQTjo2TzHqFR32akSjBunbhCsRplSS4J735/H4F0t8p6ZKS5U9JaXk5WYz\n7YfNnPvYRETg8iO7ccFhnWiUm82ekhLm/ljAlKWbeH6yM4319OWHcfnT3wQa//Xp5dlu06FQ3rnm\nKBo3yOHRzxbRMCebF6csZ5/medxy6v78JEYSyUS0adaQX8VIKujnc2jqpuIOusYjnXRs0ZgftxYm\ntbbhosO78Mb0VQBJZca95vieAFx4ePWlPjcykwkBg17ShSmVKL5dsYWFa7dxUIfm7N8+nxenLOeW\nN2Zz/Qn78vgXSwA4+m/j+fj645i0dCN9OzSnVdOG3P72HF6YvJy/nn0Qt745G3Aemk9NWMpTE5bG\nHC+oQqkO+nbcC4AHzz+YrbuK2FNcyl1n9KFZXm6ClqlR6vMqf9tp+9O5VWNOiuM4T4ULByb/sP7P\nxf2ZumxTUkkR+3dpwTVDevLvTxcltTFU4wY53JTC1J1h1DbqnVKZvWpr2dTN8MM6MXbuGt7/3THs\nnZ/Hkg3bK2XWjeBNorhy8y72v2Ns2fkTlwzgBdfyiCiUmqJfx+a8fc3RANz1ztyyqbO2zRrSt2Nz\nju7Zmi27ivhHgkzDzRvl8sD56Y0o8tsgqFleLlcN7lmp/NVfH8HnC9bH9W/48eVNQ8jJlkrrb4LQ\nskkDTjog+Q2serVzUrp0adU4QU3DyDzqnVLx8tI3KwA48t7xVernl89ODUOcSiz566mMfGMWs1cV\nkJMlzF611bde66YN2eDubOddr3DXGQdw8RFdWLJ+R6WQ2Z/024e83GyOquK9p0KXVo35/A9Dkmpz\nWNfKazqC0Kll9T/Yz+i3D51aNuaQTntV+9iGUdPUa6VS28nKEu7zrD/4ccuuSgpw4sjjmftjAVe6\niq2wuOLGVz3aNKVHm4rJECPlYexPnaxf+ftRp2R8hJSIcGjnFjUthmHUCKZUAtK1VWNOPmBv2jfP\no1ubplz61JRA7Rb+5RQUpWFOuQXxwEcL+Nf4RVx/wr5cfEQX8vNyyMnOShhRFYkka5Cdxfw/D0Nx\nsgx7w4R7JLFwriqBRgv/cgprCwppnGSUSbLTV4Zh1C3qvFIRkWHAw0A28ISq3huv/kEdmvP+rUNR\nnK0/1xUU0jY/j8KiEnKyhCnLNtG8US6qcPq/vgKge+smjP/94Ar9jL3umLIIpe5tmlJQWESj3Gxy\nPcph2u0n+G4OVBY+mi0xncB75/snGHzm8sPo3rpieK5XN9wYYBOosnYivPvboznzkQn8+rjugduB\nk3+rJqaWDMOo3dRppSIi2cAjwInASuAbEXlHVb+L166t54EdOY74Io7s0bpC3f5dWvD6b46s1Efv\nvfMrnOd7IqSeumwARSVKqxj5p644ujvbCou54uhuFco/+/1glm3cQdOGOXSO4eQdvF9b33KAob3b\nlu1SGJQDOzRncQqZgg3DMPyo00oFGAgsUtUlACLyEnAmEFepBGXe3cNSSg1+fO/44bCNGmRzy6n7\nVyrv2rpJUnmfIjRu6CjEVk1rx37ghmHUX+q6UukArPCcrwQOj64kIiOAEe7pdhGpvEFI3af1/bDh\n/pqWIn20BjbUtBBpJNPvDzL/HjP9/gLNrdd1pRIIVR0NjK5pOdKJiExV1QE1LUe6sPur+2T6PdaH\n+wtSr66H4qwCOnnOO7plhmEYRg1Q15XKN0AvEekmIg2A4cA7NSyTYRhGvaVOT3+parGIXAN8iBNS\n/JSqzq1hsWqKjJ7ew+4vE8j0e7T7AyTI1rOGYRiGEYS6Pv1lGIZh1CJMqRiGYRihYUqlFiMiy0Rk\ntoh8GwnnE5GWIvKxiHzvfrfw1L9FRBaJyAIROdlT3t/tZ5GI/FNibatYA4hItojMEJF33fOMuD8R\nyRORKSIyU0Tmisif3PKMuD8AEekkIp+KyHfuPV7rlmfEPYrIUyKyTkTmeMoy4t6SQUSGufe0SERG\nJmygqvappR9gGdA6quw+YKR7PBL4m3vcB5gJNAS6AYuBbPfaFGAQTpqwD4BTavrePPdzA/AC8G4m\n3Z8rS1P3OBeY7MqYEffnytUeONQ9bgYsdO8jI+4ROBY4FJjjKcuIe0viN8h276U70MC9xz7x2pil\nUvc4ExjjHo8BzvKUv6Squ1V1KbAIGCgi7YF8VZ2kzv+SZz1tahQR6QicBjzhKc6I+1OH7e5prvtR\nMuT+AFR1tapOd4+3AfNwslxkxD2q6hfApqjijLi3JChLhaWqe4BIKqyYmFKp3SgwTkSmualmANqp\n6mr3eA0QSTTml7Kmg/tZ6VNeG/gHcBPg3QQmY+7Pndr7FlgHfKyqk8mg+/MiIl2BQ3Assoy8R5dM\nvjc/Yt1XTOr0OpV6wNGqukpE2gIfi8h870VVVRGpkzHhInI6sE5Vp4nIYL86dfn+AFS1BDhYRPYC\n3hSRA6Ou1+n7iyAiTYHXgetUtcDrMsiUe/Qjk++tKpilUotR1VXu9zrgTRxTdK1rUuN+r3Orx0pZ\ns8o9ji6vaY4CzhCRZTgm9fEi8hyZc39lqOoW4FNgGBl2fyKSi6NQnlfVN9zijLrHKDL53vxIOhWW\nKZVaiog0EZFmkWPgJGAOThqaS91qlwJvu8fvAMNFpKGIdAN6AVNcU71ARAa5USeXeNrUGKp6i6p2\nVNWuOOl1xqvqz8mQ+xORNq6Fgog0wtnzZz4Zcn8ArjxPAvNU9UHPpYy5Rx8y+d78SD4VVk1HF9gn\nZtRFd5xIi5nAXOA2t7wV8AnwPTAOaOlpcxtOpMYCPBEmwAAchbQY+DduJoXa8gEGUx79lRH3B/QF\nZhGz+UUAAAcVSURBVACzXNnuyKT7c+U6GsfvNwv41v2cmin3CLwIrAaKcHwJV2TKvSX5O5yKE9m3\nOPIcivexNC2GYRhGaNj0l2EYhhEaplQMwzCM0DClYhiGYYSGKRXDMAwjNEypGIZhGKFhSsWIiYi0\nEidD8rciskZEVnnOG6TQ3wki8pZ7fLaI/CEkOZ8TkaXiZAReKCJjRGSfMPqOMd7+IvK5+zvME5HH\n3PLDReShNI57goioiFzmKRvgll2XQn/Hi8igGNd+KSLr3XucLyK/q4Lo6ZBrhjiZgsfGqmvUDJam\nxYiJqm4EDgYQkbuA7ar6d28dd0GXqGpp5R7i9v1mWHK6XK+qb4lIFk7m4/EicpCqFoU8DjhrDe5T\n1ffc+z8QQJ3cXpPTMJ6X2cAFwDPu+YU4a5lS4XhgAzApxvXnVfU6EWkDLBCRV7U871U6CSQXOIoW\neFtEjlHVhdUgm5EAs1SMpBGRnuLsofE8zsLM9iIyWkSmirOvxh2euqeJsxfDdDzZTd03zn+4x8+J\nyMMiMlFElojI2W55toj8x31T/sh9K42b4VVVS13FtwknCwF+sonISSLymkeeU0TkVRHJEZH/irP/\nxZwYb+jtcZMEqsNstw+vJfYXEXnStWiWiMjVnrEuF5FZrmX1tFvWTkTecOWcEuftewmQLyKtXQV6\nIvChp+9DRWSy2//rItLcLb/e/Teb5f7ePYBfAn9wrZEj4/ym691xI+lJfGUVkWaulTjL/Zzl+W2/\nFpHpIvKyOBkiEJGVInKXa3XMEpF9k5HLlW0czqr+K90+fy0i37i/7asi0khEmrv/BjlunRbecyNc\nTKkYqdIbeEhV+6iTo2ykqg4A+gEnikgfEWkMPI6zIrc/EG9Kqi1OPrCzgHvcsp/iZETtA1wGHJGE\nfNNdGfGTDWc1dF8RaeXWuRx4ypWztaoepKoH4qQqj+ZB4AsReV9Eros8uH3YF+ehPwi421WS/YCb\ngcGq2g+40a37TxzrZwBwPhW3A4jmdeA84Bgcy8hrjT0H3KCqfXFWdv/RLb8JONgtv0ZVF7tj3K+q\nB6vqxFiDiZOBOBtnVXg8We8C1rtj9AM+FycZ6khgqKoeirP6/lpP92tV9RC3jxuSkcuD99/6VVU9\nzP1tFwOXqepWYAJO7jVwrLtXVbU4QN9GkphSMVJlsapO9Zxf6Foj04H9cRRBH2Chqi5WJ3XD83H6\ne8t9659FeWrto4FXXOvjR+DzJOTz7q5XSTZ3uu554Gci0hJHmXyEsw/GfuLs0HcysDW6Y1V9wr23\n14ChwNfi72N6V1X3qJMQdBPQBmdq52VV3eT2Fdmv4wTgP+Kkyn8LaCFOzjA/XsZ5mF+Ik0rEuWFH\nQeap6gS3aAzORlPgWJTPichFVFRC8bhIRGbjpCT5lzr7acST9QTgEfe+VFU3A0fi/FYT3foXAV09\nY0SSUE6LKk8G7791XxH50pV7OHCAW/4EzosD7vfTKY5lJMDMPyNVdkQORKQXztvnQFXdIk624bwk\n+9vtOQ5ju9WDgfcSyPYUzls/OA/6EmCjiPQFTgGuBs4FRhCFa509BTwlzpYE+ye4pxLi/72JK+Oe\nOHXKxhYRAY4DrsJRVIk42a1/BnCre4+JiPhUDgc+EJF3XQXpK6v475IrwFhVvTjGGJHfKNHvE49D\ncDYIA8eyPEVV54jIL3GsRFT1cxH5t4gMAYpUdX6MvowqYpaKEQb5wDacbKztcR5gAN9RnuFUcN6s\nk2ECcJ44tKf8rTsmbt3rcRL/fRxHNlR1BY5DeCSu41scp7So6qvAHTjbyUaPMcwzP78P0AL4MeA9\njQcucK0jIt8403Fev8vBCfr5I3CzN0DCDazY5fFDXIwzBZUNdFTV8TjTYK2Bxji/S7NEArsBCC8C\nv00g68eRcvffoQUwEThORLq75U1cRR+PQHK5/Q0BfoHjVwFoAqwRJyX/z6KqP4djnZqVkkZMqRhh\nMB1HgczHeVOcAKCqO4Ff4+zLPRUn42syvIKzX8U8nIf+DHymo1weEpGZOH6Eg4Hj3cgvX9k8vAAs\n9UQOdcLxl3yL8/C51WesU4C57njv42xOtT7IDanqTJx9ziNj3O9euho4ynVYf4freI7Tz1eq6peC\n/GKc32IWzrTTX3AsgBfcsunA39XZ/vdt4HzXUR7XIQ7cC/zSdbLHkvVPQDsRmYOTsfgYVV2Lk933\nZff3mojja4pHIrkucp34C3H8U2ep6gL32h046don4Py7e3keaI4zfWikCctSbNRqRKSpqm53LYjJ\nwOFBH+AB+/8P8LWqjklY2ajTiMhw4GRVvTxhZSNlzKdi1HY+EJF8IBe4M2SF8i2wGai2hX1GzSDO\nAtUTKI8AM9KEWSqGYRhGaJhPxTAMwwgNUyqGYRhGaJhSMQzDMELDlIphGIYRGqZUDMMwjND4fz7W\nfBF5jLPuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x185658a3c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data_Volume = all_data.SP_Volume / 1000000\n",
    "\n",
    "plt.axis([5962,0,14,12000])\n",
    "plt.plot(plot_data_Volume)\n",
    "plt.ylabel('S&P500 Volume (in millions)')\n",
    "plt.xlabel('Trading Days Since Most Recent Day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Calculate the 'Break_Coming' feature, which is a measure of whether the market will close for a break on the next day\n",
    "\n",
    "all_data['Break_Coming'] = all_data['Days_Since_Open'].shift(1)\n",
    "\n",
    "all_data.loc[all_data['Break_Coming']<=1,'Break_Coming'] = 0\n",
    "all_data.loc[all_data['Break_Coming']>1,'Break_Coming'] = 1\n",
    "\n",
    "all_data.Break_Coming.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the 'Overnight_Return' feature\n",
    "\n",
    "all_data['Overnight_Return'] = all_data['SP_Open'] / all_data['SP_Close'].shift(-1) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the 'No_Overnight_Change' value. This is not a feature, but was used to identify unreliable data rows\n",
    "# See accompanying report for further details\n",
    "\n",
    "all_data['No_Overnight_Change'] = all_data['Overnight_Return']\n",
    "\n",
    "all_data.loc[all_data['No_Overnight_Change']==0.00,'No_Overnight_Change'] = 1\n",
    "all_data.loc[all_data['No_Overnight_Change']!=1,'No_Overnight_Change'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the 'Overnight_VIX' feature, which measures whether the VIX has opened up or down relative to previous day\n",
    "\n",
    "all_data['Overnight_VIX'] = all_data['Vix_Open'] / all_data['Vix_Close'].shift(-1) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the 'O_to_O' feature, which compares the current opening price to the previous day\n",
    "\n",
    "all_data['O_to_O'] = all_data['SP_Open'] / all_data['SP_Open'].shift(-1) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate 11 different trailing return features, 9 based on the S&P500 data and 2 based on VIX data\n",
    "\n",
    "all_data['Trail_1d_Ret'] = all_data['SP_Close'].shift(-1) / all_data['SP_Close'].shift(-2) - 1\n",
    "all_data['Trail_2d_Ret'] = all_data['SP_Close'].shift(-1) / all_data['SP_Close'].shift(-3) - 1\n",
    "all_data['Trail_3d_Ret'] = all_data['SP_Close'].shift(-1) / all_data['SP_Close'].shift(-4) - 1\n",
    "all_data['Trail_4d_Ret'] = all_data['SP_Close'].shift(-1) / all_data['SP_Close'].shift(-5) - 1\n",
    "all_data['Trail_5d_Ret'] = all_data['SP_Close'].shift(-1) / all_data['SP_Close'].shift(-6) - 1\n",
    "all_data['Trail_21d_Ret'] = all_data['SP_Close'].shift(-1) / all_data['SP_Close'].shift(-22) - 1\n",
    "all_data['Trail_63d_Ret'] = all_data['SP_Close'].shift(-1) / all_data['SP_Close'].shift(-64) - 1\n",
    "all_data['Trail_126d_Ret'] = all_data['SP_Close'].shift(-1) / all_data['SP_Close'].shift(-127) - 1\n",
    "all_data['Trail_252d_Ret'] = all_data['SP_Close'].shift(-1) / all_data['SP_Close'].shift(-253) - 1\n",
    "\n",
    "all_data['Trail_1d_VIX'] = all_data['Vix_Close'].shift(-1) / all_data['Vix_Close'].shift(-2) - 1\n",
    "all_data['Trail_5d_VIX'] = all_data['Vix_Close'].shift(-1) / all_data['Vix_Close'].shift(-6) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate 2 different trailing volume features, which measure whether the last day's volume is above or below\n",
    "# recent averages\n",
    "\n",
    "all_data['Trail_1d_Rel_Vol'] = all_data['SP_Volume'].shift(-1) / (\n",
    "    all_data['SP_Volume'].rolling(window=4).mean().shift(-5)) - 1\n",
    "\n",
    "all_data['Trail_5d_Rel_Vol'] = all_data['SP_Volume'].rolling(window=5).mean().shift(-5) / (\n",
    "    all_data['SP_Volume'].rolling(window=21).mean().shift(-26)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the 'Trail_1d_PtT' feature, which measure how much the S&P500 moved from high to low values on the \n",
    "# previous trading day\n",
    "\n",
    "all_data['Trail_1d_PtT'] = (all_data['SP_High'].shift(-1) - all_data['SP_Low'].shift(-1)) / (0.5*(\n",
    "        all_data['SP_Open'].shift(-1) + all_data['SP_Close'].shift(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the 'Trail_1d_VIX_PtT' feature, which measure how much the VIX moved from high to low values on the \n",
    "# previous trading day\n",
    "\n",
    "all_data['Trail_1d_VIX_PtT'] = (all_data['Vix_High'].shift(-1) - all_data['Vix_Low'].shift(-1)) / (0.5*(\n",
    "        all_data['Vix_Open'].shift(-1) + all_data['Vix_Close'].shift(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the 'Intraday_Increase' label, which is ultimately what the machine learner should predict, and as is a\n",
    "# measure of whether the S&P500 increased on a given day (value = 1) or not (value = 0)\n",
    "\n",
    "all_data['Intraday_Increase'] = all_data['SP_Close'] - all_data['SP_Open']\n",
    "\n",
    "all_data.loc[all_data['Intraday_Increase']>0,'Intraday_Increase'] = 1\n",
    "all_data.loc[all_data['Intraday_Increase']<=0,'Intraday_Increase'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 5709\n"
     ]
    }
   ],
   "source": [
    "noNA_data = all_data.dropna()\n",
    "\n",
    "print (\"Number of data points:\", len(noNA_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 2678\n"
     ]
    }
   ],
   "source": [
    "validated_data = noNA_data[noNA_data.No_Overnight_Change != 1]\n",
    "print (\"Number of data points:\", len(validated_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'SP_Open', 'SP_High', 'SP_Low', 'SP_Close', 'SP_Volume',\n",
      "       'Vix_Open', 'Vix_High', 'Vix_Low', 'Vix_Close', 'Days_Since_Open',\n",
      "       'Break_Coming', 'Overnight_Return', 'No_Overnight_Change',\n",
      "       'Overnight_VIX', 'O_to_O', 'Trail_1d_Ret', 'Trail_2d_Ret',\n",
      "       'Trail_3d_Ret', 'Trail_4d_Ret', 'Trail_5d_Ret', 'Trail_21d_Ret',\n",
      "       'Trail_63d_Ret', 'Trail_126d_Ret', 'Trail_252d_Ret', 'Trail_1d_VIX',\n",
      "       'Trail_5d_VIX', 'Trail_1d_Rel_Vol', 'Trail_5d_Rel_Vol', 'Trail_1d_PtT',\n",
      "       'Trail_1d_VIX_PtT', 'Intraday_Increase'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print the column headers of the current data set\n",
    "print (validated_data.dtypes.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop the columns that are not one of the 20 features or the label\n",
    "data = validated_data.drop(validated_data.columns[[0,1,2,3,4,5,6,7,8,9,13]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Days_Since_Open', 'Break_Coming', 'Overnight_Return', 'Overnight_VIX',\n",
      "       'O_to_O', 'Trail_1d_Ret', 'Trail_2d_Ret', 'Trail_3d_Ret',\n",
      "       'Trail_4d_Ret', 'Trail_5d_Ret', 'Trail_21d_Ret', 'Trail_63d_Ret',\n",
      "       'Trail_126d_Ret', 'Trail_252d_Ret', 'Trail_1d_VIX', 'Trail_5d_VIX',\n",
      "       'Trail_1d_Rel_Vol', 'Trail_5d_Rel_Vol', 'Trail_1d_PtT',\n",
      "       'Trail_1d_VIX_PtT', 'Intraday_Increase'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print the headers of 'data', to validate that the correct columns were dropped\n",
    "print (data.dtypes.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"eval-data.csv\", data, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Days_Since_Open</th>\n",
       "      <th>Break_Coming</th>\n",
       "      <th>Overnight_Return</th>\n",
       "      <th>Overnight_VIX</th>\n",
       "      <th>O_to_O</th>\n",
       "      <th>Trail_1d_Ret</th>\n",
       "      <th>Trail_2d_Ret</th>\n",
       "      <th>Trail_3d_Ret</th>\n",
       "      <th>Trail_4d_Ret</th>\n",
       "      <th>Trail_5d_Ret</th>\n",
       "      <th>...</th>\n",
       "      <th>Trail_63d_Ret</th>\n",
       "      <th>Trail_126d_Ret</th>\n",
       "      <th>Trail_252d_Ret</th>\n",
       "      <th>Trail_1d_VIX</th>\n",
       "      <th>Trail_5d_VIX</th>\n",
       "      <th>Trail_1d_Rel_Vol</th>\n",
       "      <th>Trail_5d_Rel_Vol</th>\n",
       "      <th>Trail_1d_PtT</th>\n",
       "      <th>Trail_1d_VIX_PtT</th>\n",
       "      <th>Intraday_Increase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2678.000000</td>\n",
       "      <td>2678.000000</td>\n",
       "      <td>2678.000000</td>\n",
       "      <td>2678.000000</td>\n",
       "      <td>2678.000000</td>\n",
       "      <td>2678.000000</td>\n",
       "      <td>2678.000000</td>\n",
       "      <td>2678.000000</td>\n",
       "      <td>2678.000000</td>\n",
       "      <td>2678.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2678.000000</td>\n",
       "      <td>2678.000000</td>\n",
       "      <td>2678.000000</td>\n",
       "      <td>2678.000000</td>\n",
       "      <td>2678.000000</td>\n",
       "      <td>2678.000000</td>\n",
       "      <td>2678.000000</td>\n",
       "      <td>2678.000000</td>\n",
       "      <td>2678.000000</td>\n",
       "      <td>2678.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.444735</td>\n",
       "      <td>0.210978</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.005908</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013449</td>\n",
       "      <td>0.029453</td>\n",
       "      <td>0.059645</td>\n",
       "      <td>0.002947</td>\n",
       "      <td>0.010982</td>\n",
       "      <td>0.008819</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.013533</td>\n",
       "      <td>0.085928</td>\n",
       "      <td>0.547050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.875799</td>\n",
       "      <td>0.408079</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.045081</td>\n",
       "      <td>0.012292</td>\n",
       "      <td>0.012973</td>\n",
       "      <td>0.017303</td>\n",
       "      <td>0.020321</td>\n",
       "      <td>0.023078</td>\n",
       "      <td>0.025472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081302</td>\n",
       "      <td>0.124501</td>\n",
       "      <td>0.173760</td>\n",
       "      <td>0.074680</td>\n",
       "      <td>0.155039</td>\n",
       "      <td>0.181773</td>\n",
       "      <td>0.156196</td>\n",
       "      <td>0.011147</td>\n",
       "      <td>0.050513</td>\n",
       "      <td>0.497874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.014194</td>\n",
       "      <td>-0.300366</td>\n",
       "      <td>-0.087119</td>\n",
       "      <td>-0.090350</td>\n",
       "      <td>-0.124174</td>\n",
       "      <td>-0.139059</td>\n",
       "      <td>-0.172221</td>\n",
       "      <td>-0.183401</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.417706</td>\n",
       "      <td>-0.464658</td>\n",
       "      <td>-0.488228</td>\n",
       "      <td>-0.295726</td>\n",
       "      <td>-0.426630</td>\n",
       "      <td>-0.832518</td>\n",
       "      <td>-0.669690</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.014966</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000407</td>\n",
       "      <td>-0.016031</td>\n",
       "      <td>-0.004256</td>\n",
       "      <td>-0.004494</td>\n",
       "      <td>-0.006988</td>\n",
       "      <td>-0.007946</td>\n",
       "      <td>-0.009736</td>\n",
       "      <td>-0.010137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022581</td>\n",
       "      <td>-0.027543</td>\n",
       "      <td>-0.004349</td>\n",
       "      <td>-0.040230</td>\n",
       "      <td>-0.079295</td>\n",
       "      <td>-0.090512</td>\n",
       "      <td>-0.083042</td>\n",
       "      <td>0.006880</td>\n",
       "      <td>0.053312</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.003111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026604</td>\n",
       "      <td>0.043190</td>\n",
       "      <td>0.089677</td>\n",
       "      <td>-0.005022</td>\n",
       "      <td>-0.009048</td>\n",
       "      <td>-0.005982</td>\n",
       "      <td>-0.000374</td>\n",
       "      <td>0.010471</td>\n",
       "      <td>0.074426</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.024785</td>\n",
       "      <td>0.005425</td>\n",
       "      <td>0.005642</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>0.010729</td>\n",
       "      <td>0.012735</td>\n",
       "      <td>0.014399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061822</td>\n",
       "      <td>0.097326</td>\n",
       "      <td>0.163089</td>\n",
       "      <td>0.036402</td>\n",
       "      <td>0.072292</td>\n",
       "      <td>0.090148</td>\n",
       "      <td>0.089807</td>\n",
       "      <td>0.016249</td>\n",
       "      <td>0.103512</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015046</td>\n",
       "      <td>0.510725</td>\n",
       "      <td>0.106712</td>\n",
       "      <td>0.115800</td>\n",
       "      <td>0.132064</td>\n",
       "      <td>0.139480</td>\n",
       "      <td>0.179735</td>\n",
       "      <td>0.191112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388172</td>\n",
       "      <td>0.502372</td>\n",
       "      <td>0.685735</td>\n",
       "      <td>0.642152</td>\n",
       "      <td>2.129032</td>\n",
       "      <td>2.045477</td>\n",
       "      <td>0.947982</td>\n",
       "      <td>0.107198</td>\n",
       "      <td>0.734623</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Days_Since_Open  Break_Coming  Overnight_Return  Overnight_VIX  \\\n",
       "count      2678.000000   2678.000000       2678.000000    2678.000000   \n",
       "mean          1.444735      0.210978         -0.000022       0.005908   \n",
       "std           0.875799      0.408079          0.001603       0.045081   \n",
       "min           1.000000      0.000000         -0.014194      -0.300366   \n",
       "25%           1.000000      0.000000         -0.000407      -0.016031   \n",
       "50%           1.000000      0.000000         -0.000008       0.000820   \n",
       "75%           1.000000      0.000000          0.000500       0.024785   \n",
       "max           5.000000      1.000000          0.015046       0.510725   \n",
       "\n",
       "            O_to_O  Trail_1d_Ret  Trail_2d_Ret  Trail_3d_Ret  Trail_4d_Ret  \\\n",
       "count  2678.000000   2678.000000   2678.000000   2678.000000   2678.000000   \n",
       "mean      0.000251      0.000260      0.000511      0.000612      0.000847   \n",
       "std       0.012292      0.012973      0.017303      0.020321      0.023078   \n",
       "min      -0.087119     -0.090350     -0.124174     -0.139059     -0.172221   \n",
       "25%      -0.004256     -0.004494     -0.006988     -0.007946     -0.009736   \n",
       "50%       0.000642      0.000569      0.001294      0.002182      0.002630   \n",
       "75%       0.005425      0.005642      0.008789      0.010729      0.012735   \n",
       "max       0.106712      0.115800      0.132064      0.139480      0.179735   \n",
       "\n",
       "       Trail_5d_Ret        ...          Trail_63d_Ret  Trail_126d_Ret  \\\n",
       "count   2678.000000        ...            2678.000000     2678.000000   \n",
       "mean       0.001112        ...               0.013449        0.029453   \n",
       "std        0.025472        ...               0.081302        0.124501   \n",
       "min       -0.183401        ...              -0.417706       -0.464658   \n",
       "25%       -0.010137        ...              -0.022581       -0.027543   \n",
       "50%        0.003111        ...               0.026604        0.043190   \n",
       "75%        0.014399        ...               0.061822        0.097326   \n",
       "max        0.191112        ...               0.388172        0.502372   \n",
       "\n",
       "       Trail_252d_Ret  Trail_1d_VIX  Trail_5d_VIX  Trail_1d_Rel_Vol  \\\n",
       "count     2678.000000   2678.000000   2678.000000       2678.000000   \n",
       "mean         0.059645      0.002947      0.010982          0.008819   \n",
       "std          0.173760      0.074680      0.155039          0.181773   \n",
       "min         -0.488228     -0.295726     -0.426630         -0.832518   \n",
       "25%         -0.004349     -0.040230     -0.079295         -0.090512   \n",
       "50%          0.089677     -0.005022     -0.009048         -0.005982   \n",
       "75%          0.163089      0.036402      0.072292          0.090148   \n",
       "max          0.685735      0.642152      2.129032          2.045477   \n",
       "\n",
       "       Trail_5d_Rel_Vol  Trail_1d_PtT  Trail_1d_VIX_PtT  Intraday_Increase  \n",
       "count       2678.000000   2678.000000       2678.000000        2678.000000  \n",
       "mean           0.010441      0.013533          0.085928           0.547050  \n",
       "std            0.156196      0.011147          0.050513           0.497874  \n",
       "min           -0.669690      0.002009          0.014966           0.000000  \n",
       "25%           -0.083042      0.006880          0.053312           0.000000  \n",
       "50%           -0.000374      0.010471          0.074426           1.000000  \n",
       "75%            0.089807      0.016249          0.103512           1.000000  \n",
       "max            0.947982      0.107198          0.734623           1.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intraday_Increase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2678.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.547050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.497871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Intraday_Increase\n",
       "count        2678.000000\n",
       "mean            0.547050\n",
       "std             0.497871\n",
       "min             0.000000\n",
       "25%             0.000000\n",
       "50%             1.000000\n",
       "75%             1.000000\n",
       "max             1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = pd.DataFrame(data.loc[:,'Days_Since_Open':'Trail_1d_VIX_PtT'],dtype='float32')\n",
    "y = pd.DataFrame(data.loc[:,'Intraday_Increase'],dtype='float32')\n",
    "\n",
    "# Summarize the label data\n",
    "display(y.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Days_Since_Open</th>\n",
       "      <th>Break_Coming</th>\n",
       "      <th>Overnight_Return</th>\n",
       "      <th>Overnight_VIX</th>\n",
       "      <th>O_to_O</th>\n",
       "      <th>Trail_1d_Ret</th>\n",
       "      <th>Trail_2d_Ret</th>\n",
       "      <th>Trail_3d_Ret</th>\n",
       "      <th>Trail_4d_Ret</th>\n",
       "      <th>Trail_5d_Ret</th>\n",
       "      <th>Trail_21d_Ret</th>\n",
       "      <th>Trail_63d_Ret</th>\n",
       "      <th>Trail_126d_Ret</th>\n",
       "      <th>Trail_252d_Ret</th>\n",
       "      <th>Trail_1d_VIX</th>\n",
       "      <th>Trail_5d_VIX</th>\n",
       "      <th>Trail_1d_Rel_Vol</th>\n",
       "      <th>Trail_5d_Rel_Vol</th>\n",
       "      <th>Trail_1d_PtT</th>\n",
       "      <th>Trail_1d_VIX_PtT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "      <td>2426.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.444353</td>\n",
       "      <td>0.211047</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.005527</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>0.013012</td>\n",
       "      <td>0.030937</td>\n",
       "      <td>0.065235</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.012115</td>\n",
       "      <td>0.009098</td>\n",
       "      <td>0.011425</td>\n",
       "      <td>0.013841</td>\n",
       "      <td>0.083890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.874623</td>\n",
       "      <td>0.408140</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.043615</td>\n",
       "      <td>0.012631</td>\n",
       "      <td>0.013309</td>\n",
       "      <td>0.017728</td>\n",
       "      <td>0.020805</td>\n",
       "      <td>0.023623</td>\n",
       "      <td>0.026056</td>\n",
       "      <td>0.048482</td>\n",
       "      <td>0.083473</td>\n",
       "      <td>0.128763</td>\n",
       "      <td>0.180816</td>\n",
       "      <td>0.073607</td>\n",
       "      <td>0.153743</td>\n",
       "      <td>0.182354</td>\n",
       "      <td>0.158147</td>\n",
       "      <td>0.011501</td>\n",
       "      <td>0.050290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.014194</td>\n",
       "      <td>-0.300366</td>\n",
       "      <td>-0.087119</td>\n",
       "      <td>-0.090350</td>\n",
       "      <td>-0.124174</td>\n",
       "      <td>-0.139059</td>\n",
       "      <td>-0.172221</td>\n",
       "      <td>-0.183401</td>\n",
       "      <td>-0.280077</td>\n",
       "      <td>-0.417706</td>\n",
       "      <td>-0.464658</td>\n",
       "      <td>-0.488228</td>\n",
       "      <td>-0.295727</td>\n",
       "      <td>-0.393590</td>\n",
       "      <td>-0.832518</td>\n",
       "      <td>-0.669690</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.014966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000342</td>\n",
       "      <td>-0.015761</td>\n",
       "      <td>-0.004302</td>\n",
       "      <td>-0.004533</td>\n",
       "      <td>-0.007193</td>\n",
       "      <td>-0.008456</td>\n",
       "      <td>-0.010041</td>\n",
       "      <td>-0.010553</td>\n",
       "      <td>-0.018995</td>\n",
       "      <td>-0.022675</td>\n",
       "      <td>-0.027350</td>\n",
       "      <td>0.004498</td>\n",
       "      <td>-0.039352</td>\n",
       "      <td>-0.076418</td>\n",
       "      <td>-0.090298</td>\n",
       "      <td>-0.082820</td>\n",
       "      <td>0.007032</td>\n",
       "      <td>0.052200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.011066</td>\n",
       "      <td>0.026493</td>\n",
       "      <td>0.048630</td>\n",
       "      <td>0.104952</td>\n",
       "      <td>-0.004886</td>\n",
       "      <td>-0.007810</td>\n",
       "      <td>-0.005607</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.010627</td>\n",
       "      <td>0.072389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.024386</td>\n",
       "      <td>0.005476</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>0.008879</td>\n",
       "      <td>0.010794</td>\n",
       "      <td>0.012735</td>\n",
       "      <td>0.014443</td>\n",
       "      <td>0.031853</td>\n",
       "      <td>0.062510</td>\n",
       "      <td>0.101349</td>\n",
       "      <td>0.173855</td>\n",
       "      <td>0.035583</td>\n",
       "      <td>0.072183</td>\n",
       "      <td>0.091046</td>\n",
       "      <td>0.092600</td>\n",
       "      <td>0.016484</td>\n",
       "      <td>0.100435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015046</td>\n",
       "      <td>0.292127</td>\n",
       "      <td>0.106712</td>\n",
       "      <td>0.115800</td>\n",
       "      <td>0.132064</td>\n",
       "      <td>0.139480</td>\n",
       "      <td>0.179735</td>\n",
       "      <td>0.191112</td>\n",
       "      <td>0.234342</td>\n",
       "      <td>0.388172</td>\n",
       "      <td>0.502372</td>\n",
       "      <td>0.685735</td>\n",
       "      <td>0.642152</td>\n",
       "      <td>2.129032</td>\n",
       "      <td>2.045477</td>\n",
       "      <td>0.947982</td>\n",
       "      <td>0.107198</td>\n",
       "      <td>0.734623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Days_Since_Open  Break_Coming  Overnight_Return  Overnight_VIX  \\\n",
       "count      2426.000000   2426.000000       2426.000000    2426.000000   \n",
       "mean          1.444353      0.211047         -0.000024       0.005527   \n",
       "std           0.874623      0.408140          0.001603       0.043615   \n",
       "min           1.000000      0.000000         -0.014194      -0.300366   \n",
       "25%           1.000000      0.000000         -0.000342      -0.015761   \n",
       "50%           1.000000      0.000000         -0.000008       0.000790   \n",
       "75%           1.000000      0.000000          0.000466       0.024386   \n",
       "max           5.000000      1.000000          0.015046       0.292127   \n",
       "\n",
       "            O_to_O  Trail_1d_Ret  Trail_2d_Ret  Trail_3d_Ret  Trail_4d_Ret  \\\n",
       "count  2426.000000   2426.000000   2426.000000   2426.000000   2426.000000   \n",
       "mean      0.000217      0.000224      0.000441      0.000505      0.000714   \n",
       "std       0.012631      0.013309      0.017728      0.020805      0.023623   \n",
       "min      -0.087119     -0.090350     -0.124174     -0.139059     -0.172221   \n",
       "25%      -0.004302     -0.004533     -0.007193     -0.008456     -0.010041   \n",
       "50%       0.000642      0.000622      0.001292      0.002193      0.002646   \n",
       "75%       0.005476      0.005689      0.008879      0.010794      0.012735   \n",
       "max       0.106712      0.115800      0.132064      0.139480      0.179735   \n",
       "\n",
       "       Trail_5d_Ret  Trail_21d_Ret  Trail_63d_Ret  Trail_126d_Ret  \\\n",
       "count   2426.000000    2426.000000    2426.000000     2426.000000   \n",
       "mean       0.000955       0.003691       0.013012        0.030937   \n",
       "std        0.026056       0.048482       0.083473        0.128763   \n",
       "min       -0.183401      -0.280077      -0.417706       -0.464658   \n",
       "25%       -0.010553      -0.018995      -0.022675       -0.027350   \n",
       "50%        0.003077       0.011066       0.026493        0.048630   \n",
       "75%        0.014443       0.031853       0.062510        0.101349   \n",
       "max        0.191112       0.234342       0.388172        0.502372   \n",
       "\n",
       "       Trail_252d_Ret  Trail_1d_VIX  Trail_5d_VIX  Trail_1d_Rel_Vol  \\\n",
       "count     2426.000000   2426.000000   2426.000000       2426.000000   \n",
       "mean         0.065235      0.003223      0.012115          0.009098   \n",
       "std          0.180816      0.073607      0.153743          0.182354   \n",
       "min         -0.488228     -0.295727     -0.393590         -0.832518   \n",
       "25%          0.004498     -0.039352     -0.076418         -0.090298   \n",
       "50%          0.104952     -0.004886     -0.007810         -0.005607   \n",
       "75%          0.173855      0.035583      0.072183          0.091046   \n",
       "max          0.685735      0.642152      2.129032          2.045477   \n",
       "\n",
       "       Trail_5d_Rel_Vol  Trail_1d_PtT  Trail_1d_VIX_PtT  \n",
       "count       2426.000000   2426.000000       2426.000000  \n",
       "mean           0.011425      0.013841          0.083890  \n",
       "std            0.158147      0.011501          0.050290  \n",
       "min           -0.669690      0.002009          0.014966  \n",
       "25%           -0.082820      0.007032          0.052200  \n",
       "50%            0.000701      0.010627          0.072389  \n",
       "75%            0.092600      0.016484          0.100435  \n",
       "max            0.947982      0.107198          0.734623  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Days_Since_Open</th>\n",
       "      <th>Break_Coming</th>\n",
       "      <th>Overnight_Return</th>\n",
       "      <th>Overnight_VIX</th>\n",
       "      <th>O_to_O</th>\n",
       "      <th>Trail_1d_Ret</th>\n",
       "      <th>Trail_2d_Ret</th>\n",
       "      <th>Trail_3d_Ret</th>\n",
       "      <th>Trail_4d_Ret</th>\n",
       "      <th>Trail_5d_Ret</th>\n",
       "      <th>Trail_21d_Ret</th>\n",
       "      <th>Trail_63d_Ret</th>\n",
       "      <th>Trail_126d_Ret</th>\n",
       "      <th>Trail_252d_Ret</th>\n",
       "      <th>Trail_1d_VIX</th>\n",
       "      <th>Trail_5d_VIX</th>\n",
       "      <th>Trail_1d_Rel_Vol</th>\n",
       "      <th>Trail_5d_Rel_Vol</th>\n",
       "      <th>Trail_1d_PtT</th>\n",
       "      <th>Trail_1d_VIX_PtT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>2.520000e+02</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.448413</td>\n",
       "      <td>0.210317</td>\n",
       "      <td>4.407181e-07</td>\n",
       "      <td>0.009577</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>0.009352</td>\n",
       "      <td>0.017652</td>\n",
       "      <td>0.015159</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.006127</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.105551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.888909</td>\n",
       "      <td>0.408345</td>\n",
       "      <td>1.604419e-03</td>\n",
       "      <td>0.057292</td>\n",
       "      <td>0.008363</td>\n",
       "      <td>0.009143</td>\n",
       "      <td>0.012497</td>\n",
       "      <td>0.014866</td>\n",
       "      <td>0.016942</td>\n",
       "      <td>0.018933</td>\n",
       "      <td>0.037278</td>\n",
       "      <td>0.056219</td>\n",
       "      <td>0.070058</td>\n",
       "      <td>0.054138</td>\n",
       "      <td>0.084439</td>\n",
       "      <td>0.166937</td>\n",
       "      <td>0.176414</td>\n",
       "      <td>0.135903</td>\n",
       "      <td>0.006132</td>\n",
       "      <td>0.048502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.602164e-03</td>\n",
       "      <td>-0.102524</td>\n",
       "      <td>-0.034395</td>\n",
       "      <td>-0.035920</td>\n",
       "      <td>-0.053366</td>\n",
       "      <td>-0.046948</td>\n",
       "      <td>-0.049341</td>\n",
       "      <td>-0.059645</td>\n",
       "      <td>-0.092491</td>\n",
       "      <td>-0.121361</td>\n",
       "      <td>-0.123185</td>\n",
       "      <td>-0.115759</td>\n",
       "      <td>-0.213836</td>\n",
       "      <td>-0.426630</td>\n",
       "      <td>-0.676333</td>\n",
       "      <td>-0.430812</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.031952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.001223e-03</td>\n",
       "      <td>-0.017472</td>\n",
       "      <td>-0.003650</td>\n",
       "      <td>-0.003330</td>\n",
       "      <td>-0.004971</td>\n",
       "      <td>-0.006011</td>\n",
       "      <td>-0.006977</td>\n",
       "      <td>-0.006892</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.021088</td>\n",
       "      <td>-0.027548</td>\n",
       "      <td>-0.023973</td>\n",
       "      <td>-0.053735</td>\n",
       "      <td>-0.113056</td>\n",
       "      <td>-0.093940</td>\n",
       "      <td>-0.085283</td>\n",
       "      <td>0.006028</td>\n",
       "      <td>0.073073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.708986e-05</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.009779</td>\n",
       "      <td>0.029720</td>\n",
       "      <td>0.006411</td>\n",
       "      <td>-0.002416</td>\n",
       "      <td>-0.008548</td>\n",
       "      <td>-0.021378</td>\n",
       "      <td>-0.008384</td>\n",
       "      <td>-0.012706</td>\n",
       "      <td>0.008984</td>\n",
       "      <td>0.094671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.068254e-04</td>\n",
       "      <td>0.028720</td>\n",
       "      <td>0.004812</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0.007628</td>\n",
       "      <td>0.009715</td>\n",
       "      <td>0.012169</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>0.031173</td>\n",
       "      <td>0.059052</td>\n",
       "      <td>0.047859</td>\n",
       "      <td>0.034760</td>\n",
       "      <td>0.044724</td>\n",
       "      <td>0.073382</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.076359</td>\n",
       "      <td>0.013615</td>\n",
       "      <td>0.125867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.499757e-03</td>\n",
       "      <td>0.510725</td>\n",
       "      <td>0.022672</td>\n",
       "      <td>0.024760</td>\n",
       "      <td>0.036357</td>\n",
       "      <td>0.053437</td>\n",
       "      <td>0.054647</td>\n",
       "      <td>0.055947</td>\n",
       "      <td>0.109475</td>\n",
       "      <td>0.130730</td>\n",
       "      <td>0.195022</td>\n",
       "      <td>0.164826</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.646860</td>\n",
       "      <td>1.308129</td>\n",
       "      <td>0.466593</td>\n",
       "      <td>0.034405</td>\n",
       "      <td>0.334444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Days_Since_Open  Break_Coming  Overnight_Return  Overnight_VIX  \\\n",
       "count       252.000000    252.000000      2.520000e+02     252.000000   \n",
       "mean          1.448413      0.210317      4.407181e-07       0.009577   \n",
       "std           0.888909      0.408345      1.604419e-03       0.057292   \n",
       "min           1.000000      0.000000     -5.602164e-03      -0.102524   \n",
       "25%           1.000000      0.000000     -1.001223e-03      -0.017472   \n",
       "50%           1.000000      0.000000      6.708986e-05       0.002482   \n",
       "75%           1.000000      0.000000      9.068254e-04       0.028720   \n",
       "max           4.000000      1.000000      4.499757e-03       0.510725   \n",
       "\n",
       "           O_to_O  Trail_1d_Ret  Trail_2d_Ret  Trail_3d_Ret  Trail_4d_Ret  \\\n",
       "count  252.000000    252.000000    252.000000    252.000000    252.000000   \n",
       "mean     0.000587      0.000605      0.001189      0.001640      0.002124   \n",
       "std      0.008363      0.009143      0.012497      0.014866      0.016942   \n",
       "min     -0.034395     -0.035920     -0.053366     -0.046948     -0.049341   \n",
       "25%     -0.003650     -0.003330     -0.004971     -0.006011     -0.006977   \n",
       "50%      0.000573      0.000209      0.001337      0.001823      0.002451   \n",
       "75%      0.004812      0.005236      0.007628      0.009715      0.012169   \n",
       "max      0.022672      0.024760      0.036357      0.053437      0.054647   \n",
       "\n",
       "       Trail_5d_Ret  Trail_21d_Ret  Trail_63d_Ret  Trail_126d_Ret  \\\n",
       "count    252.000000     252.000000     252.000000      252.000000   \n",
       "mean       0.002622       0.009352       0.017652        0.015159   \n",
       "std        0.018933       0.037278       0.056219        0.070058   \n",
       "min       -0.059645      -0.092491      -0.121361       -0.123185   \n",
       "25%       -0.006892      -0.011080      -0.021088       -0.027548   \n",
       "50%        0.003944       0.009779       0.029720        0.006411   \n",
       "75%        0.013917       0.031173       0.059052        0.047859   \n",
       "max        0.055947       0.109475       0.130730        0.195022   \n",
       "\n",
       "       Trail_252d_Ret  Trail_1d_VIX  Trail_5d_VIX  Trail_1d_Rel_Vol  \\\n",
       "count      252.000000    252.000000    252.000000        252.000000   \n",
       "mean         0.005831      0.000298      0.000078          0.006127   \n",
       "std          0.054138      0.084439      0.166937          0.176414   \n",
       "min         -0.115759     -0.213836     -0.426630         -0.676333   \n",
       "25%         -0.023973     -0.053735     -0.113056         -0.093940   \n",
       "50%         -0.002416     -0.008548     -0.021378         -0.008384   \n",
       "75%          0.034760      0.044724      0.073382          0.084300   \n",
       "max          0.164826      0.493333      0.646860          1.308129   \n",
       "\n",
       "       Trail_5d_Rel_Vol  Trail_1d_PtT  Trail_1d_VIX_PtT  \n",
       "count        252.000000    252.000000        252.000000  \n",
       "mean           0.000971      0.010563          0.105551  \n",
       "std            0.135903      0.006132          0.048502  \n",
       "min           -0.430812      0.002597          0.031952  \n",
       "25%           -0.085283      0.006028          0.073073  \n",
       "50%           -0.012706      0.008984          0.094671  \n",
       "75%            0.076359      0.013615          0.125867  \n",
       "max            0.466593      0.034405          0.334444  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2426.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.549052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.497694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  2426.000000\n",
       "mean      0.549052\n",
       "std       0.497694\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       1.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>252.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  252.000000\n",
       "mean     0.527778\n",
       "std      0.500221\n",
       "min      0.000000\n",
       "25%      0.000000\n",
       "50%      1.000000\n",
       "75%      1.000000\n",
       "max      1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the data into train, validation and test sets:\n",
    "# Shuffling will not be used because test data should be drawn from the latest data points, to remove any risk of\n",
    "# the learning algorithms glimpsing the future\n",
    "\n",
    "X_train = X[252:]\n",
    "X_test = X[:252]\n",
    "\n",
    "y_train = y[252:]\n",
    "y_test = y[:252]\n",
    "\n",
    "y_train = np.reshape(y_train.values,[2426,])\n",
    "y_test = np.reshape(y_test.values,[252,])\n",
    "\n",
    "describe_train = pd.DataFrame(X_train)\n",
    "describe_test = pd.DataFrame(X_test)\n",
    "\n",
    "describe_train_labels = pd.DataFrame(y_train)\n",
    "describe_test_labels = pd.DataFrame(y_test)\n",
    "\n",
    "\n",
    "display(describe_train.describe())\n",
    "display(describe_test.describe())\n",
    "\n",
    "display(describe_train_labels.describe())\n",
    "display(describe_test_labels.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for predicting all \"up (1)\" on test set: 0.6909\n",
      "Accuracy score for predicting all \"up (1)\" on test set: 0.5278\n"
     ]
    }
   ],
   "source": [
    "# Calculate the benchmark values, against which the learners will be assessed\n",
    "\n",
    "# A suitable benchmark for the models would be comparing to the case where one simply predicts all 1s on the test set\n",
    "# i.e. simply assume the market will go up every day, as it historically has on 52-54% of days in the time range\n",
    "# under consideration here:\n",
    "\n",
    "# Benchmark F1 score results from simply predicting all '1' on the test set\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "print (\"F1 score for predicting all \\\"up (1)\\\" on test set: {:.4f}\".format(\n",
    "    f1_score(y_test, [1]*len(y_test), pos_label=1, average='binary')))\n",
    "\n",
    "# Benchmark accuracy score results from simply predicting all '1' on the test set\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print (\"Accuracy score for predicting all \\\"up (1)\\\" on test set: {:.4f}\".format(\n",
    "    accuracy_score(y_test, [1]*len(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up a series of functions for monitoring training and testing of the various learning algorithms\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print (\"Trained model in {:.4f} seconds\".format(end - start))\n",
    "\n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Print and return results\n",
    "    print (\"Made predictions in {:.4f} seconds.\".format(end - start))\n",
    "    return f1_score(target, y_pred, pos_label=1)\n",
    "\n",
    "def predict_labels_accuracy(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on the accuracy score. '''\n",
    "    \n",
    "    y_pred = clf.predict(features)\n",
    "    \n",
    "    # Print and return results\n",
    "    return accuracy_score(target, y_pred)   \n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print (\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    print (\"F1 score for training set: {:.4f}.\".format(predict_labels(clf, X_train, y_train)))\n",
    "    print (\"Accuracy score for training set: {:.4f}.\".format(predict_labels_accuracy(clf, X_train, y_train)))\n",
    "    print (\"F1 score for test set: {:.4f}.\".format(predict_labels(clf, X_test, y_test)))\n",
    "    print (\"Accuracy score for test set: {:.4f}.\".format(predict_labels_accuracy(clf, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import  three supervised learning models from sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DecisionTreeClassifier: \n",
      "\n",
      "Training a DecisionTreeClassifier using a training set size of 800. . .\n",
      "Trained model in 0.2143 seconds\n",
      "Made predictions in 0.0113 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "Made predictions in 0.0005 seconds.\n",
      "F1 score for test set: 0.5292.\n",
      "Accuracy score for test set: 0.5198.\n",
      "--------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1600. . .\n",
      "Trained model in 0.0375 seconds\n",
      "Made predictions in 0.0010 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for test set: 0.6043.\n",
      "Accuracy score for test set: 0.5635.\n",
      "--------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 2426. . .\n",
      "Trained model in 0.0465 seconds\n",
      "Made predictions in 0.0005 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "Made predictions in 0.0005 seconds.\n",
      "F1 score for test set: 0.5827.\n",
      "Accuracy score for test set: 0.5397.\n",
      "--------------------------------\n",
      "\n",
      "GaussianNB: \n",
      "\n",
      "Training a GaussianNB using a training set size of 800. . .\n",
      "Trained model in 0.0015 seconds\n",
      "Made predictions in 0.0005 seconds.\n",
      "F1 score for training set: 0.7220.\n",
      "Accuracy score for training set: 0.6650.\n",
      "Made predictions in 0.0005 seconds.\n",
      "F1 score for test set: 0.6400.\n",
      "Accuracy score for test set: 0.6071.\n",
      "--------------------------------\n",
      "Training a GaussianNB using a training set size of 1600. . .\n",
      "Trained model in 0.0010 seconds\n",
      "Made predictions in 0.0005 seconds.\n",
      "F1 score for training set: 0.7073.\n",
      "Accuracy score for training set: 0.6219.\n",
      "Made predictions in 0.0005 seconds.\n",
      "F1 score for test set: 0.6543.\n",
      "Accuracy score for test set: 0.5556.\n",
      "--------------------------------\n",
      "Training a GaussianNB using a training set size of 2426. . .\n",
      "Trained model in 0.0015 seconds\n",
      "Made predictions in 0.0010 seconds.\n",
      "F1 score for training set: 0.7021.\n",
      "Accuracy score for training set: 0.6146.\n",
      "Made predictions in 0.0005 seconds.\n",
      "F1 score for test set: 0.6812.\n",
      "Accuracy score for test set: 0.5952.\n",
      "--------------------------------\n",
      "\n",
      "SVC: \n",
      "\n",
      "Training a SVC using a training set size of 800. . .\n",
      "Trained model in 0.0295 seconds\n",
      "Made predictions in 0.0210 seconds.\n",
      "F1 score for training set: 0.7045.\n",
      "Accuracy score for training set: 0.5437.\n",
      "Made predictions in 0.0090 seconds.\n",
      "F1 score for test set: 0.6909.\n",
      "Accuracy score for test set: 0.5278.\n",
      "--------------------------------\n",
      "Training a SVC using a training set size of 1600. . .\n",
      "Trained model in 0.1276 seconds\n",
      "Made predictions in 0.0841 seconds.\n",
      "F1 score for training set: 0.7081.\n",
      "Accuracy score for training set: 0.5481.\n",
      "Made predictions in 0.0135 seconds.\n",
      "F1 score for test set: 0.6909.\n",
      "Accuracy score for test set: 0.5278.\n",
      "--------------------------------\n",
      "Training a SVC using a training set size of 2426. . .\n",
      "Trained model in 0.3222 seconds\n",
      "Made predictions in 0.2046 seconds.\n",
      "F1 score for training set: 0.7089.\n",
      "Accuracy score for training set: 0.5491.\n",
      "Made predictions in 0.0195 seconds.\n",
      "F1 score for test set: 0.6909.\n",
      "Accuracy score for test set: 0.5278.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize the three models\n",
    "clf_A = DecisionTreeClassifier(random_state=1)\n",
    "clf_B = GaussianNB()\n",
    "clf_C = SVC(random_state=2)\n",
    "\n",
    "# Set up the training set sizes\n",
    "X_train_800 = X_train[:800]\n",
    "y_train_800 = y_train[:800]\n",
    "\n",
    "X_train_1600 = X_train[:1600]\n",
    "y_train_1600 = y_train[:1600]\n",
    "\n",
    "X_train_2426 = X_train[:2426]\n",
    "y_train_2426 = y_train[:2426]\n",
    "\n",
    "# Execute the 'train_predict' function for each classifier and each training set size\n",
    "\n",
    "# loop thru models, then thru train sizes\n",
    "for clf in [clf_A, clf_B, clf_C]:\n",
    "    print (\"\\n{}: \\n\".format(clf.__class__.__name__))\n",
    "    for n in [800, 1600, 2426]:\n",
    "        train_predict(clf, X_train[:n], y_train[:n], X_test, y_test)\n",
    "        print ('-'*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gaurav\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Gaurav\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made predictions in 0.0005 seconds.\n",
      "Tuned model has a training F1 score of 0.6680.\n",
      "Tuned model has a training accuracy score of 0.6533.\n",
      "Made predictions in 0.0000 seconds.\n",
      "Tuned model has a testing F1 score of 0.6763.\n",
      "Tuned model has a testing accuracy score of 0.6429.\n",
      "The best parameters are {'criterion': 'gini', 'max_depth': 3, 'splitter': 'best'}\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "Days_Since_Open     0.000000\n",
      "Break_Coming        0.000000\n",
      "Overnight_Return    0.574240\n",
      "Overnight_VIX       0.384663\n",
      "O_to_O              0.000000\n",
      "Trail_1d_Ret        0.000000\n",
      "Trail_2d_Ret        0.000000\n",
      "Trail_3d_Ret        0.000000\n",
      "Trail_4d_Ret        0.000000\n",
      "Trail_5d_Ret        0.000000\n",
      "Trail_21d_Ret       0.025981\n",
      "Trail_63d_Ret       0.015116\n",
      "Trail_126d_Ret      0.000000\n",
      "Trail_252d_Ret      0.000000\n",
      "Trail_1d_VIX        0.000000\n",
      "Trail_5d_VIX        0.000000\n",
      "Trail_1d_Rel_Vol    0.000000\n",
      "Trail_5d_Rel_Vol    0.000000\n",
      "Trail_1d_PtT        0.000000\n",
      "Trail_1d_VIX_PtT    0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Optimize the Decision Tree parameters by using grid search cross validation\n",
    "\n",
    "# Import 'GridSearchCV' and 'make_scorer'\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Create the parameters list you wish to tune\n",
    "\n",
    "parameters = {'max_depth': [1,2,3,4,5,6,7,8,9],'criterion':('gini','entropy'),'splitter':('best','random')}\n",
    "\n",
    "# Initialize the classifier\n",
    "clf = DecisionTreeClassifier(random_state=4)\n",
    "\n",
    "# Perform grid search on the classifier using the default scoring method (accuracy)\n",
    "grid_obj = GridSearchCV(clf, parameters)\n",
    "\n",
    "# Fit the grid search object to the training data and find the optimal parameters\n",
    "grid_obj.fit(X_train,y_train)\n",
    "\n",
    "# Get the estimator\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Report the final F1 score for training and testing after parameter tuning\n",
    "print (\"Tuned model has a training F1 score of {:.4f}.\".format(predict_labels(clf, X_train, y_train)))\n",
    "print (\"Tuned model has a training accuracy score of {:.4f}.\".format(predict_labels_accuracy(clf, X_train, y_train)))\n",
    "print (\"Tuned model has a testing F1 score of {:.4f}.\".format(predict_labels(clf, X_test, y_test)))\n",
    "print (\"Tuned model has a testing accuracy score of {:.4f}.\".format(predict_labels_accuracy(clf, X_test, y_test)))\n",
    "\n",
    "print(\"The best parameters are %s\"\n",
    "      % (grid_obj.best_params_))\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "\n",
    "feature_importance = pd.Series(importances,index=['Days_Since_Open','Break_Coming','Overnight_Return',\n",
    "                                                  'Overnight_VIX','O_to_O','Trail_1d_Ret','Trail_2d_Ret',\n",
    "                                                  'Trail_3d_Ret','Trail_4d_Ret','Trail_5d_Ret','Trail_21d_Ret',\n",
    "                                                  'Trail_63d_Ret','Trail_126d_Ret','Trail_252d_Ret','Trail_1d_VIX',\n",
    "                                                  'Trail_5d_VIX','Trail_1d_Rel_Vol','Trail_5d_Rel_Vol','Trail_1d_PtT',\n",
    "                                                  'Trail_1d_VIX_PtT'])\n",
    "\n",
    "print('\\n')\n",
    "print(\"Feature Importance:\" )\n",
    "print(feature_importance)\n",
    "\n",
    "# Output predictions for further analysis\n",
    "np.savetxt(\"eval-DT.csv\", clf.predict(X_test), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made predictions in 0.0771 seconds.\n",
      "Tuned model has a training F1 score of 0.7250.\n",
      "Tuned model has a training accuracy score of 0.6385.\n",
      "Made predictions in 0.0100 seconds.\n",
      "Tuned model has a testing F1 score of 0.7032.\n",
      "Tuned model has a testing accuracy score of 0.6349.\n",
      "The best parameters are {'C': 12, 'gamma': 1e-06, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Optimize the SVM parameters by using grid search cross validation\n",
    "\n",
    "# Import 'GridSearchCV' and 'make_scorer'\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Create the parameters list you wish to tune\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf','sigmoid'), 'C':[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15], \n",
    "              'gamma':[.000001,.000005,.00005,.0005,.001,.005,.01,.02,.04,.05,.1,.3,.5]}\n",
    "\n",
    "# Initialize the classifier\n",
    "clf = SVC(random_state=3)\n",
    "\n",
    "# Perform grid search on the classifier using the default scoring method (accuracy)\n",
    "grid_obj = GridSearchCV(clf, parameters)\n",
    "\n",
    "# Fit the grid search object to the training data and find the optimal parameters\n",
    "grid_obj.fit(X_train,y_train)\n",
    "\n",
    "# Get the estimator\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Report the final F1 score for training and testing after parameter tuning\n",
    "print (\"Tuned model has a training F1 score of {:.4f}.\".format(predict_labels(clf, X_train, y_train)))\n",
    "print (\"Tuned model has a training accuracy score of {:.4f}.\".format(predict_labels_accuracy(clf, X_train, y_train)))\n",
    "print (\"Tuned model has a testing F1 score of {:.4f}.\".format(predict_labels(clf, X_test, y_test)))\n",
    "print (\"Tuned model has a testing accuracy score of {:.4f}.\".format(predict_labels_accuracy(clf, X_test, y_test)))\n",
    "\n",
    "print(\"The best parameters are %s\"\n",
    "      % (grid_obj.best_params_))\n",
    "\n",
    "# Output predictions for further analysis\n",
    "np.savetxt(\"eval-SVM.csv\", clf.predict(X_test), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scale features (mean = 0, stdev = 1):\n",
    "\n",
    "from sklearn import preprocessing\n",
    "X_scaled = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2678.000000</td>\n",
       "      <td>2678.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.452950</td>\n",
       "      <td>0.547050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.497874</td>\n",
       "      <td>0.497874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1\n",
       "count  2678.000000  2678.000000\n",
       "mean      0.452950     0.547050\n",
       "std       0.497874     0.497874\n",
       "min       0.000000     0.000000\n",
       "25%       0.000000     0.000000\n",
       "50%       0.000000     1.000000\n",
       "75%       1.000000     1.000000\n",
       "max       1.000000     1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2678, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(y)\n",
    "y_scaled = enc.transform(y).toarray()\n",
    "\n",
    "y_insight = pd.DataFrame(y_scaled)\n",
    "\n",
    "display(y_insight.describe())\n",
    "\n",
    "y_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (1922, 20) (1922, 2)\n",
      "Validation set (504, 20) (504, 2)\n",
      "Test set (252, 20) (252, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1922.000000</td>\n",
       "      <td>1922.000000</td>\n",
       "      <td>1922.000000</td>\n",
       "      <td>1922.000000</td>\n",
       "      <td>1922.000000</td>\n",
       "      <td>1922.000000</td>\n",
       "      <td>1922.000000</td>\n",
       "      <td>1922.000000</td>\n",
       "      <td>1922.000000</td>\n",
       "      <td>1922.000000</td>\n",
       "      <td>1922.000000</td>\n",
       "      <td>1922.000000</td>\n",
       "      <td>1922.000000</td>\n",
       "      <td>1922.000000</td>\n",
       "      <td>1922.000000</td>\n",
       "      <td>1922.000000</td>\n",
       "      <td>1922.000000</td>\n",
       "      <td>1922.000000</td>\n",
       "      <td>1922.000000</td>\n",
       "      <td>1922.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.002246</td>\n",
       "      <td>-0.004464</td>\n",
       "      <td>-0.022735</td>\n",
       "      <td>-0.017680</td>\n",
       "      <td>-0.003585</td>\n",
       "      <td>-0.003335</td>\n",
       "      <td>-0.004705</td>\n",
       "      <td>-0.008693</td>\n",
       "      <td>-0.009718</td>\n",
       "      <td>-0.009922</td>\n",
       "      <td>-0.027411</td>\n",
       "      <td>-0.043538</td>\n",
       "      <td>-0.049059</td>\n",
       "      <td>-0.098692</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>-0.008035</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>0.010455</td>\n",
       "      <td>0.133389</td>\n",
       "      <td>-0.081174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.999763</td>\n",
       "      <td>0.997082</td>\n",
       "      <td>1.074310</td>\n",
       "      <td>0.923680</td>\n",
       "      <td>1.109777</td>\n",
       "      <td>1.106825</td>\n",
       "      <td>1.098113</td>\n",
       "      <td>1.092914</td>\n",
       "      <td>1.091955</td>\n",
       "      <td>1.093523</td>\n",
       "      <td>1.101376</td>\n",
       "      <td>1.127321</td>\n",
       "      <td>1.140101</td>\n",
       "      <td>1.113726</td>\n",
       "      <td>0.960511</td>\n",
       "      <td>0.880923</td>\n",
       "      <td>1.021252</td>\n",
       "      <td>1.048842</td>\n",
       "      <td>1.105402</td>\n",
       "      <td>0.952326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.507900</td>\n",
       "      <td>-0.517100</td>\n",
       "      <td>-8.844321</td>\n",
       "      <td>-6.795061</td>\n",
       "      <td>-7.109165</td>\n",
       "      <td>-6.985810</td>\n",
       "      <td>-7.207462</td>\n",
       "      <td>-6.874485</td>\n",
       "      <td>-7.500630</td>\n",
       "      <td>-7.245063</td>\n",
       "      <td>-5.978411</td>\n",
       "      <td>-5.304133</td>\n",
       "      <td>-3.969464</td>\n",
       "      <td>-3.153637</td>\n",
       "      <td>-4.000111</td>\n",
       "      <td>-2.340529</td>\n",
       "      <td>-4.223995</td>\n",
       "      <td>-4.355154</td>\n",
       "      <td>-0.990167</td>\n",
       "      <td>-1.405074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.507900</td>\n",
       "      <td>-0.517100</td>\n",
       "      <td>-0.170724</td>\n",
       "      <td>-0.461074</td>\n",
       "      <td>-0.396309</td>\n",
       "      <td>-0.401901</td>\n",
       "      <td>-0.478210</td>\n",
       "      <td>-0.497041</td>\n",
       "      <td>-0.523534</td>\n",
       "      <td>-0.501545</td>\n",
       "      <td>-0.569747</td>\n",
       "      <td>-0.603210</td>\n",
       "      <td>-0.569127</td>\n",
       "      <td>-0.455262</td>\n",
       "      <td>-0.556414</td>\n",
       "      <td>-0.554569</td>\n",
       "      <td>-0.559025</td>\n",
       "      <td>-0.600749</td>\n",
       "      <td>-0.535700</td>\n",
       "      <td>-0.687520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.507900</td>\n",
       "      <td>-0.517100</td>\n",
       "      <td>0.004919</td>\n",
       "      <td>-0.122359</td>\n",
       "      <td>0.036526</td>\n",
       "      <td>0.032513</td>\n",
       "      <td>0.041032</td>\n",
       "      <td>0.077633</td>\n",
       "      <td>0.085518</td>\n",
       "      <td>0.074873</td>\n",
       "      <td>0.171047</td>\n",
       "      <td>0.136405</td>\n",
       "      <td>0.051890</td>\n",
       "      <td>0.074842</td>\n",
       "      <td>-0.107183</td>\n",
       "      <td>-0.124521</td>\n",
       "      <td>-0.076691</td>\n",
       "      <td>-0.051002</td>\n",
       "      <td>-0.167506</td>\n",
       "      <td>-0.298434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.507900</td>\n",
       "      <td>-0.517100</td>\n",
       "      <td>0.223773</td>\n",
       "      <td>0.390256</td>\n",
       "      <td>0.462439</td>\n",
       "      <td>0.446846</td>\n",
       "      <td>0.522221</td>\n",
       "      <td>0.536587</td>\n",
       "      <td>0.552471</td>\n",
       "      <td>0.561334</td>\n",
       "      <td>0.619494</td>\n",
       "      <td>0.705675</td>\n",
       "      <td>0.662916</td>\n",
       "      <td>0.559837</td>\n",
       "      <td>0.408253</td>\n",
       "      <td>0.387349</td>\n",
       "      <td>0.469229</td>\n",
       "      <td>0.528372</td>\n",
       "      <td>0.402930</td>\n",
       "      <td>0.234408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.060214</td>\n",
       "      <td>1.933862</td>\n",
       "      <td>9.403597</td>\n",
       "      <td>6.350112</td>\n",
       "      <td>8.662504</td>\n",
       "      <td>8.907937</td>\n",
       "      <td>7.604455</td>\n",
       "      <td>6.834938</td>\n",
       "      <td>7.752933</td>\n",
       "      <td>7.460513</td>\n",
       "      <td>4.839027</td>\n",
       "      <td>4.609906</td>\n",
       "      <td>3.799225</td>\n",
       "      <td>3.603865</td>\n",
       "      <td>8.560812</td>\n",
       "      <td>6.565746</td>\n",
       "      <td>11.206517</td>\n",
       "      <td>6.003443</td>\n",
       "      <td>8.404070</td>\n",
       "      <td>9.285350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  1922.000000  1922.000000  1922.000000  1922.000000  1922.000000   \n",
       "mean     -0.002246    -0.004464    -0.022735    -0.017680    -0.003585   \n",
       "std       0.999763     0.997082     1.074310     0.923680     1.109777   \n",
       "min      -0.507900    -0.517100    -8.844321    -6.795061    -7.109165   \n",
       "25%      -0.507900    -0.517100    -0.170724    -0.461074    -0.396309   \n",
       "50%      -0.507900    -0.517100     0.004919    -0.122359     0.036526   \n",
       "75%      -0.507900    -0.517100     0.223773     0.390256     0.462439   \n",
       "max       4.060214     1.933862     9.403597     6.350112     8.662504   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  1922.000000  1922.000000  1922.000000  1922.000000  1922.000000   \n",
       "mean     -0.003335    -0.004705    -0.008693    -0.009718    -0.009922   \n",
       "std       1.106825     1.098113     1.092914     1.091955     1.093523   \n",
       "min      -6.985810    -7.207462    -6.874485    -7.500630    -7.245063   \n",
       "25%      -0.401901    -0.478210    -0.497041    -0.523534    -0.501545   \n",
       "50%       0.032513     0.041032     0.077633     0.085518     0.074873   \n",
       "75%       0.446846     0.522221     0.536587     0.552471     0.561334   \n",
       "max       8.907937     7.604455     6.834938     7.752933     7.460513   \n",
       "\n",
       "                10           11           12           13           14  \\\n",
       "count  1922.000000  1922.000000  1922.000000  1922.000000  1922.000000   \n",
       "mean     -0.027411    -0.043538    -0.049059    -0.098692     0.000492   \n",
       "std       1.101376     1.127321     1.140101     1.113726     0.960511   \n",
       "min      -5.978411    -5.304133    -3.969464    -3.153637    -4.000111   \n",
       "25%      -0.569747    -0.603210    -0.569127    -0.455262    -0.556414   \n",
       "50%       0.171047     0.136405     0.051890     0.074842    -0.107183   \n",
       "75%       0.619494     0.705675     0.662916     0.559837     0.408253   \n",
       "max       4.839027     4.609906     3.799225     3.603865     8.560812   \n",
       "\n",
       "                15           16           17           18           19  \n",
       "count  1922.000000  1922.000000  1922.000000  1922.000000  1922.000000  \n",
       "mean     -0.008035     0.002379     0.010455     0.133389    -0.081174  \n",
       "std       0.880923     1.021252     1.048842     1.105402     0.952326  \n",
       "min      -2.340529    -4.223995    -4.355154    -0.990167    -1.405074  \n",
       "25%      -0.554569    -0.559025    -0.600749    -0.535700    -0.687520  \n",
       "50%      -0.124521    -0.076691    -0.051002    -0.167506    -0.298434  \n",
       "75%       0.387349     0.469229     0.528372     0.402930     0.234408  \n",
       "max       6.565746    11.206517     6.003443     8.404070     9.285350  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>504.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>504.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.006466</td>\n",
       "      <td>0.017832</td>\n",
       "      <td>0.079679</td>\n",
       "      <td>0.026721</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000588</td>\n",
       "      <td>-0.001641</td>\n",
       "      <td>0.007858</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>0.008198</td>\n",
       "      <td>0.050612</td>\n",
       "      <td>0.140175</td>\n",
       "      <td>0.244503</td>\n",
       "      <td>0.531242</td>\n",
       "      <td>0.015865</td>\n",
       "      <td>0.065817</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>-0.009547</td>\n",
       "      <td>-0.375440</td>\n",
       "      <td>0.115282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.996222</td>\n",
       "      <td>1.013402</td>\n",
       "      <td>0.638435</td>\n",
       "      <td>1.119913</td>\n",
       "      <td>0.623667</td>\n",
       "      <td>0.630154</td>\n",
       "      <td>0.676409</td>\n",
       "      <td>0.702497</td>\n",
       "      <td>0.706604</td>\n",
       "      <td>0.692251</td>\n",
       "      <td>0.611144</td>\n",
       "      <td>0.451226</td>\n",
       "      <td>0.355141</td>\n",
       "      <td>0.412784</td>\n",
       "      <td>1.077767</td>\n",
       "      <td>1.332116</td>\n",
       "      <td>0.933055</td>\n",
       "      <td>0.861707</td>\n",
       "      <td>0.511464</td>\n",
       "      <td>1.134053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.507900</td>\n",
       "      <td>-0.517100</td>\n",
       "      <td>-2.786333</td>\n",
       "      <td>-5.364490</td>\n",
       "      <td>-2.797536</td>\n",
       "      <td>-3.058741</td>\n",
       "      <td>-4.076469</td>\n",
       "      <td>-4.441744</td>\n",
       "      <td>-4.454806</td>\n",
       "      <td>-4.337606</td>\n",
       "      <td>-2.123183</td>\n",
       "      <td>-1.647801</td>\n",
       "      <td>-1.172461</td>\n",
       "      <td>-0.718756</td>\n",
       "      <td>-2.874521</td>\n",
       "      <td>-2.609975</td>\n",
       "      <td>-4.629373</td>\n",
       "      <td>-2.865730</td>\n",
       "      <td>-1.033919</td>\n",
       "      <td>-1.159760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.507900</td>\n",
       "      <td>-0.517100</td>\n",
       "      <td>-0.277986</td>\n",
       "      <td>-0.574980</td>\n",
       "      <td>-0.299378</td>\n",
       "      <td>-0.312059</td>\n",
       "      <td>-0.332724</td>\n",
       "      <td>-0.320271</td>\n",
       "      <td>-0.318381</td>\n",
       "      <td>-0.311481</td>\n",
       "      <td>-0.269975</td>\n",
       "      <td>-0.059651</td>\n",
       "      <td>0.081024</td>\n",
       "      <td>0.305012</td>\n",
       "      <td>-0.586045</td>\n",
       "      <td>-0.624110</td>\n",
       "      <td>-0.487563</td>\n",
       "      <td>-0.581333</td>\n",
       "      <td>-0.729745</td>\n",
       "      <td>-0.610215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.507900</td>\n",
       "      <td>-0.517100</td>\n",
       "      <td>0.086295</td>\n",
       "      <td>-0.042573</td>\n",
       "      <td>0.021022</td>\n",
       "      <td>0.012360</td>\n",
       "      <td>0.060728</td>\n",
       "      <td>0.078113</td>\n",
       "      <td>0.053703</td>\n",
       "      <td>0.080739</td>\n",
       "      <td>0.094618</td>\n",
       "      <td>0.177505</td>\n",
       "      <td>0.302295</td>\n",
       "      <td>0.520800</td>\n",
       "      <td>-0.077102</td>\n",
       "      <td>-0.087428</td>\n",
       "      <td>-0.087380</td>\n",
       "      <td>-0.155388</td>\n",
       "      <td>-0.502978</td>\n",
       "      <td>-0.143488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.507900</td>\n",
       "      <td>-0.517100</td>\n",
       "      <td>0.485547</td>\n",
       "      <td>0.502434</td>\n",
       "      <td>0.350993</td>\n",
       "      <td>0.350933</td>\n",
       "      <td>0.367431</td>\n",
       "      <td>0.404540</td>\n",
       "      <td>0.410578</td>\n",
       "      <td>0.415818</td>\n",
       "      <td>0.417397</td>\n",
       "      <td>0.411836</td>\n",
       "      <td>0.448069</td>\n",
       "      <td>0.800260</td>\n",
       "      <td>0.536229</td>\n",
       "      <td>0.464823</td>\n",
       "      <td>0.422676</td>\n",
       "      <td>0.500613</td>\n",
       "      <td>-0.141730</td>\n",
       "      <td>0.463834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.918185</td>\n",
       "      <td>1.933862</td>\n",
       "      <td>2.203346</td>\n",
       "      <td>4.109946</td>\n",
       "      <td>3.021801</td>\n",
       "      <td>2.989399</td>\n",
       "      <td>3.686188</td>\n",
       "      <td>3.165570</td>\n",
       "      <td>2.389943</td>\n",
       "      <td>2.134465</td>\n",
       "      <td>1.909986</td>\n",
       "      <td>1.187349</td>\n",
       "      <td>1.015746</td>\n",
       "      <td>1.548766</td>\n",
       "      <td>6.181159</td>\n",
       "      <td>13.663933</td>\n",
       "      <td>3.897680</td>\n",
       "      <td>3.077722</td>\n",
       "      <td>3.350198</td>\n",
       "      <td>12.844461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  504.000000  504.000000  504.000000  504.000000  504.000000  504.000000   \n",
       "mean     0.006466    0.017832    0.079679    0.026721    0.000011   -0.000588   \n",
       "std      0.996222    1.013402    0.638435    1.119913    0.623667    0.630154   \n",
       "min     -0.507900   -0.517100   -2.786333   -5.364490   -2.797536   -3.058741   \n",
       "25%     -0.507900   -0.517100   -0.277986   -0.574980   -0.299378   -0.312059   \n",
       "50%     -0.507900   -0.517100    0.086295   -0.042573    0.021022    0.012360   \n",
       "75%     -0.507900   -0.517100    0.485547    0.502434    0.350993    0.350933   \n",
       "max      2.918185    1.933862    2.203346    4.109946    3.021801    2.989399   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  504.000000  504.000000  504.000000  504.000000  504.000000  504.000000   \n",
       "mean    -0.001641    0.007858    0.009373    0.008198    0.050612    0.140175   \n",
       "std      0.676409    0.702497    0.706604    0.692251    0.611144    0.451226   \n",
       "min     -4.076469   -4.441744   -4.454806   -4.337606   -2.123183   -1.647801   \n",
       "25%     -0.332724   -0.320271   -0.318381   -0.311481   -0.269975   -0.059651   \n",
       "50%      0.060728    0.078113    0.053703    0.080739    0.094618    0.177505   \n",
       "75%      0.367431    0.404540    0.410578    0.415818    0.417397    0.411836   \n",
       "max      3.686188    3.165570    2.389943    2.134465    1.909986    1.187349   \n",
       "\n",
       "               12          13          14          15          16          17  \\\n",
       "count  504.000000  504.000000  504.000000  504.000000  504.000000  504.000000   \n",
       "mean     0.244503    0.531242    0.015865    0.065817   -0.001668   -0.009547   \n",
       "std      0.355141    0.412784    1.077767    1.332116    0.933055    0.861707   \n",
       "min     -1.172461   -0.718756   -2.874521   -2.609975   -4.629373   -2.865730   \n",
       "25%      0.081024    0.305012   -0.586045   -0.624110   -0.487563   -0.581333   \n",
       "50%      0.302295    0.520800   -0.077102   -0.087428   -0.087380   -0.155388   \n",
       "75%      0.448069    0.800260    0.536229    0.464823    0.422676    0.500613   \n",
       "max      1.015746    1.548766    6.181159   13.663933    3.897680    3.077722   \n",
       "\n",
       "               18          19  \n",
       "count  504.000000  504.000000  \n",
       "mean    -0.375440    0.115282  \n",
       "std      0.511464    1.134053  \n",
       "min     -1.033919   -1.159760  \n",
       "25%     -0.729745   -0.610215  \n",
       "50%     -0.502978   -0.143488  \n",
       "75%     -0.141730    0.463834  \n",
       "max      3.350198   12.844461  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.004200</td>\n",
       "      <td>-0.001620</td>\n",
       "      <td>0.014045</td>\n",
       "      <td>0.081402</td>\n",
       "      <td>0.027319</td>\n",
       "      <td>0.026614</td>\n",
       "      <td>0.039167</td>\n",
       "      <td>0.050588</td>\n",
       "      <td>0.055376</td>\n",
       "      <td>0.059281</td>\n",
       "      <td>0.107843</td>\n",
       "      <td>0.051715</td>\n",
       "      <td>-0.114830</td>\n",
       "      <td>-0.309760</td>\n",
       "      <td>-0.035483</td>\n",
       "      <td>-0.070350</td>\n",
       "      <td>-0.014808</td>\n",
       "      <td>-0.060646</td>\n",
       "      <td>-0.266477</td>\n",
       "      <td>0.388549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.015158</td>\n",
       "      <td>1.000838</td>\n",
       "      <td>1.001252</td>\n",
       "      <td>1.271094</td>\n",
       "      <td>0.680479</td>\n",
       "      <td>0.704905</td>\n",
       "      <td>0.722403</td>\n",
       "      <td>0.731715</td>\n",
       "      <td>0.734263</td>\n",
       "      <td>0.743440</td>\n",
       "      <td>0.783896</td>\n",
       "      <td>0.691611</td>\n",
       "      <td>0.562812</td>\n",
       "      <td>0.311627</td>\n",
       "      <td>1.130880</td>\n",
       "      <td>1.076941</td>\n",
       "      <td>0.970700</td>\n",
       "      <td>0.870239</td>\n",
       "      <td>0.550212</td>\n",
       "      <td>0.960356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.507900</td>\n",
       "      <td>-0.517100</td>\n",
       "      <td>-3.482311</td>\n",
       "      <td>-2.405700</td>\n",
       "      <td>-2.819101</td>\n",
       "      <td>-2.789370</td>\n",
       "      <td>-3.114412</td>\n",
       "      <td>-2.340853</td>\n",
       "      <td>-2.175100</td>\n",
       "      <td>-2.385657</td>\n",
       "      <td>-2.033764</td>\n",
       "      <td>-1.658450</td>\n",
       "      <td>-1.226221</td>\n",
       "      <td>-1.009647</td>\n",
       "      <td>-2.903366</td>\n",
       "      <td>-2.823122</td>\n",
       "      <td>-3.769979</td>\n",
       "      <td>-2.825518</td>\n",
       "      <td>-0.981178</td>\n",
       "      <td>-1.068757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.507900</td>\n",
       "      <td>-0.517100</td>\n",
       "      <td>-0.611052</td>\n",
       "      <td>-0.518717</td>\n",
       "      <td>-0.317475</td>\n",
       "      <td>-0.276751</td>\n",
       "      <td>-0.316887</td>\n",
       "      <td>-0.325984</td>\n",
       "      <td>-0.339072</td>\n",
       "      <td>-0.314260</td>\n",
       "      <td>-0.321826</td>\n",
       "      <td>-0.424870</td>\n",
       "      <td>-0.457919</td>\n",
       "      <td>-0.481317</td>\n",
       "      <td>-0.759143</td>\n",
       "      <td>-0.800195</td>\n",
       "      <td>-0.565420</td>\n",
       "      <td>-0.612964</td>\n",
       "      <td>-0.673336</td>\n",
       "      <td>-0.254535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.507900</td>\n",
       "      <td>-0.517100</td>\n",
       "      <td>0.055638</td>\n",
       "      <td>-0.076000</td>\n",
       "      <td>0.026183</td>\n",
       "      <td>-0.003926</td>\n",
       "      <td>0.047736</td>\n",
       "      <td>0.059595</td>\n",
       "      <td>0.069553</td>\n",
       "      <td>0.111218</td>\n",
       "      <td>0.116825</td>\n",
       "      <td>0.200171</td>\n",
       "      <td>-0.185106</td>\n",
       "      <td>-0.357229</td>\n",
       "      <td>-0.153959</td>\n",
       "      <td>-0.208765</td>\n",
       "      <td>-0.094655</td>\n",
       "      <td>-0.148221</td>\n",
       "      <td>-0.408135</td>\n",
       "      <td>0.173110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.507900</td>\n",
       "      <td>-0.517100</td>\n",
       "      <td>0.579683</td>\n",
       "      <td>0.506111</td>\n",
       "      <td>0.371059</td>\n",
       "      <td>0.383646</td>\n",
       "      <td>0.411371</td>\n",
       "      <td>0.448027</td>\n",
       "      <td>0.490706</td>\n",
       "      <td>0.502796</td>\n",
       "      <td>0.566689</td>\n",
       "      <td>0.561025</td>\n",
       "      <td>0.147872</td>\n",
       "      <td>-0.143241</td>\n",
       "      <td>0.559515</td>\n",
       "      <td>0.402551</td>\n",
       "      <td>0.415332</td>\n",
       "      <td>0.422095</td>\n",
       "      <td>0.007372</td>\n",
       "      <td>0.790819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.918185</td>\n",
       "      <td>1.933862</td>\n",
       "      <td>2.821884</td>\n",
       "      <td>11.199976</td>\n",
       "      <td>1.824283</td>\n",
       "      <td>1.888931</td>\n",
       "      <td>2.072088</td>\n",
       "      <td>2.599983</td>\n",
       "      <td>2.331683</td>\n",
       "      <td>2.153165</td>\n",
       "      <td>2.213261</td>\n",
       "      <td>1.442814</td>\n",
       "      <td>1.330106</td>\n",
       "      <td>0.605436</td>\n",
       "      <td>6.567692</td>\n",
       "      <td>4.102165</td>\n",
       "      <td>7.149330</td>\n",
       "      <td>2.920923</td>\n",
       "      <td>1.872788</td>\n",
       "      <td>4.920729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  252.000000  252.000000  252.000000  252.000000  252.000000  252.000000   \n",
       "mean     0.004200   -0.001620    0.014045    0.081402    0.027319    0.026614   \n",
       "std      1.015158    1.000838    1.001252    1.271094    0.680479    0.704905   \n",
       "min     -0.507900   -0.517100   -3.482311   -2.405700   -2.819101   -2.789370   \n",
       "25%     -0.507900   -0.517100   -0.611052   -0.518717   -0.317475   -0.276751   \n",
       "50%     -0.507900   -0.517100    0.055638   -0.076000    0.026183   -0.003926   \n",
       "75%     -0.507900   -0.517100    0.579683    0.506111    0.371059    0.383646   \n",
       "max      2.918185    1.933862    2.821884   11.199976    1.824283    1.888931   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  252.000000  252.000000  252.000000  252.000000  252.000000  252.000000   \n",
       "mean     0.039167    0.050588    0.055376    0.059281    0.107843    0.051715   \n",
       "std      0.722403    0.731715    0.734263    0.743440    0.783896    0.691611   \n",
       "min     -3.114412   -2.340853   -2.175100   -2.385657   -2.033764   -1.658450   \n",
       "25%     -0.316887   -0.325984   -0.339072   -0.314260   -0.321826   -0.424870   \n",
       "50%      0.047736    0.059595    0.069553    0.111218    0.116825    0.200171   \n",
       "75%      0.411371    0.448027    0.490706    0.502796    0.566689    0.561025   \n",
       "max      2.072088    2.599983    2.331683    2.153165    2.213261    1.442814   \n",
       "\n",
       "               12          13          14          15          16          17  \\\n",
       "count  252.000000  252.000000  252.000000  252.000000  252.000000  252.000000   \n",
       "mean    -0.114830   -0.309760   -0.035483   -0.070350   -0.014808   -0.060646   \n",
       "std      0.562812    0.311627    1.130880    1.076941    0.970700    0.870239   \n",
       "min     -1.226221   -1.009647   -2.903366   -2.823122   -3.769979   -2.825518   \n",
       "25%     -0.457919   -0.481317   -0.759143   -0.800195   -0.565420   -0.612964   \n",
       "50%     -0.185106   -0.357229   -0.153959   -0.208765   -0.094655   -0.148221   \n",
       "75%      0.147872   -0.143241    0.559515    0.402551    0.415332    0.422095   \n",
       "max      1.330106    0.605436    6.567692    4.102165    7.149330    2.920923   \n",
       "\n",
       "               18          19  \n",
       "count  252.000000  252.000000  \n",
       "mean    -0.266477    0.388549  \n",
       "std      0.550212    0.960356  \n",
       "min     -0.981178   -1.068757  \n",
       "25%     -0.673336   -0.254535  \n",
       "50%     -0.408135    0.173110  \n",
       "75%      0.007372    0.790819  \n",
       "max      1.872788    4.920729  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1922.000000</td>\n",
       "      <td>1922.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.443809</td>\n",
       "      <td>0.556191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.496962</td>\n",
       "      <td>0.496962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1\n",
       "count  1922.000000  1922.000000\n",
       "mean      0.443809     0.556191\n",
       "std       0.496962     0.496962\n",
       "min       0.000000     0.000000\n",
       "25%       0.000000     0.000000\n",
       "50%       0.000000     1.000000\n",
       "75%       1.000000     1.000000\n",
       "max       1.000000     1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>504.000000</td>\n",
       "      <td>504.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.478175</td>\n",
       "      <td>0.521825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500020</td>\n",
       "      <td>0.500020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0           1\n",
       "count  504.000000  504.000000\n",
       "mean     0.478175    0.521825\n",
       "std      0.500020    0.500020\n",
       "min      0.000000    0.000000\n",
       "25%      0.000000    0.000000\n",
       "50%      0.000000    1.000000\n",
       "75%      1.000000    1.000000\n",
       "max      1.000000    1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500221</td>\n",
       "      <td>0.500221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0           1\n",
       "count  252.000000  252.000000\n",
       "mean     0.472222    0.527778\n",
       "std      0.500221    0.500221\n",
       "min      0.000000    0.000000\n",
       "25%      0.000000    0.000000\n",
       "50%      0.000000    1.000000\n",
       "75%      1.000000    1.000000\n",
       "max      1.000000    1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the data into train, validation and test sets:\n",
    "# Shuffling will not be used because test data should be drawn from the latest data points, to remove any risk of\n",
    "# the learning algorithms glimpsing the future\n",
    "\n",
    "train_dataset = X_scaled[756:]\n",
    "valid_dataset = X_scaled[252:756]\n",
    "test_dataset = X_scaled[:252]\n",
    "\n",
    "train_labels = y_scaled[756:]\n",
    "valid_labels = y_scaled[252:756]\n",
    "test_labels = y_scaled[:252]\n",
    "\n",
    "tf.cast(train_dataset, tf.float32)\n",
    "tf.cast(valid_dataset, tf.float32)\n",
    "tf.cast(test_dataset, tf.float32)\n",
    "\n",
    "tf.cast(train_labels, tf.float32)\n",
    "tf.cast(valid_labels, tf.float32)\n",
    "tf.cast(test_labels, tf.float32)\n",
    "\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)\n",
    "\n",
    "describe_train = pd.DataFrame(train_dataset)\n",
    "describe_valid = pd.DataFrame(valid_dataset)\n",
    "describe_test = pd.DataFrame(test_dataset)\n",
    "\n",
    "describe_train_labels = pd.DataFrame(train_labels)\n",
    "describe_valid_labels = pd.DataFrame(valid_labels)\n",
    "describe_test_labels = pd.DataFrame(test_labels)\n",
    "\n",
    "\n",
    "display(describe_train.describe())\n",
    "display(describe_valid.describe())\n",
    "display(describe_test.describe())\n",
    "\n",
    "display(describe_train_labels.describe())\n",
    "display(describe_valid_labels.describe())\n",
    "display(describe_test_labels.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Establish functions for calculating accuracy and F1 score\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "def F1_score(predictions, labels):\n",
    "  return f1_score(np.argmax(labels, 1), np.argmax(predictions, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set restricted to the following number of samples: 1921\n",
      "Training set (1921, 20) (1921, 2)\n",
      "WARNING:tensorflow:From C:\\Users\\Gaurav\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-a210987cdc55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m                  keep_prob2:0.95,keep_prob3:0.95}\n\u001b[0;32m     39\u001b[0m     _, l, predictions = session.run(\n\u001b[1;32m---> 40\u001b[1;33m       [optimizer, loss, train_prediction], feed_dict=feed_dict)\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m500\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "num_steps = 7001\n",
    "\n",
    "# Set train_batches to 8 to use the full training set\n",
    "\n",
    "train_batches = 1\n",
    "train_subset = train_batches * batch_size\n",
    "\n",
    "print('Training set restricted to the following number of samples:',train_subset)\n",
    "\n",
    "train_smallset = train_dataset[0:train_subset,:]\n",
    "train_smalllabel = train_labels[0:train_subset]\n",
    "\n",
    "print('Training set', train_smallset.shape, train_smalllabel.shape)\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "\n",
    "  print(\"Initialized\")\n",
    "    \n",
    "  step_counter = []\n",
    "  step_train_accuracy = []\n",
    "  step_valid_accuracy = []\n",
    "  step_test_accuracy = []\n",
    "    \n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "#    offset = (step * batch_size) % (train_smalllabel.shape[0] - batch_size)\n",
    "    offset = 0\n",
    "\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_smallset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_smalllabel[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels,keep_prob1: 0.95,\n",
    "                 keep_prob2:0.95,keep_prob3:0.95}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    \n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "      print(\"Test accuracy: %.2f%%\" % accuracy(test_prediction.eval(), test_labels))   \n",
    "      print (\"F1 Score: %f\" % F1_score(test_prediction.eval(), test_labels))\n",
    "      \n",
    "      step_counter.append(step)\n",
    "      step_train_accuracy.append(accuracy(predictions, batch_labels))\n",
    "      step_valid_accuracy.append(accuracy(valid_prediction.eval(), valid_labels))\n",
    "      step_test_accuracy.append(accuracy(test_prediction.eval(), test_labels))\n",
    "    \n",
    "  print ('\\n')\n",
    "  print(\"FINAL Test accuracy: %.2f%%\" % accuracy(test_prediction.eval(), test_labels))   \n",
    "  print (\"FINAL F1 Score: %f\" % F1_score(test_prediction.eval(), test_labels))\n",
    "    \n",
    "# Output predictions for further analysis\n",
    "  np.savetxt(\"eval-NN.csv\", test_prediction.eval(), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18568f0a8d0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEKCAYAAAA1qaOTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XuYVWXd//H3RxxFVM6gcjCoUMFDgCPhg78eDU1ABa1Q\nSB9P9UNNU3vKpNSyK+zC6jEfrzyEZWqaxg8rtVBQw7QDyUFEFJTxlBwEtEBQUMHv74+1hjbDnpnN\nzNp7z2Y+r+va16y17nut/b33wHz3uu+17qWIwMzMrLl2KXcAZma2c3BCMTOzTDihmJlZJpxQzMws\nE04oZmaWCScUMzPLhBOKmZllwgnFzMwy4YRiZmaZ2LXcAZRS165do0+fPuUOw8ysosybN+/NiOjW\nWL1WlVD69OnD3Llzyx2GmVlFkfRaIfXc5WVmZplwQjEzs0w4oZiZWSacUMzMLBNOKGZmlgknFDMz\ny4QTipmZZcIJxczMMuGEYmZmmXBCMTOzTDihmJlZJpxQzMwsE04oZmaWCScUMzPLhBOKmZllwgnF\nzMwy4YRiZmaZcEIxM7NMOKGYmVkmnFDMzCwTTihmZpYJJxQzM8uEE4qZmWXCCcXMzDJR1oQiaYSk\nFyTVSJqYp1ySbkjLF0oaXKe8jaSnJf2+dFGbmVk+ZUsoktoANwIjgQHAeEkD6lQbCfRLXxOAm+uU\nXwIsLnKoZmZWgHKeoQwBaiLi5Yh4H7gXGFOnzhjgzkjMBjpK2g9AUi/gBOBnpQzazMzyK2dC6Qm8\nnrO+LN1WaJ3rgW8AHxYrQDMzK1xFDspLOhFYHRHzCqg7QdJcSXPXrFlTgujMzFqnciaU5UDvnPVe\n6bZC6gwDRkt6laSr7NOS7sr3JhExJSKqI6K6W7duWcVuZmZ1lDOhzAH6SeoraTdgHPBAnToPAGem\nV3sNBdZFxMqI+GZE9IqIPul+f4yIM0oavZmZbWPXcr1xRGyWdBEwA2gD3BYRz0k6Py2/BZgOjAJq\ngHeBc8oVr5mZNUwRUe4YSqa6ujrmzp1b7jDMzCqKpHkRUd1YvYoclDczs5bHCcXMzDLhhGJmZplw\nQjEzs0w4oZiZWSacUMzMLBNOKGZmlgknFDMzy4QTipmZZcIJxczMMuGEYmZmmXBCMTOzTDihmJlZ\nJpxQzMwsE04oZmaWCScUMzPLhBOKmZllwgnFzMwy4YRiZmaZcEIxM7NMOKGYmVkmnFDMzCwTTihm\nZpYJJxQzM8uEE4qZmWXCCcXMzDLhhGJmZplwQjEzs0w4oZiZWSacUMzMLBNOKGZmlomyJhRJIyS9\nIKlG0sQ85ZJ0Q1q+UNLgdHtvSbMkPS/pOUmXlD56MzPLVbaEIqkNcCMwEhgAjJc0oE61kUC/9DUB\nuDndvhn4WkQMAIYCF+bZ18zMSqicZyhDgJqIeDki3gfuBcbUqTMGuDMSs4GOkvaLiJURMR8gItYD\ni4GepQzezMy2Vc6E0hN4PWd9GdsnhUbrSOoDDAL+nnmEZmZWsIoelJe0F3AfcGlEvF1PnQmS5kqa\nu2bNmtIGaGbWipQzoSwHeues90q3FVRHUhVJMrk7In5T35tExJSIqI6I6m7dumUSuJmZba+cCWUO\n0E9SX0m7AeOAB+rUeQA4M73aayiwLiJWShLwc2BxRFxX2rDNzCyfXcv1xhGxWdJFwAygDXBbRDwn\n6fy0/BZgOjAKqAHeBc5Jdx8G/BfwrKQF6bZvRcT0UrbBzMz+TRFR7hhKprq6OubOnVvuMMzMKoqk\neRFR3Vi9ih6UNzOzlsMJxczMMtHoGIqkXYBPAD2AjcCiiFhd7MDMzKyy1JtQJH0MuBw4FlgKrAHa\nAgdIehf4KXBHRHxYikDNzKxla+gMZRLJ3FnnRZ2Re0ndgS+QXGl1R/HCMzOzSlFvQomI8Q2UrQau\nL0pEZmZWkQoelJf0cUl3SbpP0pHFDMrMzCpPQ2MobSNiU86m7wHfSJcfBAYWMzAzM6ssDZ2hPCjp\nzJz1D4A+wEeALcUMyszMKk9DCWUE0F7Sw5I+BXwdOB44BTi9FMGZmVnlaGhQfgvwE0m/BK4CLgCu\njIiXShWcmZlVjobGUD4JXAa8D3yf5KbGayQtB74XEWtLE6KZmVWChu5D+SnJTL97Ab+IiGHAOEn/\nCfyapPvLzMwMaDihbCYZhN+T5CwFgIj4E/Cn4oZlZmaVpqGE8gXgPJJkcmYD9czMzBpMKEsj4msN\n7SxJdadlMTOz1qmhy4ZnSfqKpP1zN0raTdKnJd0BnFXc8MzMrFI0dIYyAjgXuEdSX2AtyWzDbYCZ\nwPUR8XTxQzQzs0rQ0H0om4CbgJskVQFdgY2+XNjMzPJp9AFbABHxAbCyyLGYmVkF8yOAzcwsE04o\nZmaWiUYTSnqlV6dSBGNmZpWrkDOUfYA5kqZKGiFJxQ7KzMwqT6MJJSKuBPoBPwfOBpZK+r6kjxU5\nNjMzqyAFjaGkd8O/kb42A52AaZJ+UMTYzMysgjR62bCkS0jm8noT+BlwWUR8IGkXYCn/fiywmZm1\nYoXch9IZ+GxEvJa7MSI+lHRiccIyM7NKU0iX10PAP2tXJLVPH75FRCwuVmBmZlZZCkkoNwMbctY3\npNvMzMy2KiShbDNFfUR8SIFTtjR64OQy5Bck1UiamKdckm5IyxdKGlzovmZmVlqFJJSXJV0sqSp9\nXQK83Nw3ltQGuBEYCQwAxksaUKfaSJJLlvsBE0jPjArc18zMSqiQhHI+8B/AcmAZ8EmSP+7NNQSo\niYiXI+J94F5gTJ06Y4A7IzEb6ChpvwL3NTOzEmq06yoiVgPjivDePYHXc9Zrk1VjdXoWuK+ZmZVQ\nIfehtAW+CBxM8oAtACLi3CLGlRlJE0jPqPbff/9GapuZWVMV0uX1S2Bf4HjgT0AvYH0G770c6J2z\n3ivdVkidQvYFICKmRER1RFR369at2UGbmVl+hSSUj0fEVcA7EXEHcALZdC/NAfpJ6itpN5JutQfq\n1HkAODO92msosC4iVha4r5mZlVAhl/9+kP5cK+kQkvm8ujf3jSNis6SLgBkkz6m/LSKek3R+Wn4L\nMB0YBdQA7wLnNLRvc2MyM7OmKyShTEmfh3IlyVnAXsBVWbx5REwnSRq5227JWQ7gwkL3NTOz8mkw\noaQTQL4dEf8CngA+WpKozMys4jQ4hpLeFe/ZhM3MrFGFDMo/KunrknpL6lz7KnpkZmZWUQoZQzkt\n/Zk7lhG4+8vMzHIUcqd831IEYmZmla2QO+XPzLc9Iu7MPhwzM6tUhXR5HZGz3BYYDswHnFDMzGyr\nQrq8vpK7Lqkjyey+ZmZmWxVylVdd7wAeVzEzs20UMobyIMlVXZAkoAHA1GIGZWZmlaeQMZQf5Sxv\nBl6LiGVFisfMzCpUIQnlH8DKiNgEIGkPSX0i4tWiRmZmZhWlkDGU/wd8mLO+Jd1mZma2VSEJZdf0\nue0ApMu7FS8kMzOrRIUklDWSRteuSBoDvFm8kMzMrBIVMoZyPnC3pJ+k68uAvHfPm5lZ61XIjY0v\nAUMl7ZWubyh6VGZmVnEa7fKS9H1JHSNiQ0RskNRJ0qRSBGdmZpWjkDGUkRGxtnYlfXrjqOKFZGZm\nlaiQhNJG0u61K5L2AHZvoL6ZmbVChQzK3w08JukX6fo5eKZhMzOro5BB+WslPQMcm276XkTMKG5Y\nZmZWaQo5QyEiHgYeBpB0lKQbI+LCRnYzM7NWpKCEImkQMB44FXgF+E0xgzIzs8pTb0KRdABJEhlP\ncmf8rwFFxDElis3MzCpIQ2coS4AngRMjogZA0ldLEpWZmVWchi4b/iywEpgl6VZJwwGVJiwzM6s0\n9SaUiPhdRIwDDgJmAZcC3SXdLOkzpQrQzMwqQ6M3NkbEOxHxq4g4CegFPA1cXvTIzMysohRyp/xW\nEfGviJgSEcOLFZCZmVWmHUooZmZm9SlLQpHUWdIjkpamPzvVU2+EpBck1UiamLP9h5KWSFoo6beS\nOpYuejMzy6dcZygTgccioh/wWLq+DUltgBuBkcAAYLykAWnxI8AhEXEY8CLwzZJEbWZm9SpXQhkD\n3JEu3wGcnKfOEKAmIl5On2N/b7ofETEzIjan9WaTXCxgZmZlVK6Esk9ErEyX3wD2yVOnJ/B6zvqy\ndFtd5wIPZRuemZntqILm8moKSY8C++YpuiJ3JSJCUjTxPa4ANpNMsV9fnQnABID999+/KW9jZmYF\nKFpCiYhj6yuTtErSfhGxUtJ+wOo81ZYDvXPWe6Xbao9xNnAiMDwi6k1IETEFmAJQXV3dpMRlZmaN\nK1eX1wPAWenyWcD9eerMAfpJ6itpN2Bcuh+SRgDfAEZHxLsliNfMzBpRroQyGThO0lKSB3dNBpDU\nQ9J0gHTQ/SJgBrAYmBoRz6X7/wTYG3hE0gJJt5S6AWZmtq2idXk1JCLeAra72z4iVgCjctanA9Pz\n1Pt4UQM0M7Md5jvlzcwsE04oZmaWCScUMzPLhBOKmZllwgnFzMwy4YRiZmaZcEIxM7NMOKGYmVkm\nnFDMzCwTTihmZpYJJxQzM8tEWebyMjMrlQ8++IBly5axadOmcofS4rVt25ZevXpRVVXVpP2dUMxs\np7Zs2TL23ntv+vTpg6Ryh9NiRQRvvfUWy5Yto2/fvk06hru8zGyntmnTJrp06eJk0ghJdOnSpVln\nck4oZrbTczIpTHM/JycUM7MiWrt2LTfddNMO7zdq1CjWrl1bhIiKxwnFzKyI6ksomzdvbnC/6dOn\n07Fjx2KFVRQelDczK6KJEyfy0ksvMXDgQKqqqmjbti2dOnViyZIlvPjii5x88sm8/vrrbNq0iUsu\nuYQJEyYA0KdPH+bOncuGDRsYOXIkRx11FH/961/p2bMn999/P3vssUeZW7Y9JxQzazW+++BzPL/i\n7UyPOaBHe75z0sH1lk+ePJlFixaxYMECHn/8cU444QQWLVq09Uqq2267jc6dO7Nx40aOOOIIPve5\nz9GlS5dtjrF06VLuuecebr31Vk499VTuu+8+zjjjjEzbkQUnFDOzEhoyZMg2l+XecMMN/Pa3vwXg\n9ddfZ+nSpdsllL59+zJw4EAADj/8cF599dWSxbsjnFDMrNVo6EyiVPbcc8+ty48//jiPPvoof/vb\n32jXrh1HH3103st2d999963Lbdq0YePGjSWJdUd5UN7MrIj23ntv1q9fn7ds3bp1dOrUiXbt2rFk\nyRJmz55d4uiy5TMUM7Mi6tKlC8OGDeOQQw5hjz32YJ999tlaNmLECG655Rb69+/PgQceyNChQ8sY\nafMpIsodQ8lUV1fH3Llzyx2GmZXQ4sWL6d+/f7nDqBj5Pi9J8yKiurF93eVlZmaZcEIxM7NMOKGY\nmVkmnFDMzCwTTihmZpYJJxQzM8tEWRKKpM6SHpG0NP3ZqZ56IyS9IKlG0sQ85V+TFJK6Fj9qM7Pi\n22uvvQBYsWIFn//85/PWOfroo2nsFojrr7+ed999N/P4GlKuM5SJwGMR0Q94LF3fhqQ2wI3ASGAA\nMF7SgJzy3sBngH+UJGIzsxLq0aMH06ZNa/L+rSmhjAHuSJfvAE7OU2cIUBMRL0fE+8C96X61fgx8\nA2g9d2aaWcWZOHEiN95449b1q6++mkmTJjF8+HAGDx7MoYceyv3337/dfq+++iqHHHIIABs3bmTc\nuHH079+fU045ZZu5vC644AKqq6s5+OCD+c53vgMkE06uWLGCY445hmOOOQaAmTNncuSRRzJ48GDG\njh3Lhg0bMm9ruaZe2SciVqbLbwD75KnTE3g9Z30Z8EkASWOA5RHxjB/taWYFe2givPFstsfc91AY\nObne4tNOO41LL72UCy+8EICpU6cyY8YMLr74Ytq3b8+bb77J0KFDGT16dL2P4L355ptp164dixcv\nZuHChQwePHhr2TXXXEPnzp3ZsmULw4cPZ+HChVx88cVcd911zJo1i65du/Lmm28yadIkHn30Ufbc\nc0+uvfZarrvuOr797W9n+lEULaFIehTYN0/RFbkrERGSCj7LkNQO+BZJd1ch9ScAEwD233//Qt/G\nzCwTgwYNYvXq1axYsYI1a9bQqVMn9t13X7761a/yxBNPsMsuu7B8+XJWrVrFvvvm+5MJTzzxBBdf\nfDEAhx12GIcddtjWsqlTpzJlyhQ2b97MypUref7557cpB5g9ezbPP/88w4YNA+D999/nyCOPzLyt\nRUsoEXFsfWWSVknaLyJWStoPWJ2n2nKgd856r3Tbx4C+QO3ZSS9gvqQhEfFGnjimAFMgmcurqe0x\ns51AA2cSxTR27FimTZvGG2+8wWmnncbdd9/NmjVrmDdvHlVVVfTp0yfvtPWNeeWVV/jRj37EnDlz\n6NSpE2effXbe40QExx13HPfcc08WzalXucZQHgDOSpfPArbvQIQ5QD9JfSXtBowDHoiIZyOie0T0\niYg+JF1hg/MlEzOzluC0007j3nvvZdq0aYwdO5Z169bRvXt3qqqqmDVrFq+99lqD+3/qU5/iV7/6\nFQCLFi1i4cKFALz99tvsueeedOjQgVWrVvHQQw9t3Sd32vyhQ4fyl7/8hZqaGgDeeecdXnzxxczb\nWa4xlMnAVElfBF4DTgWQ1AP4WUSMiojNki4CZgBtgNsi4rkyxWtm1mQHH3ww69evp2fPnuy3336c\nfvrpnHTSSRx66KFUV1dz0EEHNbj/BRdcwDnnnEP//v3p378/hx9+OACf+MQnGDRoEAcddBC9e/fe\n2qUFMGHCBEaMGEGPHj2YNWsWt99+O+PHj+e9994DYNKkSRxwwAGZttPT15vZTs3T1+8YT19vZmZl\n54RiZmaZcEIxM7NMOKGYmVkmnFDMzCwTTihmZpYJJxQzsyJau3YtN910U5P2LceMwc3hhGJmVkSt\nKaGU6055M7NWYeLEibz00ksMHDiQ4447ju7duzN16lTee+89TjnlFL773e/yzjvvcOqpp7Js2TK2\nbNnCVVddxapVq7ZOQd+1a1dmzZpV7qY0ygnFzFqNa5+6liX/XJLpMQ/qfBCXD7m83vLJkyezaNEi\nFixYwMyZM5k2bRpPPfUUEcHo0aN54oknWLNmDT169OAPf/gDAOvWraNDhw7bTEFfCdzlZWZWIjNn\nzmTmzJkMGjSIwYMHs2TJEpYuXcqhhx7KI488wuWXX86TTz5Jhw4dyh1qk/gMxcxajYbOJEohIvjm\nN7/Jeeedt13Z/PnzmT59OldeeSXDhw/P/OFXpeAzFDOzIsqdRv7444/ntttu2/r43eXLl299+Fa7\ndu0444wzuOyyy5g/f/52+1YCn6GYmRVRly5dGDZsGIcccggjR47kC1/4wtanJe61117cdddd1NTU\ncNlll7HLLrtQVVXFzTffDGw/BX1L5+nrzWyn5unrd4ynrzczs7JzQjEzs0w4oZiZWSacUMxsp9ea\nxoqbo7mfkxOKme3U2rZty1tvveWk0oiI4K233qJt27ZNPoYvGzaznVqvXr1YtmwZa9asKXcoLV7b\ntm3p1atXk/d3QjGznVpVVRV9+/Ytdxitgru8zMwsE04oZmaWCScUMzPLRKuaekXSGuC1csfRBF2B\nN8sdRAm1tvaC29xaVGqbPxIR3Rqr1KoSSqWSNLeQeXR2Fq2tveA2txY7e5vd5WVmZplwQjEzs0w4\noVSGKeUOoMRaW3vBbW4tduo2ewzFzMwy4TMUMzPLhBNKCyCps6RHJC1Nf3aqp94ISS9IqpE0MU/5\n1ySFpK7Fj7p5mttmST+UtETSQkm/ldSxdNHvmAJ+b5J0Q1q+UNLgQvdtqZraZkm9Jc2S9Lyk5yRd\nUvrom6Y5v+e0vI2kpyX9vnRRZywi/CrzC/gBMDFdnghcm6dOG+Al4KPAbsAzwICc8t7ADJL7bLqW\nu03FbjPwGWDXdPnafPu3hFdjv7e0zijgIUDAUODvhe7bEl/NbPN+wOB0eW/gxZ29zTnl/w38Cvh9\nudvT1JfPUFqGMcAd6fIdwMl56gwBaiLi5Yh4H7g33a/Wj4FvAJUyKNasNkfEzIjYnNabDTR9itTi\nauz3Rrp+ZyRmAx0l7Vfgvi1Rk9scESsjYj5ARKwHFgM9Sxl8EzXn94ykXsAJwM9KGXTWnFBahn0i\nYmW6/AawT546PYHXc9aXpduQNAZYHhHPFDXKbDWrzXWcS/LNryUqpA311Sm0/S1Nc9q8laQ+wCDg\n75lHmL3mtvl6ki+EHxYrwFLw9PUlIulRYN88RVfkrkRESCr4LENSO+BbJF1ALUqx2lznPa4ANgN3\nN2V/a5kk7QXcB1waEW+XO55iknQisDoi5kk6utzxNIcTSolExLH1lUlaVXu6n54Cr85TbTnJOEmt\nXum2jwF9gWck1W6fL2lIRLyRWQOaoIhtrj3G2cCJwPBIO6FboAbb0EidqgL2bYma02YkVZEkk7sj\n4jdFjDNLzWnz54DRkkYBbYH2ku6KiDOKGG9xlHsQx68A+CHbDlD/IE+dXYGXSZJH7aDfwXnqvUpl\nDMo3q83ACOB5oFu529JIOxv9vZH0necO1j61I7/zlvZqZpsF3AlcX+52lKrNdeocTQUPypc9AL8C\noAvwGLAUeBTonG7vAUzPqTeK5KqXl4Ar6jlWpSSUZrUZqCHpj16Qvm4pd5saaOt2bQDOB85PlwXc\nmJY/C1TvyO+8Jb6a2mbgKJILSxbm/G5Hlbs9xf495xyjohOK75Q3M7NM+CovMzPLhBOKmZllwgnF\nzMwy4YRiZmaZcEIxM7NMOKHYdtIZi/8nZ/3rkq7O6Ni3S/p8Fsdq5H3GSlosaVaesi2SFqSvB3K2\n95X093Q22F9L2i3d3uAssTn7nyvp2bTOonRKHCSdLalHBm06PifuDenMtgsk3bkDx2gj6ckC6v1C\n0oHNixgk7Vrn854naWgj+3SWdH4Bx/6zpIHNjdGy44Ri+bwHfFYtbBp8STsys8MXgf8bEcfkKdsY\nEQPT1+ic7dcCP46IjwP/So8BMBLol74mADfnia0XyZQyR0XEYSQ3ri1Mi88mub+mWSJiRm3cwFzg\n9HT9zDqx1Ps5RcSWiPg/BbzXORHxQnNjTq3PifvbwDWN1O9Mcv+GVRgnFMtnM8mjSr9at6DuGYak\nDenPoyX9SdL9kl6WNFnS6ZKeSr+1fyznMMdKmivpxXQeo9pvzj+UNCf9hn9eznGfTM8kns8Tz/j0\n+IskXZtu+zbJDXI/l/TDQhqsZN6aTwPT0k25MyDXO0tsju7AemADQERsiIhX0s+qGrg7/Ya+h6TD\n089qnqQZOTPOPi7pf9N6iyQNKST2dN8vSfpdekY2Q1J7SX+UND/9PGs/510lrU2Xj5X0mKTfpGc7\nd+Yc78+SBtbWT3+fz0j6m6TuaZ1+6Rnds5KuqT1uI9qTJGvqixGYDByYfg6T07rfSt/nGUm5CWlc\n+m/sBUn/kdPG69LtCyV9Kd3eM21X7ef7H4V+vlagct9Z6VfLe5H8UWxPctd9B+DrwNVp2e3A53Pr\npj+PBtaSPM9id5I5ir6bll1COpVGuv/DJF9m+pHMuNqW5Jv/lWmd3Um+gfdNj/sO0DdPnD2AfwDd\nSKa++CNwclr2OHnuRE7LNgPzSaa9r63flWT68do6vYFF6fLvSc48asseq3tskudhzEjj+QVwUk7Z\n1lhI5uf6K+mUMcBpwG059W5Nlz9V+/71tGGb9gFfInkWTqec92mfLncHlqbLuwJr0+VjSf6490jj\nnwMMTcv+DAxM6wcwMt1+Hf+eMudhYGy6fFHtcevEuSuwheSO9yXpv5FBjcT4cWBBzjFOAp4E9kjX\nO+fEeG26PBp4OF3+ck6MuwNPA/sDlwOX5/y+9ir3/7Wd7eXJIS2viHg7/cZ6MbCxwN3mRDolvaSX\ngJnp9meB3K6nqRHxIbBU0svAQSSzJR+Wc/bTgSThvE8y59Ered7vCODxiFiTvufdJH+If9dInB+J\niOWSPgr8UdKzwLoC25hXRGyRNCKNaTjwY0mHR8TVdaoeCBwCPJKcFNEGWJlTfk96vCfSb/AdI6KQ\nb/4AMyPiX+mygMmSjiKZEr132oVZ91izI2IFgKQFQB+SRJtrY0TUPh5gHlDbZfZJkulGIHkw1KR6\n4lofSXcXaTx3Aoc2EGNdx5Ik3Y0AEfHPnLLaySPnpbFD8m+pv6Rx6Xrtv6U5wE8ltQV+F5X1uIeK\n4IRiDbme5Jv8L3K2bSbtKpW0C8lEeLXey1n+MGf9Q7b9t1Z3vp8g+ePylYiYkVugZDrvd5oWfn4R\nsTz9+bKkx0meuXEfSVfWrpE8uCt3tthCZpIlkq++TwFPSXqE5HO7uk41Ac9FxJH1hdfIekNyP6cz\nSf6QDo6IzZJqzwTryv2dbSH/34T3C6hTkIj4s6QekjoDny0wxobUxp8bl4AvR8RjdSun/55OAO6U\n9IOI8GMPMuQxFKtX+k1wKv8enIakG+zwdHk0SbfFjhoraZd0XOWjwAsk3UUXKJm6HEkHSNqzkeM8\nBfynpK6S2gDjgT81tIOkTpJ2T5e7AsOA59NkMAuoPUM6C7g/XX4AOFOJocC6+PfDwWqP20PbXv01\nkKQLCpKxlb3T5ReAbpKOTPerknRwzn6npduPSt+nqWdOHUiesbFZ0nEU58FcTwGnpMvjGqpYK23r\nhyRdbfXFmPt5ATwCnCtpj/QYnRt5mxnAl5VenCDpwHTs6iPAGxExhSTZDyokZiucz1CsMf9D0j9e\n61bgfknPkPShN+Xs4R8kf4zak8zEuknSz0i6LOYr6QtaQ/7HAm8VybNUJpIkAgF/iIj7G9oH6E/S\n7fEhyReqyRFRO9h/OXCvpEkk/e4/T7dPJ+naqQHeBc7Jc9wq4EdKLg/elMZfe6XS7cAtkjYCR5Ik\nrRskdSD5P3g98Fxad5Okp9PjndtIWxryS+DBtDvvKZJZnbN2MfBLSd8h+SNeX/LbO+1Oq3VmRISk\nvDFGxColFyw8S/I7nSjpE8BcSR8ADwJXNRDXT0nGTBak3YqrSS6sGA78d3qM9cB/Na3ZVh/PNmzW\nQqTdb1+PiLnljqUQ6Rnku2lyOAM4JSI+V+64rHx8hmJmTXUEcH06lvYv8p+5WSviMxQzM8uEB+XN\nzCwTTigr+iEaAAAAIUlEQVRmZpYJJxQzM8uEE4qZmWXCCcXMzDLhhGJmZpn4/629DQ0REjKwAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18568e86fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(step_train_accuracy, label = 'train')\n",
    "plt.plot(step_valid_accuracy, label = 'validate')\n",
    "plt.plot(step_test_accuracy, label = 'test')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Number of 500 Step Training Batches')\n",
    "plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
